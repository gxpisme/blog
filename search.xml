<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常用统计概念定义]]></title>
    <url>%2Fposts%2F%E6%A6%82%E5%BF%B5%2F2020%2F01%2F03%2Fbasic-statistical-data-definition%2F</url>
    <content type="text"><![CDATA[PV/UV/IP/DAU 经常听各个角色的人讲PV/UV等等，产品问业务预估有多少量，业务可能会给个多少UV、多少PV。然后技术同学根据这个预估的值做系统设计，做容量保障。 DAU (Daily Active User)日活跃用户量 统计一天之内，登录或使用了某个产品的用户数（去除重复登录的用户） PV (Page View)Page View, namely the pageviews or clicks, the user is calculated once per flush. 即页面浏览量或点击量，用户每次刷新计算一次 UV (Unique Visitor) Unique Visitor, visit your site a client computer to a visitor. 00:00-24:00 within the same client to be computed only once.同一个客户端访问多次，只计算一次，一天内有多少访问(一般的单位是天)，按照客户端维度计算的。（应该可以理解为用户维度计算的，每天有多少个用户，用户一般只用一个客户端访问） IP (IP): refers to the number of independent IP. 00:00-24:00 in the same IP address is calculated once.每天独立IP访问数，按照IP地址维度计算的。 NPEJAVA NullPointerException SLI （SLI Service Level Indicator）指标 例如错误率、吐出量、可用时间百分比 SLO (SLO Service Level Objective)目标 服务的某个SLI的目标值或目标范围 SLA (SLA Service Level Agreement)协议 服务与用户之间的一个明确的，或者不明确的协议，描述达到或没有达到SLO的后果]]></content>
      <categories>
        <category>概念</category>
      </categories>
      <tags>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[保险]]></title>
    <url>%2Fposts%2F%E7%94%9F%E6%B4%BB%2F2019%2F10%2F29%2Finsurance%2F</url>
    <content type="text"><![CDATA[聊聊学的保险知识 保险保险就是通过向保险公司缴纳一定的钱，如果出问题了，保险公司赔付给你，以保证生活经济不受损失。保险简单分类来讲，分为两类，一类是消费型保险，另一类是返还型保险。 保险三大件 保障责任 保额 期限 消费型保险就是花了钱，保证一部分东西，消费了就是消费了，这些钱不会返回过来。特点是花的钱少，保证的东西值。就是每个人出一部分钱给保险公司，如果某个人生了大病，需要一大笔钱，那么保险公司就把这些钱给这个生病的人，帮助度过难关。这就是保险的作用。 返还型保险消费型保险的话，你交50就完事了，但是返还型保险的话，你得交550。其中50块钱用来保证交保险人的权益，剩余的500块钱拿去投资了。等过10年或者20年，把你的交的钱还给你。随着通货膨胀和投资的收益肯定到最后大于550元，然后收益就归保险公司所有了，你十年前的10块钱和十年后的10块钱肯定不一样。 总结所以买保险推荐买消费型的，这就是保险的本质啊。 保险种类重疾险 为了不被改变的人生罹患重大疾病作为保障责任。重大疾病：保监会定义了25种重大疾病，其发生概率超过95%的疾病种类罹患：有三种情况，一、病情达到某个标准，相当于确诊即赔。二、投保人为治疗某种疾病而接受了某种治疗方法。三、某种状态持续了一段时间。 重疾险除了重大疾病，还包括哪些？新增的责任一：身故责任，身故和重疾谁先发生，就付哪个。新增的责任二：轻疾和中疾责任。新增的责任三：针对重大疾病的花样赔付。 道理：所有的赔付方式都是对风险的定价，然后把溢价加到原有价格中。选择重大疾病险时，最重要的是做到保额满足需要。 保额：重疾险至少覆盖投保人3~5年的收入。假设投保人年薪10万，那么保额至少应该是30~50万。保障多久：终身或者70岁左右的长期产品。预算充足（保终身最好) 定期寿险 解决人生中最大的风险定期寿险的保额： 债务（房贷、车贷); 生活基本成本(以负担家庭未来5-10年的基本生活开销)； 父母的养老支出 123456例如房贷：200万车贷：20万家庭5年开支合计：15万*5=75万父母年龄60岁，按照85岁的预计寿命，养老金每人每年4万，25*4*2=200万合计：495万 保障多久：建议60岁后70岁，退休年龄为准。缴费年限：20年或30年交即可，缴费年限越长，年均保费越低。 选购产品注意：一、一定要弄清楚投保要求再买。核保是否宽松二、除外责任多不多 哪些他们不负责三、价格低不低 疾病占死亡原因79.3% 意外占死亡原因18.9%。 减额定期寿险应用场景：仅限于房贷。保额越来越低 商业医疗险 高额医疗开支医保：不限制参保人员，永不停售。商业医疗保险：谁交钱谁享受，不交钱不享受。第一种：包含门诊责任的商业医疗保险，保额不高，一般几千元。第二种：包含住院责任的商业医疗保险，保额高。 重疾险和商业医疗的区别：保险公司的理赔方式不一样。重疾险有点像一锤子买卖，只要符合条款规定，保险公司就会把理赔款一次性打给你。商业医保花多少赔多少，保额仅代表可报销额度的上限。 如果一个人罹患影响生活的重大疾病，那他主要面临的问题有两个一：治疗费太高二：无法继续工作，失去收入第一个靠商业医疗险解决第二个靠重疾险解决两类的保险的功能不一样 意外险 不容忽视的“小”保险 意外险只保障由于意外导致的身故。如果是意外造成的死亡，就赔；如果是疾病造成的死亡，则不赔。 配置意外险的几条原则一、必须涵盖意外医疗责任。意外险保障的责任有三个必选项：身故、伤残、医疗。二、一般意外身故的保额应足够高。(一般意外事故10万、航空意外事故100万，这个10万保额不够高)三、不同人群的意外险，侧重点不一样。四、保障时间一年就够了。 个性化定制方案如何给孩子买保险孩子参加政府医保，参考当地的医保政策为孩子办理少儿医保。必须孩子出生后尽快办，门诊和住院起付线多少？报销比例多少？ 孩子面临风险一、身患危重疾病(配置重疾险和高保额住院医疗险)二、发生意外受伤（意外险)三、身患一般疾病 (这个没事，花费不大) 配置儿童商业保险也就是三个保险 重大疾病险、意外险、高额住院医疗险配置重疾险，抓住价格优势，尽可能提高保额，拉长期限，避免买个重疾险，最后买了个保险大礼包 如何给父母买保险不用考虑定期寿险需要考虑重疾险、医疗险、意外险。以高保额的住院医疗险为主，住院医疗险保额不受年龄限制，选一个续保条件好、保额高、责任全的住院医疗险比买重疾险更划算。 说的也不是很详细，简单说几点吧一、确保父母双方都有社会医疗保险。不管是城市的居民医保，还是农村的“新农合”，没有的话，赶紧把社会医保办好二、遇到疑难杂症，不少人会选择带父母来北上广等大城市就诊。所以，请求研究好医保的异地结算流程，确保不让医保“白交”，这一点非常有必要。三、详细了解爸妈的身体健康情况，对症下游买保险。 如何给自己买保险其他罹患重大疾病，可以靠重大疾病险和医疗险来解决英年早逝，可以靠定期寿险和意外险 中国养老的三个支柱一、政府养老金二、企业年金、职业年金(基本上只有效益好的国企、央企)三、包含税延养老金在内的商业养老保险 推荐&amp;参考资料一个通俗易懂的故事，把五类保险都讲透了。《你的第一本保险指南》]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA 切面 AOP(Aspect Oriented Programming)]]></title>
    <url>%2Fposts%2Fjava%2F2019%2F10%2F23%2Fjava-aop%2F</url>
    <content type="text"><![CDATA[AOP AOP (Aspect Oriented Programming) 面向切面编程。感觉名字吊的不行，其实也就那样。说下自己的理解：其实就是不侵入业务代码，针对业务代码做的一些操作。做的这些操作也是写的一些代码,写的这些代码和业务代码一起编译的时候，这些代码就会找到业务代码中具体的位置，植入到业务代码中，最终编译成JAVA的字节码，就可以实现相应的功能。 概念只是概念，动手操作，才能加深理解。 使用下载spring https://start.spring.io 解压&amp;idea 打开 写业务代码 用户登录的service 1234567891011121314package com.example.demoaop;import org.springframework.stereotype.Service;/** * @author xinpeng.guo * @date 2019-10-22 10:06 */@Servicepublic class LoginService &#123; public void login(String user) &#123; System.out.println( user + " login"); &#125;&#125; Application.java 12345678910111213141516package com.example.demoaop;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ApplicationContext;@SpringBootApplicationpublic class DemoaopApplication &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = SpringApplication.run(DemoaopApplication.class, args); LoginService loginService = applicationContext.getBean(LoginService.class); loginService.login("root"); &#125;&#125; 执行 执行结果 定义切面想要登录成功之后打个日志 pom 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 切面类ServiceAspect123456789101112131415161718package com.example.demoaop;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.Aspect;import org.springframework.stereotype.Service;/** * @author xinpeng.guo * @date 2019-10-22 10:14 */@Aspect@Servicepublic class ServiceAspect &#123; @AfterReturning("execution(public void LoginService.login(String))") public void log() &#123; System.out.println("log"); &#125;&#125; 执行结果 LoginService 输出 root login ServiceAspect 输出 log 详解很清楚看到ServiceAspect.java是和业务代码分离，但是能够起到在业务代码中编写的作用。实际上的原理就是java是编译执行的语言，在编译的时候，把这个切面的代码按照规则插入到业务代码中。这样生成的字节码，就可以执行切面的代码了。 其中重要的有几个点 定义的切面类，要引入两个注解，一个是 @Aspect 用来定义这个类是切面类，另一个是@Service 用来说明是一个bean。 定义的方法名可以是任意的 log() 注解 @AfterReturning 表示执行这个方法的时机，方法返回之后在执行，那是什么方法呢？ 具体方法定义为 (``&quot;execution(public void LoginService.login(String))&quot;``) 就是在执行 这个方法的时候。 总结：把切面类中的方法放在指定类，指定时机执行。 触发时机 这个触发时机，就是切面的代码植入到业务代码哪个部分。 Before After Around AfterReturning AfterThrowing Before Run advice before the a method execution.在一个方法前执行 1234@Before("execution(public void LoginService.login(String))")public void beforeExec() &#123; System.out.println("@Before 在方法前执行");&#125; After Run advice after the method execution, regardless of its outcome.不管方法是否成功，都会在方法结束后执行 1234@After("execution(public void LoginService.login(String))")public void afterExec() &#123; System.out.println("@After 在执行方法后执行");&#125; Around Run advice before and after the advised method is invoked.写调用函数，然后想怎么写其他逻辑就怎么写其他逻辑 123456@Around("execution(public void LoginService.login(String))")public void round(ProceedingJoinPoint point) throws Throwable&#123; System.out.println("@Around 环绕开始"); point.proceed(); //执行目标方法 System.out.println("@Around 环绕结束");&#125; 这里引入了ProceedingJoinPoint，这个方法中有proceed()方法，就是直接调用对应的函数。 自己试一下这些代码，对理解起来非常有帮助 其实这个代码是有问题的？如果有返回值呢，咋办？ 12345678@Around("execution(public void LoginService.login(String))")public void round(ProceedingJoinPoint point) throws Throwable&#123; Object result = null; System.out.println("@Around 环绕开始"); point.proceed(); //执行目标方法 System.out.println("@Around 环绕结束"); return result;&#125; AfterReturning Run advice after the a method execution only if method completes successfully.只有在方法执行成功后，才会执行 1234@AfterReturning("execution(public void LoginService.login(String))")public void afterReturn() &#123; System.out.println("@afterReturn 在执行方法结束 该方法必须是成功执行的");&#125; AfterThrowing Run advice after the a method execution only if method exits by throwing an exception.当方法抛出异常时，才会执行该方法 1234@AfterThrowing("execution(public void LoginService.login(String))")public void afterThrow() &#123; System.out.println("@afterThrow 在抛出异常时执行");&#125; 总结这些都是触发的时机，按照英文原来的意思就是advice，advice分为以下5种 Before After Around AfterReturning AfterThrowing 大部分文档advice翻译过来称作增强，增强分几种，就是上面这5种。大概意思也就清楚了，这5中增强指的是什么时机增强，什么情况下触发。这种切面的方式就非常好了，可以统一操作，也不用切入业务代码，非常好玩。 上面的这些例子都是指定的方法execution(public void LoginService.login(String))当然除了这些指定，还有更丰富的指定玩法。 指定规则在上面的例子中可以看到execution(public void LoginService.login(String)) 当然除了这样的方式更丰富的方式 execution within target this args execution通过方法签名定义切点 execution(public * *(..))匹配所有目标类的public方法。 第一个代表返回类型，第二个代表方法名，而..代表任意入参的方法 execution(* *To(..)) 匹配目标类所有以To为后缀的方法。 第一个代表返回类型，而To代表任意以To为后缀的方法。 12345// log为开头@After("execution(* log* (..))") public void after() &#123; System.out.println("xxxx"); &#125; 通过类定义切点 execution(* LoginService.*(..))匹配Cleaner接口的所有方法（包括实现类中覆写的方法）， 第一个* 代表返回任意类型 ，LoginService.*代表Cleaner接口中的所有方法 1234@After("execution(* LoginService.* (..))")public void after() &#123; System.out.println("xxxx");&#125; 通过类包定义切点 在类名模式串中，.*表示包下的所有类，..*表示包、子孙包下的所有类 execution(* com.xgj.*(..))匹配com.xgj包下所有类的所有方法 execution(* com.xgj..*(..))匹配com.xgj包、子孙包下所有类的所有方法.比如 com.xgj.dao ,com.xgj.service,com.xgj.dao.user包下所有类的所有方法都匹配。 当 ..出现在类名中时，必须后面跟*表示子孙包下的所有类。 execution(* com..*Dao.find*(..))匹配包名前缀为com的任何包下类名后缀为Dao的方法，方法名必须以find为前缀， 比如com.xgj.UserDao#findUserById()方法都是匹配切点。 1234@After("execution(* com.example..* (..))")public void after() &#123; System.out.println("xxxx");&#125; 参考资料https://docs.spring.io/spring/docs/current/spring-framework-reference/core.html#aop]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA锁-Synchronized]]></title>
    <url>%2Fposts%2Fjava%2F2019%2F07%2F07%2Fjava-synchronized%2F</url>
    <content type="text"><![CDATA[聊聊java锁 最近在学习java，因为公司所有的项目都在java化，抛弃世界上最好的语言PHP，来学习在java也还是很不错的。 毕竟唯一不变的就是变化，有变化才有成长。 背景JAVA是并发编程，存在多线程，存在共享数据（临界资源）。多线程操作共享数据（临界资源）就会出现问题。 Thread A 第一步和 Thread B第一步是同时的就会导致数据错乱。 假设i是访问量，则访问量数据就是错的。 synchronized 两个线程同时操作临界资源 使用 修饰方法&amp;修饰代码块修饰方法 多个线程操作一个实例123456789101112131415161718192021222324252627public class AccountingSync implements Runnable&#123; /* 共享资源(临界资源) */ static int i=0; public void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AccountingSync instance=new AccountingSync(); // 操作同一个实例 Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); // &#125;&#125; 多个线程操作一个实例，该实例中static i 是实例共享的，对共享数据进行并发操作会出现数据错乱 原因就是最开始的讲述的。所以最后的数据 i的是小于2000000。如果对实例方法加synchronized关键字呢？ 修饰方法 多个线程操作一个实例 synchronized 修饰实例方法123456789101112131415161718192021222324252627public class AccountingSync implements Runnable&#123; /* 共享资源(临界资源) */ static int i=0; public synchronized void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AccountingSync instance=new AccountingSync(); // 操作同一个实例 Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 多个线程操作一个实例，该实例中static i 是实例共享的，synchronized修饰的是实例方法，因为只有一个实例，并且对该实例方法加了锁所以最后的数据 i是2000000。在这里是多个线程操作的是同一个实例，如果操作不同的实例呢？ 修饰方法 多个线程操作不同的实例， synchronized修饰实例方法1234567891011121314151617181920212223242526public class AccountingSync implements Runnable&#123; /* 共享资源(临界资源) */ static int i=0; public synchronized void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 不同线程操作不同的实例 Thread t1=new Thread(new AccountingSync()); Thread t2=new Thread(new AccountingSync()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 结果小于2000000，原因是一个对象可以有多个实例，不同线程操作不同实例，锁的粒度依然是实例维度，而不是对象维度，但是现在是多个线程操作不同的实例，所以锁根本对临界资源（共享资源）没有发挥作用。 如果是修饰的是静态方法呢？ 修饰方法 多个线程操作不同的实例， synchronized修饰静态方法1234567891011121314151617181920212223242526public class AccountingSync implements Runnable&#123; /* 共享资源(临界资源) */ static int i=0; public synchronized static void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 不同线程操作不同的实例 Thread t1=new Thread(new AccountingSync()); Thread t2=new Thread(new AccountingSync()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 多个线程操作多个实例，大家都知道一个对象可以有很多个实例，但是静态变量静态方法只有一个，所以这里直接synchronized修饰静态方法，是完全生效的，静态方法只有一个，所以对临界资源（共享资源）操作前是加锁的，保证了临界资源正确性。 除了用synchronized修饰方法，还是可以用来修饰代码块的，接下来看如果实现上面类似的功能，用synchronized修饰代码块如何实现呢？ 修饰代码块 synchronized修饰代码块 作用于实例12345678910111213141516171819202122232425public class AccountingSync implements Runnable&#123; /* 共享资源(临界资源) */ static int i=0; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; synchronized(this) &#123; i++; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AccountingSync instance=new AccountingSync(); // 操作同一个实例 Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 多个线程操作的是同一个实例，synchronized修饰的是this，this表示的只是当前实例。由于多个线程操作的是同一个实例，在整个过程中，只有一个实例；this修饰的是实例，所以也保证了临界资源的正确性。 如果是多个线程操作不同实例呢，那这个代码肯定就不行了，接下来看下这种情况如何使用synchronized。 修饰代码块 synchronized修饰代码块 作用于对象12345678910111213141516171819202122232425public class AccountingSync implements Runnable&#123; /* 共享资源(临界资源) */ static int i=0; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; synchronized(AccountingSync.class) &#123; i++; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AccountingSync instance=new AccountingSync(); // 操作同一个实例 Thread t1=new Thread(new AccountingSync()); Thread t2=new Thread(new AccountingSync()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 多个线程操作多个实例，这些实例都属于一个对象。所以直接这样修饰就可以了synchronized(AccountingSync.class) 解读字节码 JVM是基于进入和退出monitor对象来实现的同步，无论是显示同步还是隐式同步。显示同步是指 synchronized修饰的是代码块 是基于monitorenter 和 monitorexit 指令来实现隐式同步是指 synchronized修饰的是方法 是基于ACC_SYNCHRONIZED实现1234567891011public class Sync &#123; public void test1() &#123; synchronized(this) &#123; System.out.println("test1 method"); &#125; &#125; public synchronized void test2() &#123; System.out.println("ok"); &#125;&#125; java反编译之后代码 javap -v Sync.class1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public Sync(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return LineNumberTable: line 1: 0 public void test1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter // 进入 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String test1 method 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit // 退出 获取锁成功的退出 14: goto 22 17: astore_2 18: aload_1 19: monitorexit // 退出 获取锁失败的退出 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any LineNumberTable: line 3: 0 line 4: 4 line 5: 12 line 6: 22 StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 17 locals = [ class Sync, class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 public synchronized void test2(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED // 标识 Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #5 // String ok 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 9: 0 line 10: 8&#125; 对象头和monitor对象头 对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充实例数据：存放类的属性数据信息，包括父类的属性信息填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍，为了对齐而填充的数据 monitor在JAVA中一切皆对象，任何对象都有一个内部锁或者成为monitor锁在JVM虚拟机中（HotSpot 大部分都是HotSpot）, monitor是由ObjectMonitor实现的，其主要数据结构如下123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //用来记录该线程获取锁的次数 _waiters = 0, _recursions = 0; //锁的重入次数 _object = NULL; _owner = NULL; //指向持有ObjectMonitor对象的线程 _WaitSet = NULL; //存放处于wait状态的线程队列 _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //存放处于等待锁block状态的线程队列 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; 如上图所示，一个线程通过1号门进入Entry Set(入口区)，如果在入口区没有线程等待，那么这个线程就会获取监视器成为监视器的Owner，然后执行监视区域的代码。如果在入口区中有其它线程在等待，那么新来的线程也会和这些线程一起等待。线程在持有监视器的过程中，有两个选择，一个是正常执行监视器区域的代码，释放监视器，通过5号门退出监视器；还有可能等待某个条件的出现，于是它会通过3号门到Wait Set（等待区）休息，直到相应的条件满足后再通过4号门进入重新获取监视器再执行。注意：当一个线程释放监视器时，在入口区和等待区的等待线程都会去竞争监视器，如果入口区的线程赢了，会从2号门进入；如果等待区的线程赢了会从4号门进入。只有通过3号门才能进入等待区，在等待区中的线程只有通过4号门才能退出等待区，也就是说一个线程只有在持有监视器时才能执行wait操作，处于等待的线程只有再次获得监视器才能退出等待状态。 锁类型偏向锁偏向锁是JDK6引进的，通过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是同一个线程获取，为了让线程获取锁的代价更低，引进了偏向锁。 可以看到偏向锁是在对象头中有存储线程ID的，如果与现有的线程ID一致，只需要执行一次CAS（Compare and swap）操作即可，就不会触发轻量级锁，进而降低了锁的代价。 但是如果线程ID不一致，则会升级为轻量级锁。 轻量级锁轻量级锁的目的是 在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。轻量级锁的触发条件 当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁。轻量级锁的依据是 对于绝大部分的锁，在整个生命周期内都是不会存在竞争的。 主要原理是靠下面这种自旋锁来解决的123456while (true) &#123; if (getLock()) &#123; // get lock and do something &#125; // i++ or sleep 来保证退出循环&#125; 重量级锁Synchronized是通过对象内部的一个叫做监视器（Monitor）来实现的。但是监视器本质又是依赖于底层操作系统的mutex lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转为内核态，这个成本比较高，状态之前的切换需要很长的时间，So， 这种依赖依赖于操作系统Mutex Lock实现的锁称之为重量级锁。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MAC专题】MAC 整理]]></title>
    <url>%2Fposts%2FMAC%2F2019%2F04%2F23%2Fmac%2F</url>
    <content type="text"><![CDATA[【MAC专题】MAC整理 必备的工具 推荐文章 https://medium.com/@elviocavalcante/5-steps-to-improve-your-terminal-appearance-on-mac-osx-f58b20058c84 markdown的编辑工具 macdown 上传图片到七牛 管理手册 dash 终端软件 Iterm2 文件编辑 Sublime Text 安装工具 brew zshrc的配置 export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 charles 注册码 Registered Name: https://zhile.io License Key: 48891cf209c6d32bf4 VIM方向键等长按无效1234567891011sublime2 终端输入defaults write com.sublimetext.2 ApplePressAndHoldEnabled -bool falsesublime3 终端输入defaults write com.sublimetext.3 ApplePressAndHoldEnabled -bool falseVscode 终端输入defaults write NSGlobalDomain ApplePressAndHoldEnabled -bool falseIdea 参考https://gist.github.com/lsd/1e1826907ab7e49c536a]]></content>
      <categories>
        <category>MAC</category>
      </categories>
      <tags>
        <tag>MAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MAC专题】Iterm2]]></title>
    <url>%2Fposts%2FMAC%2F2019%2F04%2F23%2Fmac-iterm2%2F</url>
    <content type="text"><![CDATA[【MAC专题】Iterm2 默认设置 https://medium.com/@elviocavalcante/5-steps-to-improve-your-terminal-appearance-on-mac-osx-f58b20058c84 快捷键Command+D to split the window vertically 垂直切分Command+Shift+Dto split the window horizontally 水平切分]]></content>
      <categories>
        <category>MAC</category>
      </categories>
      <tags>
        <tag>MAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk 中的NR==FNR]]></title>
    <url>%2Fposts%2FLinux%2F2019%2F02%2F22%2Fawk%2F</url>
    <content type="text"><![CDATA[Linux awk NR==FNR 在使用awk的时, 如果能会利用NR==FNR这种方式, 那么可以处理许多情况。计算两个文件的交集, 在一个文件中有，在另一个文件中没有等等。 NR NR The total number of input records seen so far. 123456789101112131415161718192021222324252627$ cat file1abc$ cat file2de$ awk '&#123;print FILENAME, NR, $0&#125;' file1file1 1 afile1 2 bfile1 3 c$ awk '&#123;print FILENAME, NR, $0&#125;' file1 file2file1 1 afile1 2 bfile1 3 cfile2 4 dfile2 5 e$ awk '&#123;print FILENAME, NR, $0&#125;' file2 file1file2 1 dfile2 2 efile1 3 afile1 4 bfile1 5 c FNR FNR The input record number in the current input file. 123456789101112131415161718$ awk '&#123;print FILENAME, NR, FNR, $0&#125;' file1file1 1 1 afile1 2 2 bfile1 3 3 c$ awk '&#123;print FILENAME, NR, FNR, $0&#125;' file1 file2file1 1 1 afile1 2 2 bfile1 3 3 cfile2 4 1 dfile2 5 2 e$ awk '&#123;print FILENAME, NR, FNR, $0&#125;' file2 file1file2 1 1 dfile2 2 2 efile1 3 1 afile1 4 2 bfile1 5 3 c NR==FNR12345678910111213141516171819202122232425$ awk 'NR==FNR&#123;print FILENAME, NR, FNR, $0&#125;' file1 file2file1 1 1 afile1 2 2 bfile1 3 3 c# 当条件NR==FNR时，file1文件符合，file2文件不符合，所以只输出了file1文件$ awk 'NR==FNR&#123;a[$0]; print FILENAME, $0&#125;' file1 file2file1 afile1 bfile1 c# 这里a[$0] a是一个数组 将file1中的每行内容，放在了a这个数组中$ awk 'NR==FNR&#123;a[$0];&#125;&#123;print FILENAME, $0&#125;' file1 file2file1 afile1 bfile1 cfile2 dfile2 e# 符合NR==FNR条件才会执行第一个&#123;&#125;中的内容, 第二个&#123;&#125;中内容都会执行$ awk 'NR==FNR&#123;a[$0]; next;&#125;&#123;print FILENAME, $0&#125;' file1 file2file2 dfile2 e# 符合NR==FNR条件才会执行第一个&#123;&#125;，next关键字类似于代码中continue。后面的语句没有执行，只有当NR!=FNR才会执行后面的语句 实践1234567891011$ cat a.txtabcd$ cat b.txtbcde 在a.txt和b.txt中都有1234$ awk 'NR==FNR&#123;a[$0]; next&#125; $0 in a &#123;print FILENAME, $0&#125;' a.txt b.txtb.txt bb.txt cb.txt d 在b.txt中有, a.txt中没有12$ awk 'NR==FNR&#123;a[$0]; next&#125; &#123;if (!($0 in a)) print FILENAME, $0&#125;' a.txt b.txtb.txt e a.txt中有的 b.txt中没有; b.txt中有的 a.txt中没有123$ cat a.txt b.txt | sort -n | uniq -c | awk '&#123;if ($1 == 1) print $2&#125;'ae]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转换字符大小写（Nginx、PHP、Redis源码）]]></title>
    <url>%2Fposts%2F%E7%AE%97%E6%B3%95%2F2019%2F01%2F23%2Fto-lower-upper%2F</url>
    <content type="text"><![CDATA[剖析源码中如何做 Nginx源码中转换字符大小写12345678910/* * 字符范围 十进制表示 二进制表示 * A-Z 65-90 0100 0001 - 0101 1010 * a-z 97-122 0110 0001 - 0111 1010 * 由于0x20(2^6)该位在大写二进制中是0，小写二进制中是1 * 则利用 | 将大写改为小写 * 则利用 &amp; ~0x20 将小写改为大写 */#define ngx_tolower(c) (u_char) ((c &gt;= 'A' &amp;&amp; c &lt;= 'Z') ? (c | 0x20) : c)#define ngx_toupper(c) (u_char) ((c &gt;= 'a' &amp;&amp; c &lt;= 'z') ? (c &amp; ~0x20) : c) Redis源码中转换字符大小写1234567891011121314/* Apply tolower() to every character of the sds string 's'. */void sdstolower(sds s) &#123; int len = sdslen(s), j; //调用C的库函数 for (j = 0; j &lt; len; j++) s[j] = tolower(s[j]);&#125;/* Apply toupper() to every character of the sds string 's'. */void sdstoupper(sds s) &#123; int len = sdslen(s), j; for (j = 0; j &lt; len; j++) s[j] = toupper(s[j]);&#125; PHP源码中转换字符大小写 (strtolower，strtoupper函数具体实现)123456789101112131415161718192021222324252627PHPAPI char *php_strtolower(char *s, size_t len)&#123; unsigned char *c, *e; c = (unsigned char *)s; e = c+len; while (c &lt; e) &#123; *c = tolower(*c); c++; &#125; return s;&#125;PHPAPI char *php_strtoupper(char *s, size_t len)&#123; unsigned char *c, *e; c = (unsigned char *)s; e = (unsigned char *)c+len; while (c &lt; e) &#123; *c = toupper(*c); c++; &#125; return s;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx数据结构之ngx_hash_t]]></title>
    <url>%2Fposts%2Fnginx%2F2019%2F01%2F22%2Fngx-hash%2F</url>
    <content type="text"><![CDATA[Nginx数据结构之ngx_hash_t hash结构在php、redis中均有用到，现在来看看Nginx中的hash是如何用的。 基础代码1234567891011121314151617181920212223242526272829303132//hash 散列表中元素的结构，采用键值及其所对应的值&lt;key, value&gt;typedef struct &#123; void *value; // 指向用户自定义的数组 u_short len; // 键值key的长度 u_char name[1]; // 键值key的第一个字符，数组名name表示指向键值key首地址&#125; ngx_hash_elt_t;//基本hash散列表结构typedef struct &#123; ngx_hash_elt_t **buckets; // 指向hash散列表第一个存储元素的桶 ngx_uint_t size; // hash散列表的桶个数&#125; ngx_hash_t;//添加元素的hash元素结构typedef struct &#123; ngx_str_t key; // 元素关键字 ngx_uint_t key_hash; // 元素关键字计算出的hash值 void *value; // 指向关键字key对应的值，组成hash表元素：&lt;key, value&gt;&#125; ngx_hash_key_t;//初始hash结构typedef struct &#123; ngx_hash_t *hash; // 指向待初始化的基本hash结构 ngx_hash_key_pt key; // hash函数指针 ngx_uint_t max_size; // hash表中桶bucket的最大个数 ngx_uint_t bucket_size; // 每个桶bucket的存储空间 char *name; // hash结构的名称 ngx_pool_t *pool; // 分配hash结构的内存池 ngx_pool_t *temp_pool; // 分配临时数据空间的内存池，仅在初始化hash表前，用于分配一些临时数组&#125; ngx_hash_init_t; 图解 好玩的基础函数ngx_hash12// key * 31 + c字符串对应ASCII数值#define ngx_hash(key, c) ((ngx_uint_t) key * 31 + c) ngx_hash_key1234567891011121314//计算字符串对应的hash值ngx_uint_tngx_hash_key(u_char *data, size_t len)&#123; ngx_uint_t i, key; key = 0; for (i = 0; i &lt; len; i++) &#123; key = ngx_hash(key, data[i]); //((ngx_uint_t) key * 31 + c) 得出的值乘31，在加上当前字符对应ASCII &#125; return key;&#125; ngx_hash_key_lc1234567891011121314//将字符转化为小写，再去计算对应的hash值ngx_uint_tngx_hash_key_lc(u_char *data, size_t len)&#123; ngx_uint_t i, key; key = 0; for (i = 0; i &lt; len; i++) &#123; key = ngx_hash(key, ngx_tolower(data[i])); //((ngx_uint_t) key * 31 + c) 得出的值乘31，在加上当前字符对应ASCII &#125; return key;&#125; ngx_hash_strlow1234567891011121314151617181920/** * 把原始关键字符串的前n个字符转换为小写字母在计算hash值 * 只计算前n个字符的hash值 */ngx_uint_tngx_hash_strlow(u_char *dst, u_char *src, size_t n)&#123; ngx_uint_t key; key = 0; while (n--) &#123; //把src字符串的前n个字符转换为小写字母 *dst = ngx_tolower(*src); key = ngx_hash(key, *dst); // 计算所转换的小写字母的hash值 dst++; src++; &#125; return key; //返回整型的hash值&#125; ngx_tolower12345678910/* * 字符范围 十进制表示 二进制表示 * A-Z 65-90 0100 0001 - 0101 1010 * a-z 97-122 0110 0001 - 0111 1010 * 由于0x20(2^6)该位在大写二进制中是0，小写二进制中是1 * 则利用 | 将大写改为小写 * 则利用 &amp; ~0x20 将小写改为大写 */#define ngx_tolower(c) (u_char) ((c &gt;= 'A' &amp;&amp; c &lt;= 'Z') ? (c | 0x20) : c)#define ngx_toupper(c) (u_char) ((c &gt;= 'a' &amp;&amp; c &lt;= 'z') ? (c &amp; ~0x20) : c) 重要函数ngx_hash_find 查找函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * hash查找函数 * * 假设要在hash中找到k是abc对应的值 * @param key是字符串abc计算hash之后的int值 * @param name是字符串abc */void *ngx_hash_find(ngx_hash_t *hash, ngx_uint_t key, u_char *name, size_t len)&#123; ngx_uint_t i; ngx_hash_elt_t *elt;#if 0 ngx_log_error(NGX_LOG_ALERT, ngx_cycle-&gt;log, 0, "hf:\"%*s\"", len, name);#endif //根据key对hash-&gt;size求余 得出索引位置 进而获得buckets中的元素elt elt = hash-&gt;buckets[key % hash-&gt;size]; if (elt == NULL) &#123; return NULL; &#125; //索引位置有值 while (elt-&gt;value) &#123; //先判断长度是否相等 发现php源码中也有这样的比较 if (len != (size_t) elt-&gt;len) &#123; goto next; &#125; //循环key的每个字符 // * 假设要在hash中找到k是abc对应的值 // * @param key是字符串abc计算hash之后的int值 // * @param name是字符串abc for (i = 0; i &lt; len; i++) &#123; if (name[i] != elt-&gt;name[i]) &#123; goto next; &#125; &#125; return elt-&gt;value; next: //由于ngx解决hash冲突时用的开发地址法 //向后遍历元素 elt = (ngx_hash_elt_t *) ngx_align_ptr(&amp;elt-&gt;name[0] + elt-&gt;len, sizeof(void *)); continue; &#125; return NULL;&#125; 源码注解：https://github.com/gxpisme/read_nginx/commit/04d638f7da21ca6669efbf06ce1086c94e95c9ce]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx数据结构之ngx_array_t]]></title>
    <url>%2Fposts%2Fnginx%2F2019%2F01%2F16%2Fngx-array%2F</url>
    <content type="text"><![CDATA[Nginx数据结构之ngx_array_t 动态数组 在Nginx数组中，内存分配是基于内存池的，并不是固定不变的。当存储的元素越来越多，内存不够时会扩容，以当前的长度的2倍扩容。 数据结构定义代码12345678// 动态数组typedef struct &#123; void *elts; //elts指向数组的首地址 ngx_uint_t nelts; //nelts数组中已经使用的元素个数 size_t size; //每个数组元素占用的内存大小 ngx_uint_t nalloc; //当前数组中能够容纳元素的总大小 ngx_pool_t *pool; //内存池对象&#125; ngx_array_t; 图解 基础ngx_array_init 初始化1234567891011121314151617181920212223//初始化static ngx_inline ngx_int_tngx_array_init(ngx_array_t *array, ngx_pool_t *pool, ngx_uint_t n, size_t size)&#123; /* * set "array-&gt;nelts" before "array-&gt;elts", otherwise MSVC thinks * that "array-&gt;nelts" may be used without having been initialized */ //初始化数组成员，注意：nelts必须比elts先初始化 array-&gt;nelts = 0; array-&gt;size = size; array-&gt;nalloc = n; array-&gt;pool = pool; //分配数组数据所需要的内存 array-&gt;elts = ngx_palloc(pool, n * size); if (array-&gt;elts == NULL) &#123; return NGX_ERROR; &#125; return NGX_OK;&#125; ngx_array_create 创建动态数组对象12345678910111213141516171819//创建动态数组对象ngx_array_t *ngx_array_create(ngx_pool_t *p, ngx_uint_t n, size_t size)&#123; ngx_array_t *a; //分配动态数组头部 a = ngx_palloc(p, sizeof(ngx_array_t)); if (a == NULL) &#123; return NULL; &#125; //分配容量为n 动态数组数据区 并将其初始化 if (ngx_array_init(a, p, n, size) != NGX_OK) &#123; return NULL; &#125; return a;&#125; ngx_array_destroy 销毁数组对象123456789101112131415161718//销毁数组对象，即数组所占据的内存被内存池回收voidngx_array_destroy(ngx_array_t *a)&#123; ngx_pool_t *p; p = a-&gt;pool; //移动内存池的last指针，释放数组所有元素所占据的内存 if ((u_char *) a-&gt;elts + a-&gt;size * a-&gt;nalloc == p-&gt;d.last) &#123; p-&gt;d.last -= a-&gt;size * a-&gt;nalloc; &#125; //释放数组首指针所占据的内存 if ((u_char *) a + sizeof(ngx_array_t) == p-&gt;d.last) &#123; p-&gt;d.last = (u_char *) a; &#125;&#125; ngx_array_push 添加一个元素12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152void *ngx_array_push(ngx_array_t *a)&#123; void *elt, *new; size_t size; ngx_pool_t *p; if (a-&gt;nelts == a-&gt;nalloc) &#123; /* the array is full 数组满了 */ //所有元素占用的内存大小 size = a-&gt;size * a-&gt;nalloc; p = a-&gt;pool; if ((u_char *) a-&gt;elts + size == p-&gt;d.last &amp;&amp; p-&gt;d.last + a-&gt;size &lt;= p-&gt;d.end) &#123; /* * 若当前内存池的内存空间至少可容纳一个元素大小 * the array allocation is the last in the pool * and there is space for new allocation */ p-&gt;d.last += a-&gt;size; a-&gt;nalloc++; &#125; else &#123; /* allocate a new array 分配新的数组内存*/ //新的数组内存是现有的2倍 new = ngx_palloc(p, 2 * size); if (new == NULL) &#123; return NULL; &#125; //首先把现有数组的所有元素复制到新的数组中 ngx_memcpy(new, a-&gt;elts, size); //数组的首地址 a-&gt;elts = new; //容纳元素的总大小 a-&gt;nalloc *= 2; &#125; &#125; elt = (u_char *) a-&gt;elts + a-&gt;size * a-&gt;nelts; a-&gt;nelts++; //返回指向新增加元素的指针 return elt;&#125; 代码注释 https://github.com/gxpisme/read_nginx/commit/663a1aa7d885fd564c58d1a1092a20ebd08cad80]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx数据结构之ngx_queue_t]]></title>
    <url>%2Fposts%2Fnginx%2F2019%2F01%2F14%2Fngx-queue%2F</url>
    <content type="text"><![CDATA[Nginx数据结构之ngx_queue_t ngx_queue_t是具有头结点的双向链表结构链表作为顺序容器的优势，高效插入、删除、合并操作优势 实现了排序功能 非常轻量级，是一个纯粹的双向链表，他不负责链表所占内存的分配 支持链表合并 初始结构代码展现12345678910111213/** * 队列结构，其实质是具有头节点的双向循环链表 */typedef struct ngx_queue_s ngx_queue_t;/** * 队列中每个节点结构，只有两个指针，并没有数据区 */struct ngx_queue_s &#123; ngx_queue_t *prev; ngx_queue_t *next;&#125;; 图解 基础宏ngx_queue_init 代码1234567/** * q为链表容器结构体ngx_queue_t的指针 * 链表容器q初始化，会设置为空的链表 */#define ngx_queue_init(q) \ (q)-&gt;prev = q; \ (q)-&gt;next = q ngx_queue_init 图解 ngx_queue_empty 代码12345/** * 检测链表容器是否为空 */#define ngx_queue_empty(h) \ (h == (h)-&gt;prev) ngx_queue_insert_head 代码12345678910/** * 将元素x，插入h链表的头部 */#define ngx_queue_insert_head(h, x) \ (x)-&gt;next = (h)-&gt;next; \ (x)-&gt;next-&gt;prev = x; \ (x)-&gt;prev = h; \ (h)-&gt;next = x#define ngx_queue_insert_after ngx_queue_insert_head ngx_queue_insert_head 图解 ngx_queue_insert_tail 代码12345678/** * 将元素x，插入h链表的尾部 */#define ngx_queue_insert_tail(h, x) \ (x)-&gt;prev = (h)-&gt;prev; \ (x)-&gt;prev-&gt;next = x; \ (x)-&gt;next = h; \ (h)-&gt;prev = x ngx_queue_insert_tail 图解 ngx_queue_split 代码123456789101112/** * h为链表容器结构体ngx_queue_t的指针 该函数用于拆分链表 * h是链表容器，而q是链表h中的一个元素。 * 将链表h以元素q为界拆分成两个链表 h 和 n */#define ngx_queue_split(h, q, n) \ (n)-&gt;prev = (h)-&gt;prev; \ (n)-&gt;prev-&gt;next = n; \ (n)-&gt;next = q; \ (h)-&gt;prev = (q)-&gt;prev; \ (h)-&gt;prev-&gt;next = h; \ (q)-&gt;prev = n; ngx_queue_split 图解 ngx_queue_add 代码123456789/** * h为链表容器结构体ngx_queue_t的指针，n为另一个链表容器结构体ngx_queue_t的指针 * 合并链表，将n链表添加到h链表的末尾 */#define ngx_queue_add(h, n) \ (h)-&gt;prev-&gt;next = (n)-&gt;next; \ (n)-&gt;next-&gt;prev = (h)-&gt;prev; \ (h)-&gt;prev = (n)-&gt;prev; \ (h)-&gt;prev-&gt;next = h; ngx_queue_add 图解 基础宏代码123456789101112131415161718192021222324252627/** * 链表的头元素 */#define ngx_queue_head(h) \ (h)-&gt;next/** * 链表的尾元素 */#define ngx_queue_last(h) \ (h)-&gt;prev#define ngx_queue_sentinel(h) \ (h)/** * 链表的后一个元素 */#define ngx_queue_next(q) \ (q)-&gt;next/** * 链表的前一个元素 */#define ngx_queue_prev(q) \ (q)-&gt;prev 函数ngx_queue_middle 代码12345678910111213141516171819202122232425262728293031323334353637383940/** * 找中间元素 */ngx_queue_t *ngx_queue_middle(ngx_queue_t *queue)&#123; ngx_queue_t *middle, *next; //链表的头元素 middle = ngx_queue_head(queue); //链表的头元素与尾元素相等，则就一个元素，返回该元素即可 if (middle == ngx_queue_last(queue)) &#123; return middle; &#125; //这里也是头元素 next = ngx_queue_head(queue); //开始循环 //1.采用了每循环一次，middle向后移一个指针 //2.每循环一次，next向后移动两个指针 //3.middle走一步，next走两步，当next走到尾元素，则正好输出middle，完美 for ( ;; ) &#123; //从头元素开始，middle依次向后，每循环一次，向后移一个指针 middle = ngx_queue_next(middle); //也是从头元素开始，next，每循环一次，向后移动两个指针 //next每移动一次之后，要判读next与最后一个元素是否相等 next = ngx_queue_next(next); if (next == ngx_queue_last(queue)) &#123; return middle; &#125; next = ngx_queue_next(next); if (next == ngx_queue_last(queue)) &#123; return middle; &#125; &#125;&#125; ngx_queue_sort 排序代码12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 无须的双向链表，排序成有序的双向链表 很好玩，很精妙的逻辑 */voidngx_queue_sort(ngx_queue_t *queue, ngx_int_t (*cmp)(const ngx_queue_t *, const ngx_queue_t *))&#123; ngx_queue_t *q, *prev, *next; //链表的头元素 q = ngx_queue_head(queue); //头元素等于尾元素 if (q == ngx_queue_last(queue)) &#123; return; &#125; //从头元素向后循环 for (q = ngx_queue_next(q); q != ngx_queue_sentinel(queue); q = next) &#123; //向前遍历 prev = ngx_queue_prev(q); //向后遍历 next = ngx_queue_next(q); //移除q元素 ngx_queue_remove(q); //该循环保证了，q大于prev的最大值，一定q放在了最大值prev的后面 do &#123; //当q大于prev时，退出循环 if (cmp(prev, q) &lt;= 0) &#123; break; &#125; prev = ngx_queue_prev(prev); &#125; while (prev != ngx_queue_sentinel(queue)); //将q元素插入在prev的后面，保证q元素大于prev ngx_queue_insert_after(prev, q); &#125;&#125; 代码注释 https://github.com/gxpisme/read_nginx/commit/4bd1d147dd92d8c93ad89a53236c7309484c5940]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx数据结构之ngx_list_t]]></title>
    <url>%2Fposts%2Fnginx%2F2019%2F01%2F08%2Fngx-list%2F</url>
    <content type="text"><![CDATA[Nginx数据结构之ngx_list_t ngx_list_t是Nginx封装的链表容器，他在Nginx中使用得很频繁。与普通链表不同，不同点就在于它的节点，它的节点不像我们常见的list的节点，只能存放一个元素，ngx_list_t的节点实际上是一个固定大小的数组。 结构定义如下12345678910111213141516typedef struct ngx_list_part_s ngx_list_part_t;struct ngx_list_part_s &#123; void *elts; // 节点中存放具体元素的内存的开始地址。 ngx_uint_t nelts; // 节点中已有元素个数。这个值是不能大于链表头节点ngx_list_t类型中的nalloc字段的。 ngx_list_part_t *next;&#125;;typedef struct &#123; ngx_list_part_t *last; // 指向该链表的最后一个节点 ngx_list_part_t part; // 该链表的首个存放具体元素的节点 size_t size; // 数组存储的是某种类型的数据结构，且ngx_list_t是非常灵活的数据结构，只是通过size限制每一个数组元素占用空间的大小 ngx_uint_t nalloc; // 每个节点所含的固定大小的数组的容量。 ngx_pool_t *pool; // 该list使用的分配内存的pool。&#125; ngx_list_t; 图解结构 解释 ngx_list_t中的pool内存池为其分配了连续的内存 最前端内存存储ngx_list_t结构体的成员 紧接着是第一个ngx_list_part_t结构占用的内存 然后是ngx_list_part_t结构指向的数组，共占用size*nalloc字节，表示数组中拥有nalloc个大小为size的元素 其后面2个ngx_list_part_t结构以及它所指向的数组，依次类推。 Nginx提供的接口ngx_list_create 创建新的链表1234567891011121314151617181920212223/* * ngx_list_create 创建元素时， * pool参数是内存池对象 * n是每个链表可容纳元素的个数 相当于ngx_list_t结构中nalloc成员 * size是每个元素的大小 * * 返回 包含n个大小为size字节的连续内存块，也就是ngx_list_t结构中的part成员 */ngx_list_t * ngx_list_create(ngx_pool_t *pool, ngx_uint_t n, size_t size)&#123; ngx_list_t *list; list = ngx_palloc(pool, sizeof(ngx_list_t)); if (list == NULL) &#123; return NULL; &#125; if (ngx_list_init(list, pool, n, size) != NGX_OK) &#123; return NULL; &#125; return list;&#125; ngx_list_init 初始化已有的链表1234567891011121314151617static ngx_inline ngx_int_t ngx_list_init(ngx_list_t *list, ngx_pool_t *pool, ngx_uint_t n, size_t size)&#123; list-&gt;part.elts = ngx_palloc(pool, n * size); //内存的开始地址 if (list-&gt;part.elts == NULL) &#123; return NGX_ERROR; &#125; list-&gt;part.nelts = 0; list-&gt;part.next = NULL; list-&gt;last = &amp;list-&gt;part; list-&gt;size = size; list-&gt;nalloc = n; list-&gt;pool = pool; return NGX_OK;&#125; ngx_list_push 添加新的元素12345678910111213141516171819202122232425/** * ngx_list_push 表示添加新的元素，传入的参数是ngx_list_t链表 * 正常情况下，返回的是新分配的元素首地址 * 如果返回NULL空指针，则添加失败 * 在使用它时通常先调用ngx_list_push得到返回的元素地址，再对返回的地址进行赋值 */void * ngx_list_push(ngx_list_t *l)&#123; void *elt; ngx_list_part_t *last; last = l-&gt;last; //存储list的内存满了 有兴趣看源码 如何做的 if (last-&gt;nelts == l-&gt;nalloc) &#123; .... /* the last part is full, allocate a new list part */ .... &#125; elt = (char *) last-&gt;elts + l-&gt;size * last-&gt;nelts; last-&gt;nelts++; return elt;&#125; 遍历链表的demo12345678910111213141516171819202122232425the iteration through the list:part = &amp;list.part; // part用于指向链表中的每一个ngx_list_part_t数组data = part-&gt;elts; // 根据链表中的数据类型，把数组里的elts转化为该类型使用// i表示元素在链表的每个ngx_list_part_t数组里的序号for (i = 0 ;; i++) &#123; if (i &gt;= part-&gt;nelts) &#123; // 地址 if (part-&gt;next == NULL) &#123; //如果某个ngx_list_part_t数组的next指针为空，则说明遍历完链表 break; &#125; // 访问下一个ngx_list_part_t part = part-&gt;next; data = part-&gt;elts; 将序号置为0，准备重新访问下一个数组 i = 0; &#125; // 输出每个ngx_list_part_t数组中的元素 ... data[i] ...&#125; 参考文档http://tengine.taobao.org/book/chapter_02.html深入理解Nginx代码注释 https://github.com/gxpisme/read_nginx/commit/48518fd2dcbd862e01bd86ff49ba9f82fe9a430a]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP (Dynamic Host Configuration Protocol)]]></title>
    <url>%2Fposts%2FTCP-IP%2F2018%2F09%2F11%2Fdhcp%2F</url>
    <content type="text"><![CDATA[重要的DHCP 每一个联网的设备都需要设置IP地址，特别是在移动使用笔记本电脑、手机时，每移动一个新的地方，都要重新设置IP地址。为了统一管理IP地址分配，就产生了DHCP (Dynamic Host Configuration Protocol)协议。有了DHCP，计算机只要连接到网络，就可以进行TCP/IP通信。DHCP让即插即用变得可能。 有无DHCP的区别 DHCP工作机制 首先要架设一台DHCP服务器，配置一些必要的信息。分为四步 DHCP discovery DHCP offer DHCP request DHCP acknowledgement 第一步 主机A发送消息，发现DHCP服务器 (DHCP Discovery Server) 第二步 DHCP服务器提供IP给主机A (DHCP Server offer) 第三步 主机A发送消息到DHCP服务器 (DHCP Request) 第四步 DHCP服务器确认消息 (DHCP Acknowledgement) 本文讲述较为简单，深入了解，建议看下参考文献。 参考文献《图解TCP/IP》https://www.youtube.com/watch?v=S43CFcpOZSIhttps://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Address Resolution Protocol (ARP协议)]]></title>
    <url>%2Fposts%2FTCP-IP%2F2018%2F08%2F08%2Farp%2F</url>
    <content type="text"><![CDATA[一起聊聊ARP协议 称为一名合格的工程师，了解TCP/IP是必须的，ARP协议是网络层中非常重要的一个协议，掌握ARP协议也是非常必要的。 为什么会有ARP协议？只要确定了IP地址，就可以向IP地址发送IP数据报。然而，在底层数据链路层，进行实际通信时必须知道每个IP地址对应的MAC地址。 工作在数据链路层， 就得用MAC地址。 由于网络层下一层是数据链路层，在数据链路层需要知道MAC地址。由于知道IP地址通过DNS 域名解析服务器获取IP地址，通过IP地址获取MAC地址，这就是 ARP协议。ARP协议用于找到MAC地址。 ARP协议 工作原理 主机A通过广播发送一个ARP请求包。ARP请求包中包含了想要了解其MAC地址的主机IP地址。 广播的包可以被同一个链路上所有的主机或路由器接受。 若ARP请求包中的目标IP地址与自己的IP地址一致，那么这个节点就将自己的MAC地址塞入ARP响应包返回给主机A。 ARP协议 提高效率 缓存根据ARP可以动态地进行地址解析，因此只要有IP，无需知道MAC地址，也可以实现链路内的IP通信。 若每发送一个IP数据报都要进行一次ARP请求以此确定MAC地址，那会造成必要的网络流量。因此把获取到的MAC地址缓存一段时间。 接受ARP请求的那个主机可以从ARP请求包中获取发送端主机IP和MAC地址。 RARP (Reverse Address Resolution Protocol) RARP是将ARP反过来，从MAC地址定位IP地址的一种协议。用途：例如将打印机服务器等小型嵌入式设备接入到网络时。 平常我们可以通过个人电脑设置IP地址，也可以通过DHCP自动分配获取IP地址。然而对于嵌入式设备时，会遇到没有任何输入接口或无法通过DHCP动态获取IP的情况。 在类似情况下，就可以使用RARP。需要架设一台RARP服务器，从而在这个服务器上注册设备的MAC地址及其IP地址。然后再将这个设备接入到网络，插电启动设备时，该设备会发送一条我的MAC地址是***，请告诉我，我的IP地址是什么？的请求信息。RARP服务器接到这个消息后返回类似于MAC地址为***的设备，IP地址为***&quot;的信息给这个设备。而设备就根据从RARP服务器所收到的应答信息设置自己的IP地址。 参考文献https://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&amp;mid=2665513160&amp;idx=1&amp;sn=d938db4f1a2d62514b57e92fd8d3d749&amp;scene=21#wechat_redirect《图解TCP/IP》]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（Domain Name System）DNS]]></title>
    <url>%2Fposts%2FTCP-IP%2F2018%2F08%2F01%2Fdns%2F</url>
    <content type="text"><![CDATA[一起聊聊DNS hosts文件在网络中，联网的计算机之间都是经过IP地址进行通信的。但是IP地址是一串数字，不容易记忆。 如果每个IP都有一个名字的话，就容易记住了。因此对每个IP地址均有一个名字。例如1234220.181.57.216 zhangsan106.39.167.118 lisi140.205.220.96 wangwu... 在互联网发展早期，上述这些对应信息，存在hosts文件中。联网的计算机本地都有hosts文件，hosts文件的信息由互联网信息中心管理一份完整hosts文件。如果新加入一台计算机，则所有的计算机都需要从互联网信息中心拉取最新hosts文件。 例如：220.181.57.216 zhangsan要向140.205.220.96 wangwu进行通信， zhangsan只知道向wangwu通信，先在hosts文件中查找wangwu对应的IP地址140.205.220.96，然后在向140.205.220.96通信即可。 现在的windows中 C:\Windows\System32\drivers\etc\hosts 文件就是早期互联网发展的产物 随着联网的计算机越来越多，这种集中管理主机名和IP地址的弊端就出现了。 处理的效率低下，由此演化出DNS系统。 名字没有统一管理，后面设计成域名。 DNS 系统DNS系统是维护一个用来表示主机名和IP对应关系的数据库。如果新联网一台主机，只需要将主机名和IP地址在数据库中新增一条记录即可。根据域名查找IP，简单可理解为根据主机名从数据库中获取IP地址。 主机名被设计成域名域名的组成为1主机名.二级域名.顶级域名.根域名 例子： www.xpisme.com真正的域名是www.xpisme.com.root。因为所有的域名后缀都是.root，所以就省略了。 .root是根域名，.com是顶级域名top-level domain，除了.com是顶级域名外，.com、.org、.net、.gov、.edu也是顶级域名。xpisme是二级域名，二级域名是可以申请注册的。www.fourth.blog.xpisme.com .blog是三级域名，.fourth是四级域名，依次类推。www是主机名 host name 练练手URL: http://www.example.net/index.html顶级域名(Top-level domain): net二级域名(Second-level domain): example主机名(Host name): www 域名查找IP地址从浏览器中输入域名，经历了什么，找到了IP地址。都知道中间有很多缓存，具体是哪些缓存，咱们一起剖析一下。 在浏览器中输入xpisme.com域名，首先会找浏览器缓存的DNS信息。以chrome为例，可通过chrome://net-internals/#dns查看。 然后在本机dns缓存中查找。其中hosts文件会加载到内存中，也就是本机dns缓存。查看（windows）本机dns缓存ipconfig/displaydns。 若上面方式没找到。则会在本地DNS服务器查找，DNS服务器的地址。如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 若上面方式没找到。则会在该DNS服务器有缓存服务器查找，若存在IP地址映射，则直接返回，此解析不具有权威性。 若上面方式没找到。则会向13台根DNS域名服务器请求。13台根域名服务器会告诉.com的顶级域名服务器的IP地址。 然后在顶级域名服务器的IP地址查找，顶级域名服务器会告诉xpisme.com的次级域名服务器地址。 找到次级域名服务器地址，找到xpisme.com域名对应的IP地址，则返回。 5、6、7 三步是服务器之间迭代查询的过程。维基百科图片奉上 参考文献http://blog.51cto.com/xuweitao/1911227https://en.wikipedia.org/wiki/Domain_Name_Systemhttp://blog.51cto.com/369369/812889http://www.ruanyifeng.com/blog/2016/06/dns.html]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP协议]]></title>
    <url>%2Fposts%2FTCP-IP%2F2018%2F07%2F31%2Fip%2F</url>
    <content type="text"><![CDATA[一起聊聊IP协议 IP (Internet Protocol)IP相当于OSI参考模型的第3层-网络层网络层的主要作用是“实现终端节点之间的通信”，也称点对点通信，point-to-point。IP主要作用：在复杂的网络环境中将数据包发给最终的目标地址。 IP 地址属于网络层地址 作为网络层的IP，有这种地址信息，叫做IP地址。IP地址用于在”连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在TCP/IP通信中所有主机或路由器必须设定自己的IP地址。 IP属于面向无连接型IP采用无连接型有两点原因：一是为了简化，而是为了提速。IP只负责将数据发给目标主机，那么TCP则负责保证对端主机确实接收到了数据。 IP 地址的定义 IP地址由32位正整数来表示。IP地址在计算机内部以二进制方式被处理，由于人类不习惯采用二进制方式，所以将32位的IP地址每8位分为一组，分成4组，每组以“.”分开，再将每组数转换为十进制数。 IP地址由“网络标识（网络地址）”和“主机标识（主机地址）”两部分组成 IP 地址的分类IP地址共四个字节IP地址分为五类：A类、B类、C类、D类、E类 A 类 A类地址的第一位总是0 A类地址第一个字节为网络地址，其他三个字节为主机地址 IP地址写成二进制的形式如下：A类开始：0000 0000 . 0000 0000 . 0000 0000 . 0000 0000 - 0.0.0.0A类结束：0111 1111 . 1111 1111 . 1111 1111 . 1111 1111 - 127.255.255.255 B 类 B类地址的前两位是10 B类地址前两个字节为网络地址，后两个字节为主机地址 IP地址写成二进制的形式如下：B类开始：1000 0000 . 0000 0000 . 0000 0000 . 0000 0000 - 128.0.0.0B类结束：1011 1111 . 1111 1111 . 1111 1111 . 1111 1111 - 191.255.255.255 C 类 C类地址的前三位是110 C类地址前三个字节为网络地址，最后一个字节为主机地址 IP地址写成二进制的形式如下：C类开始：1100 0000 . 0000 0000 . 0000 0000 . 0000 0000 - 192.0.0.0C类结束：1101 1111 . 1111 1111 . 1111 1111 . 1111 1111 - 223.255.255.255 D 类 D类地址的前四位是1110 从第1位到第32位是它的网络标识。 IP地址写成二进制的形式如下：D类开始：1110 0000 . 0000 0000 . 0000 0000 . 0000 0000 - 224.0.0.0D类结束：1110 1111 . 1111 1111 . 1111 1111 . 1111 1111 - 239.255.255.255 广播地址、IP多播、子网掩码广播地址应用：广播地址用于在同一链路中相互连接的主机之间发送数据包。广播地址：将IP地址中的主机地址全部设置为1，就是广播地址。例如：172.20.0.0用二进制表示10101100 00010100 00000000 00000000B类地址从第1位到第16位是它的网络标识，从17位到第32位是主机地址，将主机地址全部设置为1，就成了广播地址。10101100 00010100 11111111 1111111十进制表示广播地址为 172.20.255.255 广播分为本地广播和直接广播本地广播：在本网络内的广播叫做本地广播，例如网络地址为192.168.0.0/24的情况下，广播地址为192.168.0.255。因为这个广播地址的IP包会被路由器屏蔽，所以不会达到192.168.0.0/24以外的其他链路上。直接广播：在不同的网络之间的广播叫做直接广播。 IP多播同时发送提高效率在人们使用多播功能之前，一直采用广播的方式。广播将数据发给所有的终端主机，再有这些主机IP之上的一层判断是否有必要接受数据。广播这种方式会给那些毫无关系的网络或主机带来影响，造成网络上很多不必要的流量。除此之外广播无法穿透路由，若给其他网段发送同样的包，就不得采用另一种机制。 IP多播与地址多播使用D类地址。 多播地址的可用范围：224.0.0.0 到 239.255.255.255不需要路由控制的范围：224.0.0.0 到 224.0.0.255 子网掩码子网掩码可以将某个IP地址划分成网络地址和主机地址两部分。子网掩码用二进制方式表示的话，也是一个32位的数字，它对应IP地址网络标识部分的位全部为“1”，对应IP地址主机标识的部分全部为“0”。 待优化……]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息认证]]></title>
    <url>%2Fposts%2F%E5%AF%86%E7%A0%81%2F2018%2F07%2F21%2Fcipher%2F</url>
    <content type="text"><![CDATA[单向散列函数、消息认证码、数字签名、证书 消息被篡改 A向B转账1万元 消息在传递的过程中被篡改成了转账100万 如果这条消息”A向B转账1万元”经过函数计算后，得出一个值，暂称为”散列值”，把”散列值”发送给银行。银行也通过函数计算得出一个”散列值”，判断两个散列值是否相等，如果相等则认为消息没有被篡改，如果不相等则消息被篡改。这种函数计算一般就是单向散列函数。 单向散列函数 防止信息被篡改 保证消息完整性 根据任意长度的消息计算出固定长度的散列值 能够快速计算出散列值 消息不同散列值也不同，即使改1比特的数据，散列值完全不一样 具有单向性（不可逆） 单向散列函数能够识别篡改，但无法辨别伪装。消息被伪装 A向B转账1万元，这个消息是A用户发出的吗？还是攻击者伪装成A发送的？ 如果A有密钥，密钥+消息，这两个一起通过单向散列函数计算；银行得到这个消息后，也用密钥+消息，两个一起单向散列函数值计算。 A发送的散列值与B计算得到的散列值是否相同。 其中A和银行使用的密钥是一样的，该密钥又称为共享密钥。 共享密钥只有A和银行知道，这样就可以辨别出伪装了。 消息认证码 消息认证码是一种与密钥相关联的单向散列函数。 密钥配送问题，需要使用公钥密码、Diffie-Hellman密钥交换、密钥分配中心等。 消息认证码无法解决的问题现在国家要对银行每笔交易进行监控，即第三方。那么第三方也要有共享密钥，如果银行冒充用户A，向第三方发送消息了，用户A的钱就少了。实际上用户A无缘无故钱就少了。第三方对你说：我们收到你的转账请求了，银行死不要脸对你说：我们收到你的请求，才会给第三方(国家)说的。 第三方证明 用户A、银行、国家(第三方)。银行直接扣除用户A的钱，银行模拟用户A向国家发送了消息。实际上用户A是无辜的呀，投诉无门，银行咬死说就是用户A发的消息。 中间的问题出现在密钥是共享的，用户、银行、国家都有该密钥。如果用户有密钥A，银行和国家有同一个密钥B，密钥B能对密钥A进行验证，那么就不会出现这样的问题了。 数字签名 数字签名包括生成消息签名&amp;验证数字签名 签名密钥只能签名的人持有（可理解为用户A），验证密钥的人任何人都可持有（理解为银行、国家） 使用非对称加密，但是与正常的非对称加密不同。正常情况下使用的非对称加密： (多个)发送者使用公钥加密，接受者使用私钥解密。数字签名使用的非对称加密：发送者使用私钥加密，(多个)接受者使用公钥解密。 数字签名无法解决的问题要正确使用数字签名，前提是用于验证签名的公钥必须属于真正的发送者。(中间人攻击) 数字签名是用来识别消息篡改、伪装以及否认的，但是为此我们又必须得到真正的公钥才行。 矛盾了，死循环。 发送真正的公钥 未被篡改的公钥 发送者发送公钥、接受者接受公钥，如何保证接受者收到的是正确的公钥，未被篡改过的。数字签名就是解决消息认证的问题，但是需要接受者收到的是真正的公钥。死循环了吧。 公钥证书有认证机构施加数字签名，只要是公钥证书，我们就可以知道认证机构认定该公钥是发送者的、是正确的。 认证机构：能够认定“公钥确实属于此人”并能够生成数字签名的个人或者组织。 证书 消息接收者receiver 生成密钥对 （公钥A，私钥A’） 消息接收者receiver 在认证机构注册自己的公钥 A 认证机构用自己的私钥B’对公钥A进行数字签名，就是证书 消息发送者sender 得到消息接收者receiver的公钥A+数字签名 消息发送者sender 用认证结构的公钥B，验证数字签名是否合法。 消息发送者sender 用接收者receiver的公钥A 加密消息 消息接收者receiver用私钥A’，进行解密]]></content>
      <categories>
        <category>密码</category>
      </categories>
      <tags>
        <tag>密码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSA]]></title>
    <url>%2Fposts%2F%E5%AF%86%E7%A0%81%2F2018%2F07%2F17%2Frsa%2F</url>
    <content type="text"><![CDATA[RSA（非对称加密） 从对称加密到非对称加密对称加密 服务端 使用某一种加密规则，对信息进行加密。 客户端 使用同一种规则，对信息进行解密。这种加密模式有一个最大弱点：服务端必须把加密规则告诉客户端，否则无法解密。保存和传递密钥，就成了最头疼的问题。 Diffie–Hellman key exchange1976年，Whitfield Diffie 和 Martin Hellman，提出Diffie–Hellman key exchange算法，可以在不直接传递密钥的情况下，完成解密。只要服务端和客户端的规则存在某种对应关系即可。 非对称加密 服务端生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的，只有自己知道。 客户端获取服务端的公钥，然后用它对信息加密。 服务端得到加密后的信息，用私钥解密。 RSA来源 RSA加密算法是一种非对称加密算法。在公开密钥加密和电子商业中RSA被广泛使用。RSA是1977年由Ron Rivest、Adi Shamir、Leonard Adleman 一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的。 RSA基本原理$密文=明文^E mod N$ RSA加密 明文的E次方对N求余就是密文$明文=密文^D mod N$ RSA解密 密文的D次方对N求余就是明文 E是(Encrytion)的首字母D是(Decrytion)的首字母N是(Number)的首字母 公钥就是{E,N} 密钥就是{D,N} 公钥{E,N}和密钥{D,N}的生成步骤 求N 求L（L仅在过程中使用的数） 求E 求D N有互质关系的两个数的乘积，假设p和q具有互质关系，则N=p*q 互质关系： 如果两个正整数，除了1以外，没有其他公因子，我们就称这两个数是互质关系（coprime）3和16 公因子是1 是互质关系6和27 公因子是1，3 不是互质关系 LL 是 p - 1 和 q - 1的最小公倍数。 欧拉函数：φ(n) 任意给定正整数n，请问在小于等于n的正整数之中，有多少个与n构成互质关系？在1到8之中，有多少个数与8构成互质关系？ 存在互质关系的有1、 3、 5、 7。所以 φ(8) = 4。 第一种情况 如果n=1，则 φ(1) = 1 。因为1与任何数（包括自身）都构成互质关系 第二种情况 如果n是质数，则 φ(n)=n-1 。因为质数与小于它的每一个数，都构成互质关系。比如5与1、2、3、4都构成互质关系。 第三种情况 如果n是质数的某一个次方，即 $n = p^k$ (p为质数，k为大于等于1的整数)，则$φ(p^k) = p^k - p^{k-1}$ 例如：$φ(8) = φ(2^3) =2^3 – 2^{3-1} = 8 - 4 = 4$ 这是因为只有当一个数不包含质数p，才可能与n互质。而包含质数p的数一共有$p^{k-1}$个，即$1×p$、$2×p$、$3×p$、…、$p^{k-1}×p$，把它们去除，剩下的就是与n互质的数。 0至p中，只有一个数，p与n不是互质p至2p中，只有一个数，2p与n不是互质2p至3p中，只有一个数，3p与n不是互质……$p^{k-2}$至$p^{k-1}$中，只有一个数，$p^{k-1}$与n不是互质 $φ(n) = p^k(总数) - p^{k-1}(不是互质的数) = p^k(1-\frac{1}{k})$ 第四种情况 如果n可以分解成两个互质的整数之积n = p1 * p2，则 φ(n) = φ(p1*p2) = φ(p1) * φ(p2) 第五种情况 因为任意一个大于1的正整数，都可以写成一系列质数的积。 $n = p1^{k1} × p2^{k2} × ⋅⋅⋅ × pr^{kr}$根据第四种情况$φ(n) = φ(p1^{k1}) + φ(p2^{k2}) + ⋅⋅⋅ + φ(pr^{kr})$再根据第三种情况$φ(n) = p1^{k1} × p2^{k2} × ⋅⋅⋅ × pr^{kr}(1-\frac{1}{p1})(1-\frac{1}{p2})(1-\frac{1}{p3})⋅⋅⋅(1-\frac{1}{pr})$$φ(n) = n(1-\frac{1}{p1})(1-\frac{1}{p2})(1-\frac{1}{p3})⋅⋅⋅(1-\frac{1}{pr})$ $φ(1323)=φ(3^3 × 7^2)=1323(1-\frac{1}{3})(1-\frac{1}{7})=756$ EE 是比1大比L小的数，E和L的最大公约数为1 DD 是比1大比L小的数，E和D的乘积对L求余为11 &lt; D &lt; LE x D mod L = 1 举例说明求N随机选择两个不相等的质数p和q，p=17，q=19 N = p x q = 17 x 19 = 323 求LL = 最小公倍数(17 - 1) x (19 - 1) = 144 16 x 9 = 14418 x 8 = 144 求E满足条件的E有很多，例如：5,7,11,13,17…. 我们选择E=5，则公钥就是E=5,N=323 求DE x D mod L = 15 x D mod 144 = 1 当D=29时，满足上面的条件。 加密明文=123$密文 = 明文^E mod N = 123^5 mod 323 = 225$ 解密$明文 = 密文^D mod N = 225^29 mod 323 = 123$ 参考资料https://mp.weixin.qq.com/s/J6UCbHPOBJyrHQwCz1eF4ghttps://mp.weixin.qq.com/s/kVXROoRulq1jYt--sU_9Xwhttp://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_one.htmlhttp://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html图解密码技术]]></content>
      <categories>
        <category>密码</category>
      </categories>
      <tags>
        <tag>密码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[登录模块 设计]]></title>
    <url>%2Fposts%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F2018%2F06%2F13%2Fdesign-login%2F</url>
    <content type="text"><![CDATA[如何设计一个安全的登录模块 原始 设计默认数据表结构123idphonepassword md5(密码) 登录请求及代码HTTP请求123456789101112$phone = htmlentities($_POST['phone']);$password = htmlentities($_POST['password']);$password = md5($password);// 从数据库中获取加密后的password$sql = "select password from user where phone = " . $phone . " limit 1";$info = querySql($sql);if ($info['password'] === $password) &#123; //设置cookie &amp; session&#125; else &#123; echo "登录失败";&#125; 安全性密码一旦数据表遭到泄露，则所有账户及密码遭到泄露，密码采用md5加密。虽然md5算法是不可逆的，但是网上有彩虹表，可以根据彩虹表来得到密码。假设数据库存储的password有一个值为d591e603e5668d1b2b5f2f6d3bdc44b0通过彩虹表可以得到密码是xpisme HTTP传输 (明文传输)窃听者盗取信息后，就可以拿着这些账号密码进行登录了，进行购买商品，转账等操作。 进阶(加盐值) 设计默认数据表结构123idphonepassword md5(密码+固定盐值) 登录的请求及代码 假设盐值是固定的funcking attack HTTP请求12345678910$phone = htmlentities($_POST['phone']);$password = htmlentities($_POST['password']);// 从数据库中获取加密后的password$sql = "select password from user where phone = " . $phone . " limit 1";$info = querySql($sql);if ($info['password'] === $password) &#123; //设置cookie &amp; session&#125; else &#123; echo "登录失败";&#125; 安全性密码根据彩虹表破解刚才传入的值bd4123fb562b60e196b832133db408ca加盐值之后，彩虹表破解的难度增加。即使数据表遭到泄露，攻击者仍然很难破解出明文的密码。 HTTP传输 (明文传输)窃听者盗取信息后，就可以拿着这些账号密码进行登录了，进行购买商品，转账等操作。但是经过HTTP协议传输，仍然还会出现被窃听的风险。 HTTP 采用RSA加密采用RSA算法，非对称加密。客户端采用公钥加密，服务端采用私钥解密。 服务端提供获取公钥的接口 拿到公钥后，对密码进行加密，然后在进行登录 窃听者通过充当中间人的身份，即可获取正常的密码。 窃听者生成自己的公钥、私钥 给客户端自己的公钥 客户端采用窃听者的公钥后加密，传给服务器 请求被监听者拦截，用自己的私钥解密 将解密后的密码，再用服务端的公钥加密 最终的设计 (HTTPS)默认数据表结构123idphonepassword md5(密码+随机盐值) 登录的请求 盐值是随机的，每个账号对应一个盐值，服务端维护这样的关系。盐值可以是创建时间、可以是用户名、邮箱等等、也可以是随机数。 HTTP请求服务端获取该账号对应的盐值 HTTP根据上一步获取到的盐值，对密码进行加密后，再登录。 安全性 破解密码 比起固定盐值，破解的难度也是大大增加。 HTTPS传输 窃听者只能拿到HTTPS加密后的信息，也不能模拟登录。 Q&amp;AQ1： 为什么要加盐值？加了盐值就安全了吗？加盐的原理是什么？A1： 如果不加盐值，则密码很容遭到破解。列如d591e603e5668d1b2b5f2f6d3bdc44b0，通过彩虹表就可以查到密码是xpisme；加了盐值只是提高了破解的难度，并不是真正的安全，当破解的成本大于收益的时候，破解也就没有了意义；加盐的原理是 md5(password + 盐值)。Q2：为什么要使用HTTPS协议？A2：因为HTTPS，会对传输的内容进行加密。窃听者即使获取信息，信息也是听过HTTP（SSL）加密后的。Q3：有同学会说利用charles、fiddler等抓包工具，也可以抓到https接口的数据，是不是https也是不安全的？A3：web中你能抓到是因为还没有经过SSL加密，SSL是在应用层和传输层中间，请求是在应用层前拦截的，没有经过SSL，所以能抓到明文的。抓app的包是因为手机安装了证书。这篇文章是个反例https://blog.csdn.net/stpeace/article/details/78073288 一定要看评论，评论才是正解。 参考资料https://stackoverflow.com/questions/962187/plain-text-password-over-httpshttps://gooroo.io/GoorooTHINK/Article/13023/The-difference-between-encryption-hashing-and-salting/2085#.WyHeyHv-jIUhttps://mp.weixin.qq.com/s/9ZB923jDybc143UKl1BRmQ彩虹表： https://crackstation.net/]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7 扩展开发 (hello world)]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F06%2F11%2Fphp7-ext%2F</url>
    <content type="text"><![CDATA[PHP7 扩展开发学习 学习概念是比较枯燥的事情，只有动手操作才能吸收的更多。从扩展开发开始 示例：123&lt;?phpecho hello();?&gt; 执行12php ./test.phphello world 第零步 搭建基础环境下载php7的源码 https://github.com/php/php-src/releases 在这里我们用php-7.2.6 12345678910111213141516[xpisme@aliyun ~]$ cd /home/xpisme/usr/local下载[xpisme@aliyun local]$ wget https://github.com/php/php-src/archive/php-7.2.6.tar.gz解压[xpisme@aliyun local]$ tar xzvf php-7.2.6.tar.gz创建配置[xpisme@aliyun local]$ cd php-src-php-7.2.6/[xpisme@aliyun php-src-php-7.2.6]$ ./buildconf --force编译三部曲[xpisme@aliyun php-src-php-7.2.6]$ ./configure --disable-all --prefix=/home/xpisme/usr/php72[xpisme@aliyun php-src-php-7.2.6]$ make [xpisme@aliyun php-src-php-7.2.6]$ make install 第一步 生成骨干代码使用php提供的代码生成工具ext_skel12[xpisme@aliyun ~]$ cd /home/xpisme/usr/local/php-src-php-7.2.6/ext[xpisme@aliyun ext]$ ./ext_skel --extname=hello 会发现ext下多个hello目录。 第二步 移除注释编辑hello/config.m4文件 移除注释--enable-hello将改为 第三步 实现代码12[xpisme@aliyun ~]$ cd /home/xpisme/usr/local/php-src-php-7.2.6/ext/hello[xpisme@aliyun hello]$ vim hello.c 找到PHP_FUNCTION(confirm_hello_compiled)，在其上面增加如下代码：123456PHP_FUNCTION(hello)&#123; zend_string *strg; strg = strpprintf(0, "hello world"); RETURN_STR(strg);&#125; 即将改为 找到 PHP_FE(confirm_hello_compiled, 在上面增加如下代码1PHP_FE(say, NULL) 即将改为 第四步 编译安装1234[xpisme@aliyun ~]$ cd /home/xpisme/usr/local/php-src-php-7.2.6/ext/hello[xpisme@aliyun hello]$ /home/xpisme/usr/php72/bin/phpize[xpisme@aliyun hello]$ ./configure --with-php-config=/home/xpisme/usr/php72/bin/php-config[xpisme@aliyun hello]$ make &amp;&amp; make install 第五步 测试12[xpisme@aliyun hello]$ /home/xpisme/usr/php72/bin/php -d "extension=hello.so" -r "echo hello();"hello world 参考资料http://www.php-internals.com/book/?p=chapt11/11-02-00-extension-hello-worldhttps://www.bo56.com/php7%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%91%E4%B9%8Bhello-word/https://www.bo56.com/php7%E6%89%A9%E5%B1%95/]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7 内存管理 （二）]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F05%2F31%2Fphp7-memory-manage%2F</url>
    <content type="text"><![CDATA[PHP7 内存管理 （二） 内存初始化12345678910111213141516171819202122232425262728293031323334static zend_mm_heap *zend_mm_init(void)&#123; // 向系统申请2MB大小的chunk zend_mm_chunk *chunk = (zend_mm_chunk*)zend_mm_chunk_alloc_int(ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE); zend_mm_heap *heap; // heap结构实际是主chunk嵌入的一个结构，后面再分配chunk的heap_slot不再使用 heap = &amp;chunk-&gt;heap_slot; chunk-&gt;heap = heap; // 双向链表 chunk-&gt;next = chunk; chunk-&gt;prev = chunk; // 剩余可用的page数 chunk-&gt;free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE; chunk-&gt;free_tail = ZEND_MM_FIRST_PAGE; chunk-&gt;num = 0; //将第一个page的bit分配标识位设置为1 标识已经被分配 占用 chunk-&gt;free_map[0] = (Z_L(1) &lt;&lt; ZEND_MM_FIRST_PAGE) - 1; //第一个page的类型为ZEND_MM_IS_LRUN，即large内存 chunk-&gt;map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE); // 指向主chunk heap-&gt;main_chunk = chunk; ....... // huge内存链表 heap-&gt;huge_list = NULL; return heap;&#125; 分配了主chunk，只有第一个chunk的heap会用到，后面分配的chunk不再用到heap，初始化完的结构如下图 内存分配Zend内存分配器按照申请内存的大小有三种不同的实现 1234567891011121314151617181920212223// 内存分配ZEND_API void* ZEND_FASTCALL _emalloc(size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; // zend_mm_alloc_heap 实现内存分配 return zend_mm_alloc_heap(AG(mm_heap), size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);&#125;// 内存分配static zend_always_inline void *zend_mm_alloc_heap(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; void *ptr; if (size &lt;= ZEND_MM_MAX_SMALL_SIZE) &#123; // small size ptr = zend_mm_alloc_small(heap, size, ZEND_MM_SMALL_SIZE_TO_BIN(size) ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); &#125; else if (size &lt;= ZEND_MM_MAX_LARGE_SIZE) &#123; // large size ptr = zend_mm_alloc_large(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); &#125; else &#123; // huge size return zend_mm_alloc_huge(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); &#125;&#125; Huge分配Huge是指超过2MB大小内存的分配，实际分配时将对齐到n个chunk，分配完以后还有分配一个zend_mm_huge_list结构，这个结构用于管理所有的Huge内存。12345678910111213141516171819202122232425262728static void *zend_mm_alloc_huge(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; // 按页大小重置实际要分配的内存 size_t new_size = ZEND_MM_ALIGNED_SIZE_EX(size, REAL_PAGE_SIZE);#if ZEND_MM_LIMIT // 如果有内存使用限制则check是否已达上限，达到的话进行zend_mm_gc清理后再检查#endif // 分配chunk ptr = zend_mm_chunk_alloc(heap, new_size, ZEND_MM_CHUNK_SIZE); if (UNEXPECTED(ptr == NULL)) &#123; /* insufficient memory */ if (zend_mm_gc(heap) &amp;&amp; (ptr = zend_mm_chunk_alloc(heap, new_size, ZEND_MM_CHUNK_SIZE)) != NULL) &#123; /* pass */ &#125; else &#123; //申请失败 zend_mm_safe_error(heap, "Out of memory"); return NULL; &#125; &#125; // 将申请的内存通过 zend_mm_add_huge_block 插入到链表中 zend_mm_add_huge_block(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); return ptr;&#125; 分配chunk是向ZendMM系统申请的唯一粒度，也是Large、Small内存分配的基础。 内存地址对齐到chunk的大小2MB，分配chunk地址都是ZEND_MM_CHUNK_SIZE的整数倍。 系统返回的地址是随机的，内存池要自己移动到对齐的位置上。 zend_mm_chunk_alloc_int12345678910111213141516171819202122232425262728293031323334353637383940414243static void *zend_mm_chunk_alloc(zend_mm_heap *heap, size_t size, size_t alignment)&#123; return zend_mm_chunk_alloc_int(size, alignment);&#125;static void *zend_mm_chunk_alloc_int(size_t size, size_t alignment)&#123; // 向系统申请size大小的内存 void *ptr = zend_mm_mmap(size); if (ptr == NULL) &#123; return NULL; &#125; else if (ZEND_MM_ALIGNED_OFFSET(ptr, alignment) == 0) &#123; // 判断申请的内存是否为alignment的整数倍 如果是，就不需要处理了 return ptr; &#125; else &#123; // 申请的内存不是按照alignment对齐的 size_t offset; // 释放申请的内存 zend_mm_munmap(ptr, size); //重新申请一块内存，这里会多申请一块内存，用于截取到alignment的整数倍，可以忽略REAL_PAGE_SIZE ptr = zend_mm_mmap(size + alignment - REAL_PAGE_SIZE); // offset 为ptr距离上一个alignment对齐内存位置的大小 offset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment); if (offset != 0) &#123; // 该offset为alignment的整数倍 offset = alignment - offset; // 释放多于的内存 zend_mm_munmap(ptr, offset); // 偏移ptr， 对齐到alignment ptr = (char*)ptr + offset; alignment -= offset; &#125; if (alignment &gt; REAL_PAGE_SIZE) &#123; zend_mm_munmap((char*)ptr + size, alignment - REAL_PAGE_SIZE); &#125; return ptr; &#125; 宏ZEND_MM_ALIGNED_OFFSET 计算按alignment对齐的内存地址距离上一个alignment整数倍内存地址的大小 alignment必须为2的n次方，比如一段n*alignment大小的内存，ptr为其中一个位置，那么就可以通过位运算计算得到ptr所属内存块的offset12#define ZEND_MM_ALIGNED_OFFSET(size, alignment) \ (((size_t)(size)) &amp; ((alignment) - 1)) 容易理解的代码offset = ptr - int取整(ptr/alignment)*alignment large 分配 申请的内存 3072Byte &lt; size &lt; 2044KB时，内存池会选择在chunk上查找对应数量的page返回。 Large内存申请的粒度是page。 12345678910111213141516static zend_always_inline void *zend_mm_alloc_large(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; // 根据size大小 计算需要分配多少个page int pages_count = (int)ZEND_MM_SIZE_TO_NUM(size, ZEND_MM_PAGE_SIZE); // 分配page_count个page void *ptr = zend_mm_alloc_pages(heap, pages_count ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); return ptr; &#125;// 宏 根据size大小 计算需要分配多少个page// 假设size = 8k1Byte alignment=4K 则 8K1Byte + 4K -1Byte = 12K / 4K = 3个page// 假设size = 8k alignment=4K 则 8K + 4K -1Byte = 11K 1023Byte / 4K = 2个page#define ZEND_MM_SIZE_TO_NUM(size, alignment) \ (((size_t)(size) + ((alignment) - 1)) / (alignment)) zend_mm_alloc_pages函数简要概述如下 从第一个chunk开始查找当前chunk下是否有pages_count个连续可用的page，有的话就停止查找。 没有的话则接着查找下一个chunk，如果直到最后一个chunk也没找到则重新分配一个新的chunk并插入chunk链表。 如何判断是否有连续的page，是通过chunk结构中的free_map。free_map实际就是：zend_ulong free_map[16/8]，以 free_map[8] 为例，数组中的8个数字分别表示：0-63、64-127、128-191、192-255、256-319、320-383、384-447、448-511 page的分配与否，比如当前chunk的page 0、page 2已经分配，则:free_map[0] = 5 12//5:00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000101 1234567891011121314151617181920212223242526272829303132333435363738394041static void *zend_mm_alloc_pages(zend_mm_heap *heap, int pages_count ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; zend_mm_chunk *chunk = heap-&gt;main_chunk; int page_num, len; //从第一个chunk开始查找可用page while (1) &#123; //当前chunk剩余page总数已不够 if (UNEXPECTED(chunk-&gt;free_pages &lt; pages_count)) &#123; goto not_found; &#125;else&#123; //查找当前chunk是否有pages_count个连续可用的page int best = -1; //已找到可用page起始页 int best_len = ZEND_MM_PAGES; //已找到chunk的page间隙大小，这个值尽可能接近page_count int free_tail = chunk-&gt;free_tail; zend_mm_bitset *bitset = chunk-&gt;free_map; zend_mm_bitset tmp = *(bitset++); // zend_mm_bitset tmp = *bitset; bitset++ 这里是复制出的，不会影响free_map int i = 0; //下面就是查找最优page的过程,稍后详细分析 //find best page &#125;not_found: if (chunk-&gt;next == heap-&gt;main_chunk) &#123; //是否已到最后一个chunkget_chunk: ... &#125;else&#123; chunk = chunk-&gt;next; &#125; &#125;found: //找到可用page，page编号为page_num至(page_num + pages_count) /* mark run as allocated */ chunk-&gt;free_pages -= pages_count; zend_mm_bitset_set_range(chunk-&gt;free_map, page_num, pages_count); //将page_num至(page_num + pages_count)page的bit标识位设置为已分配 chunk-&gt;map[page_num] = ZEND_MM_LRUN(pages_count); //map为两个值的组合值，首先表示当前page属于哪种类型，其次表示包含的page页数 if (page_num == chunk-&gt;free_tail) &#123; chunk-&gt;free_tail = page_num + pages_count; &#125; return ZEND_MM_PAGE_ADDR(chunk, page_num);&#125; 最优page的检索过程如下 ： 首先从第一个page分组(page 0-63)开始检查，如果当前分组无可用page(即free_map[x] = -1)则进入下一分组，直到当前分组有空闲page，然后进入第二步 当前分组有可用page，首先找到第一个可用page的位置，记作page_num，接着从page_num开始向下找第一个已分配page的位置，记作end_page_num，这个地方需要注意，如果当前分组剩下的page都是可用的则会进入下一分组接着搜索，直到找到为止，这里还会借助chunk-&gt;free_tail避免无谓的查找到最后分组 根据上一步找到的page_num、end_page_num可计算得到当前可用内存块大小为len个page，然后与申请的page页数(page_count)比较 3.1 如果len=page_count则表示找到的内存块符合申请条件且非常完美，直接从page_num开始分配page_count个page 3.2 如果len&gt;page_count则表示找到的内存块符合条件且空间很充裕，暂且记录下len、page_num，然后继续向下搜索，如果有更合适的则用更合适的替代 3.3 如果len&lt;page_count则表示当前内存块不够申请的大小，不符合条件，然后将这块空间的全部page设置为已分配(这样下一轮检索就不会再次找到它了)，接着从第一步重新检索 下面从一个例子具体看下，以64bit整形为例，假如当前page分配情况如下图-(1)(group1全部已分配;group2中page 67-68、71-74未分配，其余都已分配;group3中除page 128-129、133已分配外其余都未分配)，现在要申请3个page： 检索过程： a.首先会直接跳过group1，直接到group2检索 b.在group2中找到第一个可用page位置：67，然后向下找第一个不可用page位置：69，找到的可用内存块长度为2，小于3，表示此内存块不可用，这时会将page 67-68标识为已分配，图-(2) c.接着再次在group2中查找到第一个可用page位置：71,然后向下找到第一个不可用page位置：75,内存块长度为4，大于3，表示找到一个符合的位置，虽然已经找到可用内存块但并不”完美”，先将这个并不完美的page_num及len保存到best、best_len，如果后面没有比它更完美的就用它了，然后将page 71-74标示为已分配，图-(3) d.再次检索，发现group2已无可用page，进入group3，找到可用内存位置：page 130-132，大小比c中找到的合适，所以最终返回的page就是130-132，图-(4) page分配完成后会将free_map对应整数的bit位从page_num至(page_num+page_count)置为1，同时将chunk-&gt;map[page_num]置为ZEND_MM_LRUN(pages_count)，表示page_num至(page_num+page_count)这些page是被Large分配占用的。 small 分配 首先检查申请规格的内存是否已经分配，如果没有分配或者分配的已经用完了，则申请响应页数的page。 申请到page以后按固定大小将page切割为slot，slot之间构成单链表。保存在AG(mm_heap)-&gt;free_slot 例如16byte、3072byte大小的slot，将分别申请1个、3个page，然后分割为256个16byte的slot，4个3072byte的slot。 详细的分配过程123456789101112static zend_always_inline void *zend_mm_alloc_small(zend_mm_heap *heap, size_t size, int bin_num ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; if (EXPECTED(heap-&gt;free_slot[bin_num] != NULL)) &#123; // 有可用的slot zend_mm_free_slot *p = heap-&gt;free_slot[bin_num]; heap-&gt;free_slot[bin_num] = p-&gt;next_free_slot; return (void*)p; &#125; else &#123; // 新分配slot return zend_mm_alloc_small_slow(heap, bin_num ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); &#125; &#125; zend_mm_alloc_small_slow分配slot操作123456789101112131415161718192021222324252627282930313233343536373839404142434445// bin_num 为 free_slot 数组下static zend_never_inline void *zend_mm_alloc_small_slow(zend_mm_heap *heap, uint32_t bin_num ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)&#123; zend_mm_chunk *chunk; int page_num; zend_mm_bin *bin; zend_mm_free_slot *p, *end; // 分配固定数量的page bin = (zend_mm_bin*)zend_mm_alloc_pages(heap, bin_pages[bin_num] ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); if (UNEXPECTED(bin == NULL)) &#123; /* insufficient memory */ return NULL; &#125; chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(bin, ZEND_MM_CHUNK_SIZE); page_num = ZEND_MM_ALIGNED_OFFSET(bin, ZEND_MM_CHUNK_SIZE) / ZEND_MM_PAGE_SIZE; // 设置各页的分配类型 chunk-&gt;map[page_num] = ZEND_MM_SRUN(bin_num); if (bin_pages[bin_num] &gt; 1) &#123; uint32_t i = 1; do &#123; chunk-&gt;map[page_num+i] = ZEND_MM_NRUN(bin_num, i); i++; &#125; while (i &lt; bin_pages[bin_num]); &#125; /* create a linked list of elements from 1 to last 创建slot链表 */ end = (zend_mm_free_slot*)((char*)bin + (bin_data_size[bin_num] * (bin_elements[bin_num] - 1))); // heap-&gt;free_slot[bin_num] 指向第2个slot，第1个为当前申请到的slot heap-&gt;free_slot[bin_num] = p = (zend_mm_free_slot*)((char*)bin + bin_data_size[bin_num]); do &#123; p-&gt;next_free_slot = (zend_mm_free_slot*)((char*)p + bin_data_size[bin_num]); p = (zend_mm_free_slot*)((char*)p + bin_data_size[bin_num]); &#125; while (p != end); /* terminate list using NULL */ p-&gt;next_free_slot = NULL; /* return first element 返回slot链表的第一个元素 */ return (char*)bin;&#125; 参考资料：https://github.com/pangudashu/php7-internal/blob/master/5/zend_alloc.md]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7 内存管理 （一）]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F05%2F24%2Fmemory-manage%2F</url>
    <content type="text"><![CDATA[PHP7 内存管理 用 C 语言编程时，开发者要手工地进行内存管理。在用PHP编程时，不用考虑内存的情况。是因为C做了内存管理。 三种粒度的内存块 huge(chunk) 每个chunk的大小为2MB large(page) 每个page的大小为4KB small(slot) slot的大小不固定 huge(chunk) 大内存(大于2MB) 分配本质上是：分配n个chunk。通过zend_mm_huge_list管理，大内存之间构成一个单向链表。 123456// 大内存的数据结构 大内存之间构成一个单向链表struct _zend_mm_huge_list &#123; void *ptr; size_t size; zend_mm_huge_list *next; //指针指向下一个&#125;; 图解： 上图中*ptr指向的chunk具体是什么？ chunk是向系统申请、释放内存的最小粒度，chunk之间构建成双向链表。每个chunk的大小为2MB，被分为512个page，每个page4KB (2MB/512=4KB)。 chunk的数据结构123456789101112struct _zend_mm_chunk &#123; zend_mm_heap *heap; zend_mm_chunk *next; // 指向下一个chunk zend_mm_chunk *prev; // 指向上一个chunk uint32_t free_pages; // 当前chunk的剩余可用page数 uint32_t free_tail; uint32_t num; char reserve[64 - (sizeof(void*) * 3 + sizeof(uint32_t) * 3)]; zend_mm_heap heap_slot; zend_mm_page_map free_map; zend_mm_page_info map[ZEND_MM_PAGES];&#125;; large(page) 每个page 4KB 依旧用chunk结构表示123456789101112struct _zend_mm_chunk &#123; zend_mm_heap *heap; zend_mm_chunk *next; zend_mm_chunk *prev; uint32_t free_pages; // 当前chunk的剩余可用page数 uint32_t free_tail; uint32_t num; char reserve[64 - (sizeof(void*) * 3 + sizeof(uint32_t) * 3)]; zend_mm_heap heap_slot; zend_mm_page_map free_map; // 标识各page是否已使用的bitmap，总大小512bit。对应page总数，每个page占一个bit位。 zend_mm_page_info map[ZEND_MM_PAGES];&#125;; small(slot) slot内存是把若干个page按固定大小分割好的内存块，内存池定义了30种大小的slot内存。最小的slot大小为8byte，最大的为3072byte。0~7递增8byte， 8byte 16byte 24byte 32byte 40byte 48byte 56byte 64byte8~11递增16byte 80byte 96byte 112byte 128byte12~15递增32byte 160byte 192byte 224byte 256byte16~19递增64byte 320byte 384byte 448byte 512byte20~23递增128byte 640byte 768byte 896byte 1024byte24~27递增256byte 1280byte 1536byte 1792byte 2048byte28~29递增512byte 2560byte 3072byte slot 0~15各占1个page 123456789101112131415161718192021222324252627282930313233343536Zend/zend_alloc_sizes.h/* num, size, count, pages 四个值的含义依次是：slot编号、slot大小、slot数量、占用page数*/#define ZEND_MM_BINS_INFO(_, x, y) \ _( 0, 8, 512, 1, x, y) \ _( 1, 16, 256, 1, x, y) \ _( 2, 24, 170, 1, x, y) \ _( 3, 32, 128, 1, x, y) \ _( 4, 40, 102, 1, x, y) \ _( 5, 48, 85, 1, x, y) \ _( 6, 56, 73, 1, x, y) \ _( 7, 64, 64, 1, x, y) \ _( 8, 80, 51, 1, x, y) \ _( 9, 96, 42, 1, x, y) \ _(10, 112, 36, 1, x, y) \ _(11, 128, 32, 1, x, y) \ _(12, 160, 25, 1, x, y) \ _(13, 192, 21, 1, x, y) \ _(14, 224, 18, 1, x, y) \ _(15, 256, 16, 1, x, y) \ _(16, 320, 64, 5, x, y) \ //slot16占 5个page 4096byte * 5 / 320byte = 64个 _(17, 384, 32, 3, x, y) \ //slot17占 3个page 4096byte * 3 / 384byte = 32个 _(18, 448, 9, 1, x, y) \ //slot18占 这里不明白为什么只占用1个page _(19, 512, 8, 1, x, y) \ //slot19占 1个page 4096byte / 512byte = 8个 _(20, 640, 32, 5, x, y) \ //slot20占 5个page 4096byte * 5 / 640byte = 32个 _(21, 768, 16, 3, x, y) \ //slot21占 3个page 4096byte * 3 / 768byte = 16个 _(22, 896, 9, 2, x, y) \ //slot22占 这里不明白为什么占用2个page _(23, 1024, 8, 2, x, y) \ //slot23占 2个page 4096byte *2 / 1024byte = 8个 _(24, 1280, 16, 5, x, y) \ //slot24占 5个page 4096byte * 5 / 1280byte = 16个 _(25, 1536, 8, 3, x, y) \ //slot25占 3个page 4096byte * 3 / 1536byte = 8个 _(26, 1792, 16, 7, x, y) \ //slot26占 7个page 4096byte * 7 / 1792byte = 16个 _(27, 2048, 8, 4, x, y) \ //slot27占 8个page 4096byte *4 / 2048byte = 8个 _(28, 2560, 8, 5, x, y) \ //slot28占 5个page 4096byte * 5 / 2560byte = 8个 _(29, 3072, 4, 3, x, y) //slot29占 3个page 4096byte * 3 / 3072byte = 4个 zend_mm_heap123456789101112struct _zend_mm_heap &#123; ... // 小内存分配的可用位置链表，ZEND_MM_BINS等于30，即此数组表示的是各种大小内存对应的链表头部 zend_mm_free_slot *free_slot[ZEND_MM_BINS]; /* free lists for small sizes */ // 大内存链表 zend_mm_huge_list *huge_list; /* list of huge allocated blocks */ // 指向chunk链表的头部 zend_mm_chunk *main_chunk; ...&#125; 图解：]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php7 垃圾回收]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F05%2F08%2Fphp7-garbage-collection%2F</url>
    <content type="text"><![CDATA[PHP7的垃圾回收 unset后的zval是不是垃圾12$a = "hello world!";unset($a); $a现在是不是一个垃圾呢？GC认为这不是一个垃圾。因为$a在unset之后，refcount减少1变成了0，这个时候GC会直接将$a将对应的空间释放掉，则$a及对应的zval结构就不存在了。 垃圾的产生将数组的引用赋值给数组中的一个元素12$a = array('one');$a[] = &amp;$a; 此时若执行unset操作1unset($a); unset操作后，$a不在符号表中，用户无法再访问此变量，$a之前指向的zval的refcount变为1，因为$a的第二个元素指向$a的地址。因此不能被回收，这就是垃圾。 回收垃圾的规则 垃圾回收只适用于array、object这两种类型。 变量的refcount减少到0，那么此变量可以被释放掉，不属于垃圾。 变量的refcount减少之后大于0，那么此变量还不能释放，此变量可能成为一个垃圾。 第一种情况就是可以理解为正常的unset操作，不属于垃圾。 第二种情况垃圾回收器才会将变量收集起来。 回收算法第一步： 遍历垃圾收集器的buffer缓存区，并把所有的value成员refcount减1，把当前value设置为灰色，并把当前value的成员遍历也设置为灰色。第二步： 再次遍历buffer，检查当前value的refcount是否为0，为0表示是垃圾，标记为白色；不为0，则证明还有用，需要对refcount在加回去，设置颜色为黑色。第三步： 最后再次遍历buffer，把非白色的从buffer中移除，剩下的buffer中就是垃圾了。 图解：经过第一步后经过第二步后经过第三步后 数据结构123456789101112131415161718192021222324252627282930313233// 该struct对垃圾进行管理// 收集到的可能成为垃圾的value就保存在这个结构的buf中，即垃圾缓存区 buf是一个双向链表typedef struct _zend_gc_globals &#123; zend_bool gc_enabled; // 是否启用gc zend_bool gc_active; // 是否在垃圾检查过程中 zend_bool gc_full; // 缓存区是否已满 gc_root_buffer *buf; /* preallocated arrays of buffers 启动时分配的用于保存可能垃圾的缓存区 */ gc_root_buffer roots; /* list of possible roots of cycles 指向buf中最新加入的一个可能垃圾*/ gc_root_buffer *unused; /* list of unused buffers 指向buf中没有使用的buffer*/ gc_root_buffer *first_unused; /* pointer to first unused buffer 指向buf中第一个没有使用的buffer*/ gc_root_buffer *last_unused; /* pointer to last unused buffer 指向buf尾部*/ gc_root_buffer to_free; /* list to free 待释放的垃圾*/ gc_root_buffer *next_to_free; uint32_t gc_runs; // 统计gc运行的次数 uint32_t collected; // 统计已回收的垃圾数 ..... gc_additional_buffer *additional_buffer;&#125; zend_gc_globals;//双向链表typedef struct _gc_root_buffer &#123; zend_refcounted *ref; struct _gc_root_buffer *next; /* double-linked list */ struct _gc_root_buffer *prev; uint32_t refcount;&#125; gc_root_buffer; buf是个双向链表buf用于保存收集到的value，它是一个双向链表，初始化时一次性分配10001个gc_root_buffer，第一个buffer被保留。既然是个双向链表，gc_root_buffer中肯定有两个指针next、prev。zend_gc_globals结构中有两个指针指向缓冲区buf的可用空间的起点和终点first_unused和last_unused。 zend_gc_globals中的unusedunused用来管理buf中开始加入，后面又删除的节点，这是一个单链表。 添加垃圾变量 优先使用unused的这些节点。 其次才是first_unused节点，first_unused++，直到last_unused。 结构中有2个可能的垃圾变量，结构如图 代码解析初始化1234567891011// 初始化垃圾回收器ZEND_API void gc_init(void)&#123; if (GC_G(buf) == NULL &amp;&amp; GC_G(gc_enabled)) &#123; // 分配buf缓存区内存，大小为GC_ROOT_BUFFER_MAX_ENTRIES 10001，其中第1个保留不被使用 buf是一个双向链表 GC_G(buf) = (gc_root_buffer*) malloc(sizeof(gc_root_buffer) * GC_ROOT_BUFFER_MAX_ENTRIES); // last_unused 指向尾部 GC_G(last_unused) = &amp;GC_G(buf)[GC_ROOT_BUFFER_MAX_ENTRIES]; gc_reset(); &#125; &#125; 此垃圾回收机制可以通过php.ini中的zend.enable_gc设置是否开启。 垃圾收集销毁变量销毁变量判断是否需要加入垃圾收集器1234567891011121314151617Zend/zend_variables.h// 销毁一个zval 会调用i_zval_ptr_dtor进行处理static zend_always_inline void i_zval_ptr_dtor(zval *zval_ptr ZEND_FILE_LINE_DC)&#123; // 不使用引用计数的类型不需要进行回收 if (Z_REFCOUNTED_P(zval_ptr)) &#123; zend_refcounted *ref = Z_COUNTED_P(zval_ptr); if (!--GC_REFCOUNT(ref)) &#123; //refcount 减一后变为0 不是垃圾 正常回收 _zval_dtor_func(ref ZEND_FILE_LINE_RELAY_CC); &#125; else &#123; // refcount减一后仍然大于0 gc_check_possible_root(ref); &#125; &#125;&#125; gc_check_possible_root123456789101112131415161718Zend/zend_gc.h// 垃圾收集器收集static zend_always_inline void gc_check_possible_root(zend_refcounted *ref)&#123; if (GC_TYPE(ref) == IS_REFERENCE) &#123; zval *zv = &amp;((zend_reference*)ref)-&gt;val; if (!Z_REFCOUNTED_P(zv)) &#123; return; &#125; ref = Z_COUNTED_P(zv); &#125; //判断是否已经收集过 if (UNEXPECTED(GC_MAY_LEAK(ref))) &#123; gc_possible_root(ref); &#125;&#125; gc_possible_root1234567891011121314151617181920212223242526272829303132333435363738394041424344// 收集时首先会从buf中选择一个空闲节点，然后将value的gc保存到这个节点中，// 如果没有空闲节点则表明回收器已经满了，这个时候会触发垃圾鉴定、回收的程序ZEND_API void ZEND_FASTCALL gc_possible_root(zend_refcounted *ref)&#123; ... //插入的节点必须是数组或者对象 ZEND_ASSERT(GC_TYPE(ref) == IS_ARRAY || GC_TYPE(ref) == IS_OBJECT); //插入的节点必须是黑色 防止重复插入 ZEND_ASSERT(EXPECTED(GC_REF_GET_COLOR(ref) == GC_BLACK)); ZEND_ASSERT(!GC_ADDRESS(GC_INFO(ref))); GC_BENCH_INC(zval_possible_root); //unused中有可用的节点 newRoot = GC_G(unused); if (newRoot) &#123; //有的话先用unused 然后将GC_G(unused)指向单链表的下一个 GC_G(unused) = newRoot-&gt;prev; &#125; else if (GC_G(first_unused) != GC_G(last_unused)) &#123; //unused没有可用的，但buf中有 newRoot = GC_G(first_unused); GC_G(first_unused)++; &#125; else &#123; // buf 缓存区已满，这时需要启动垃圾鉴定、回收程序。 .... &#125; //将插入的ref标记为紫色，防止重复插入 GC_TRACE_SET_COLOR(ref, GC_PURPLE); GC_INFO(ref) = (newRoot - GC_G(buf)) | GC_PURPLE; newRoot-&gt;ref = ref; //插入roots链表头部 newRoot-&gt;next = GC_G(roots).next; newRoot-&gt;prev = &amp;GC_G(roots); GC_G(roots).next-&gt;prev = newRoot; GC_G(roots).next = newRoot; GC_BENCH_INC(zval_buffered); GC_BENCH_INC(root_buf_length); GC_BENCH_PEAK(root_buf_peak, root_buf_length);&#125; 删除GC_REMOVE_FROM_BUFFER1234567891011Zend/zend_gc.h#define GC_REMOVE_FROM_BUFFER(p) do &#123; \ zend_refcounted *_p = (zend_refcounted*)(p); \ if (GC_ADDRESS(GC_INFO(_p))) &#123; \ gc_remove_from_buffer(_p); \ &#125; \ &#125; while (0)#define GC_ADDRESS(v) \ ((v) &amp; ~GC_COLOR) 删除时首先根据gc_info取到gc_root_buffer，然后再从buf中移除，删除后把空出来的gc_root_buffer插入unused单链表尾部。12345678910111213141516171819202122232425262728ZEND_API void ZEND_FASTCALL gc_remove_from_buffer(zend_refcounted *ref)&#123; gc_root_buffer *root; ZEND_ASSERT(GC_ADDRESS(GC_INFO(ref))); GC_BENCH_INC(zval_remove_from_buffer); if (EXPECTED(GC_ADDRESS(GC_INFO(ref)) &lt; GC_ROOT_BUFFER_MAX_ENTRIES)) &#123; // GC_ADDRESS就是获取节点在缓存区中的位置，因为删除是根据zend_refcounted而缓存链表的节点类型是gc_root_buffer。 root = GC_G(buf) + GC_ADDRESS(GC_INFO(ref)); //双向链表的移除操作。 gc_remove_from_roots(root); &#125; else &#123; root = gc_find_additional_buffer(ref); gc_remove_from_additional_roots(root); &#125; if (GC_REF_GET_COLOR(ref) != GC_BLACK) &#123; GC_TRACE_SET_COLOR(ref, GC_PURPLE); &#125; GC_INFO(ref) = 0; /* updete next root that is going to be freed */ if (GC_G(next_to_free) == root) &#123; GC_G(next_to_free) = root-&gt;next; &#125; &#125; 释放垃圾 zend_gc_collect_cycles123456789101112131415161718192021222324252627282930313233ZEND_API int zend_gc_collect_cycles(void)&#123; ... //遍历roots链表，对当前结点value的所有成员进行遍历，refcount减1 gc_mark_roots(); //再次遍历roots链表 检查各节点当前refcount是否为0 是则标记为白色 表示为垃圾，否则需要还原，把refcount再加回去 gc_scan_roots(); //将roots链表中的非白色节点删除，之后roots链表中全部是真正的垃圾，将垃圾链表转到to_free等待释放 count = gc_collect_roots(&amp;gc_flags); //释放垃圾 current = to_free.next; while (current != &amp;to_free) &#123; p = current-&gt;ref; GC_G(next_to_free) = current-&gt;next; GC_TRACE_REF(p, "destroying"); if (GC_TYPE(p) == IS_OBJECT) &#123; ... // 调用free_obj释放对象 obj-&gt;handlers-&gt;free_obj(obj); ... &#125; else if (GC_TYPE(p) == IS_ARRAY) &#123; ... //释放数组 zend_array *arr = (zend_array*)p; GC_TYPE(arr) = IS_NULL; zend_hash_destroy(arr); &#125; current = GC_G(next_to_free); &#125; &#125; 参考资料 ：http://php.net/manual/zh/features.gc.collecting-cycles.phphttps://github.com/pangudashu/php7-internal/blob/master/5/gc.md]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7.2之HashTable]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F19%2Fphp7-hashtable%2F</url>
    <content type="text"><![CDATA[PHP7之HashTable hashtable的基本原理 http://blog.xpisme.com/posts/PHP/2018/04/09/php-hashtable/HashTable的数据结构数据结构定义在Zend/zend_types.h12345678910111213141516171819202122232425262728293031// Bucket：散列表中存储的元素typedef struct _Bucket &#123; zval val; // 存储的具体value，这里嵌入一个zval结构 zend_ulong h; /* key根据哈希算法计算得到的哈希值 或者是数字索引编号 hash value (or numeric index) */ zend_string *key; /* 存储元素的key string key or NULL for numerics */&#125; Bucket;typedef struct _zend_array HashTable;// array是PHP中非常强大的一个数据结构，它的底层实现就是普通有序HashTablestruct _zend_array &#123; zend_refcounted_h gc; // 引用计数，与字符串相同 union &#123; struct &#123; ZEND_ENDIAN_LOHI_4( zend_uchar flags, zend_uchar nApplyCount, zend_uchar nIteratorsCount, zend_uchar consistency) &#125; v; uint32_t flags; &#125; u; uint32_t nTableMask; // 计算bucket索引时的掩码 Bucket *arData; // bucket 数组 uint32_t nNumUsed; // 已用bucket数 uint32_t nNumOfElements; // 已有元素数，nNumOfElements &lt;= nNumUsed，因为删除的并不是直接从arData中移除 uint32_t nTableSize; // 数组的大小 为2^n uint32_t nInternalPointer; // 数值索引 zend_long nNextFreeElement; dtor_func_t pDestructor;&#125;; _zend_array中的 nNumUsed、nNumOfElements、nTableSize 先来说nTableSize，在初始化的时候，会先定义数组的大小，初始化一般会定义8个空间，此时nTableSize就是8，但是它还是个空数组，因为只是定义了空间，并没有向空间中存值。 再来说nNumUsed、nNumOfElements，如果向该数组中添加了3个元素，则nNumUsed=nNumOfElements=3。 如果你unset其中一个元素，此时nNumOfElements=2，nNumUsed=3。 图解如下： _zend_array中的 *arData bucket数组 这个值指向存储元素数组的第一个Bucket 插入元素时按顺序依次插入数组，比如第一个元素在arData[0]、第二个在arData[1]…arData[nNumUsed] (这里为什么是顺序递增的呢，将字符串哈希后，也不可能是顺序递增的呀？) _zend_array中的nTableMask_zend_array中的nTableMask值为nTableSize的负数。用于计算散列值，计算方式如下1nIndex = key-&gt;h | nTableMask; 因为nTableSize大小为2的幂次方，则nTableMask为（-8，-16，-32，-64，-128 …）key-&gt;h值为正整数，与nTableMask做或操作，可以得到[nTableMask, -1]之间的散列值。 说明：5用二进制表示 0000 0101 。 -5用5的反码加1（即补码表示）5的原码为0000 0101 原码：自己本身的二进制编码5的反码为1111 1010 反码：0变1, 1变05的补码为1111 1011-5用二进制表示为：1111 1011 3用二进制表示 0000 0011 。-3用3的反码加1（即补码表示）3的原码为0000 0011 原码：自己本身的二进制编码3的反码为1111 1100 反码：0变1, 1变03的补码为1111 1101-3用二进制表示为：1111 1101 8用二进制表示 0000 1000-8用二进制表示 1111 1000 5 | -8 = 0000 0101 | 1111 1000 = 1111 1101 = -33 | -8 = 0000 0011 | 1111 1000 = 1111 1011 = -5 神奇的arData 借助映射表(图解)映射表原理 arData中映射表的存储 初始化1234567891011121314151617181920// hash Table 初始化ZEND_API void ZEND_FASTCALL _zend_hash_init(HashTable *ht, uint32_t nSize, dtor_func_t pDestructor, zend_bool persistent ZEND_FILE_LINE_DC)&#123; // 初始化gc信息 GC_REFCOUNT(ht) = 1; GC_TYPE_INFO(ht) = IS_ARRAY | (persistent ? 0 : (GC_COLLECTABLE &lt;&lt; GC_FLAGS_SHIFT)); // 设置flags ht-&gt;u.flags = (persistent ? HASH_FLAG_PERSISTENT : 0) | HASH_FLAG_APPLY_PROTECTION | HASH_FLAG_STATIC_KEYS; //nTableMask的值是临时的 ht-&gt;nTableMask = HT_MIN_MASK; //临时设置ht-&gt;arData HT_SET_DATA_ADDR(ht, &amp;uninitialized_bucket); ht-&gt;nNumUsed = 0; ht-&gt;nNumOfElements = 0; ht-&gt;nInternalPointer = HT_INVALID_IDX; ht-&gt;nNextFreeElement = 0; ht-&gt;pDestructor = pDestructor; //这里会把数组大小设置为2的幂次方 ht-&gt;nTableSize = zend_hash_check_size(nSize);&#125; 此时的HashTable只是设置了散列表的大小及其他一些成员的初值，还无法用来存储元素。 插入元素真正初始化 因为初始化_zend_hash_init并没有实际分配arData的内存，在第一次插入时才会根据nTableSize的大小分配，分配完后把HashTable-&gt;u.flags打上HASH_FLAG_INITIALIZED掩码，这样就标识已分配。 12345//_zend_hash_add_or_update_i 函数中的前几行if (UNEXPECTED(!(ht-&gt;u.flags &amp; HASH_FLAG_INITIALIZED))) &#123; CHECK_INIT(ht, 0); goto add_to_hash&#125; 12#define CHECK_INIT(ht, packed) \ zend_hash_check_init(ht, packed) 12345678static zend_always_inline void zend_hash_check_init(HashTable *ht, int packed)&#123; HT_ASSERT_RC1(ht); //分配完后(ht)-&gt;u.flags 打上HASH_FLAG_INITIALIZED掩码 if (UNEXPECTED(!((ht)-&gt;u.flags &amp; HASH_FLAG_INITIALIZED))) &#123; zend_hash_real_init_ex(ht, packed); &#125;&#125; 真正完成内存的分配用zend_hash_real_init_ex函数1234567891011121314151617181920212223242526272829static zend_always_inline void zend_hash_real_init_ex(HashTable *ht, int packed)&#123; ..... //设置nTableMask (ht)-&gt;nTableMask = -(ht)-&gt;nTableSize; //分配Bucket数组及映射数组 HT_SET_DATA_ADDR(ht, pemalloc(HT_SIZE(ht), (ht)-&gt;u.flags &amp; HASH_FLAG_PERSISTENT)); //(ht)-&gt;u.flags 打上HASH_FLAG_INITIALIZED掩码 (ht)-&gt;u.flags |= HASH_FLAG_INITIALIZED; //初始化映射数组的value为-1 if (EXPECTED(ht-&gt;nTableMask == (uint32_t)-8)) &#123; //若只有8个值 Bucket *arData = ht-&gt;arData; HT_HASH_EX(arData, -8) = -1; HT_HASH_EX(arData, -7) = -1; HT_HASH_EX(arData, -6) = -1; HT_HASH_EX(arData, -5) = -1; HT_HASH_EX(arData, -4) = -1; HT_HASH_EX(arData, -3) = -1; HT_HASH_EX(arData, -2) = -1; HT_HASH_EX(arData, -1) = -1; &#125; else &#123; HT_HASH_RESET(ht); &#125; .....&#125; 添加元素12345678910111213141516171819//_zend_hash_add_or_update_i 中的add_to_hash //使用空间++，idx是bucket在arData中的存储位置 idx = ht-&gt;nNumUsed++; ht-&gt;nNumOfElements++; .... //找到存储bucket，设置key、value p = ht-&gt;arData + idx; p-&gt;h = h; p-&gt;key = NULL; //计算中间映射表的散列值，idx将保存在映射数组的nIndex位置 nIndex = h | ht-&gt;nTableMask; ZVAL_COPY_VALUE(&amp;p-&gt;val, pData); // 将映射表中原来的值保存到新bucket中，哈希冲突会用到 nIndex的范围在[nTableMask, -1] // 这里的p就是bucket Z_NEXT就是zval结构中指向下一个元素 Z_NEXT(p-&gt;val) = HT_HASH(ht, nIndex); // 保存idx ((uint32_t*)(ht-&gt;arData))[nIndex] = idx HT_HASH(ht, nIndex) = HT_IDX_TO_HASH(idx); 哈希冲突 不同元素的key可能计算得到相同的哈希值，这些具有相同哈希值的元素。散列表时就会发生冲突，应为映射表中只能存储一个元素。解决方法是把冲突的bucket串成链表，这样一来中间映射表映射出的就不再是一个Bucket，而是一个Bucket链表。 核心代码如下1234//先把旧的值保存到新插入元素中，新插入的元素为链表的头部Z_NEXT(p-&gt;val) = HT_HASH(ht, nIndex);// 再把新元素数组存储位置更新到映射表中HT_HASH(ht, nIndex) = HT_IDX_TO_HASH(idx); 1234567891011//zval结构中u2有个next指针struct _zval_struct &#123; zend_value value; union &#123; ..... &#125; u1; union &#123; uint32_t next; //用于解决哈希冲突 .... &#125; u2;&#125;; 查找元素具体过程 首先根据key计算出hash code，hash code存放在zend_string-&gt;h 计算散列值nIndex，zend_string-&gt;h | nTableMask 然后根据散列值nIndex从散列表得到idx，idx为有序数组中的位置 接着根据idx从有序数组HashTable-&gt;arData中获取Bucket。 判断Bucket的key是否是要查找的key，如果是则终止遍历，否则继续根据zval.u2.next遍历比较 详细代码123456789101112131415161718192021222324252627282930313233// Hash Table 查找static zend_always_inline Bucket *zend_hash_find_bucket(const HashTable *ht, zend_string *key)&#123; zend_ulong h; uint32_t nIndex; uint32_t idx; Bucket *p, *arData; // 将字符串获得数字 h = zend_string_hash_val(key); arData = ht-&gt;arData; //计算散列值 nIndex = h | ht-&gt;nTableMask; //获取Bucket存储位置 idx = HT_HASH_EX(arData, nIndex); //遍历 while (EXPECTED(idx != HT_INVALID_IDX)) &#123; //通过idx获取值 p = HT_HASH_TO_BUCKET_EX(arData, idx); // key是string string与需要查找的相等 if (EXPECTED(p-&gt;key == key)) &#123; /* check for the same interned string */ return p; &#125; else if (EXPECTED(p-&gt;h == h) &amp;&amp; // 比较hash code EXPECTED(p-&gt;key) &amp;&amp; EXPECTED(ZSTR_LEN(p-&gt;key) == ZSTR_LEN(key)) &amp;&amp; // 比较key的长度 EXPECTED(memcmp(ZSTR_VAL(p-&gt;key), ZSTR_VAL(key), ZSTR_LEN(key)) == 0)) &#123; // 比较查找的key与Bucket的key是否匹配 return p; &#125; // 哈希冲突 循环链表 idx = Z_NEXT(p-&gt;val); &#125; return NULL;&#125; 扩容扩容时机 数组的容量时有限的，最多可容纳nTableSize个元素。当在已经有NnTableSize个元素，再向里面插入时，则会触发扩容。 12345678910static zend_always_inline zval *_zend_hash_add_or_update_i(HashTable *ht, zend_string *key, zval *pData, uint32_t flag ZEND_FILE_LINE_DC)&#123; ... // 检查是否需要扩容 ZEND_HASH_IF_FULL_DO_RESIZE(ht);add_to_hash: //插入元素 ...&#125; 12345// HashTable 判断是否需要扩容并扩容 HashTable 最多可存储nTableSize个元素#define ZEND_HASH_IF_FULL_DO_RESIZE(ht) \ if ((ht)-&gt;nNumUsed &gt;= (ht)-&gt;nTableSize) &#123; \ zend_hash_do_resize(ht); \ &#125; 扩容过程大致扩容描述 检查数组中已经删除的元素所占的比例（也就是那些已经删除但未从存储数组中移除的元素） 如果比例达到阈值则触发重建索引的操作，会把删除的Bucket移除。 如果比例未达到阈值，则会分配一个原数组大小2倍的新数组，然后把原数组的元素复制到新数组中，最后重建索引。 阈值判断1ht-&gt;nNumUsed &gt; ht-&gt;nNumOfElements + (ht-&gt;nNumOfElements &gt;&gt; 5) 具体处理过程的代码12345678910111213141516171819202122232425262728293031static void ZEND_FASTCALL zend_hash_do_resize(HashTable *ht)&#123; IS_CONSISTENT(ht); HT_ASSERT_RC1(ht); if (ht-&gt;nNumUsed &gt; ht-&gt;nNumOfElements + (ht-&gt;nNumOfElements &gt;&gt; 5)) &#123; /* additional term is there to amortize the cost of compaction */ // 只有到一定阈值才进行rehash zend_hash_rehash(ht); // 重建索引数组 &#125; else if (ht-&gt;nTableSize &lt; HT_MAX_SIZE) &#123; /* Let's double the table size */ void *new_data, *old_data = HT_GET_DATA_ADDR(ht); // 扩大为2倍，加法要比乘法快 uint32_t nSize = ht-&gt;nTableSize + ht-&gt;nTableSize; Bucket *old_buckets = ht-&gt;arData; //新分配arData空间 大小为(sizeof(Bucket)+sizeof(uint32_t)) * nSize new_data = pemalloc(HT_SIZE_EX(nSize, -nSize), ht-&gt;u.flags &amp; HASH_FLAG_PERSISTENT); ht-&gt;nTableSize = nSize; ht-&gt;nTableMask = -ht-&gt;nTableSize; //将arData指针偏移到Bucket数组起始位置 HT_SET_DATA_ADDR(ht, new_data); //将旧的bucket数组赋值到新的空间 memcpy(ht-&gt;arData, old_buckets, sizeof(Bucket) * ht-&gt;nNumUsed); //释放旧的空间 pefree(old_data, ht-&gt;u.flags &amp; HASH_FLAG_PERSISTENT); //重建索引 zend_hash_rehash(ht); &#125; else &#123; zend_error_noreturn(E_ERROR, "Possible integer overflow in memory allocation (%u * %zu + %zu)", ht-&gt;nTableSize * 2, sizeof(Bucket) + sizeof(uint32_t), sizeof(Bucket)); &#125;&#125; 重建索引 zend_hash_rehash1234567891011121314ZEND_API int ZEND_FASTCALL zend_hash_rehash(HashTable *ht)&#123; ... do &#123; nIndex = p-&gt;h | ht-&gt;nTableMask; //将映射表中原来的值保存到新Bucket中，HT_HASH(ht, nIndex)这个函数得到的值映射表中存储的idx值,将idx值放到新的bucket(新bucket就是 刚刚生成的)的next字段中 哈希冲突时会用到 Z_NEXT(p-&gt;val) = HT_HASH(ht, nIndex); //在映射表中保存idx的值 HT_HASH(ht, nIndex) = HT_IDX_TO_HASH(i); p++; &#125; while (++i &lt; ht-&gt;nNumUsed); ...&#125; 重建索引的过程还会将已删除的Bucket删除，移除后会把这个Bucket之后的元素全部向前移动一个位置，所以在重建索引后存储数组中元素全部紧密排列。 附加 宏的定义HT_SET_DATA_ADDR1234设置HashTable arData的位置#define HT_SET_DATA_ADDR(ht, ptr) do &#123; \ (ht)-&gt;arData = (Bucket*)(((char*)(ptr)) + HT_HASH_SIZE((ht)-&gt;nTableMask)); \ &#125; while (0) HT_HASH_EX、HT_HASH、HT_HASH_RESET123// data[idx]#define HT_HASH_EX(data, idx) \ ((uint32_t*)(data))[(int32_t)(idx)] 123// HashTable-&gt;arrData[idx]#define HT_HASH(ht, idx) \ HT_HASH_EX((ht)-&gt;arData, idx) 123//将HashTable-&gt;arrData[-1]到[nTableMask]均设置为HT_INVALID_IDX（-1）#define HT_HASH_RESET(ht) \ memset(&amp;HT_HASH(ht, (ht)-&gt;nTableMask), HT_INVALID_IDX, HT_HASH_SIZE((ht)-&gt;nTableMask)) HT_IDX_TO_HASH123//idx*bucket的大小define HT_IDX_TO_HASH(idx) \ ((idx) * sizeof(Bucket)) Z_NEXT1#define Z_NEXT(zval) (zval).u2.next 参考资料https://www.dayexie.com/detail282389.htmlhttp://gywbd.github.io/posts/2014/12/php7-new-hashtable-implementation.htmlPHP7内核剖析]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7.2的变量 zval 结构]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F17%2Fphp7-2-zval%2F</url>
    <content type="text"><![CDATA[深入探究PHP7.2 zval结构 环境 PHP7.2上一节介绍了PHP5.6版本，zval的结构。这节介绍下PHP7.2版本 zval结构。 _zval_struct 结构1234567891011121314151617181920212223242526typedef struct _zval_struct zval;struct _zval_struct &#123; zend_value value; /* value */ union &#123; struct &#123; ZEND_ENDIAN_LOHI_4( zend_uchar type, /* active type */ zend_uchar type_flags, zend_uchar const_flags, zend_uchar reserved) /* call info for EX(This) */ &#125; v; uint32_t type_info; &#125; u1; union &#123; uint32_t next; /* hash collision chain */ uint32_t cache_slot; /* literal cache slot */ uint32_t lineno; /* line number (for ast nodes) */ uint32_t num_args; /* arguments number for EX(This) */ uint32_t fe_pos; /* foreach position */ uint32_t fe_iter_idx; /* foreach iterator index */ uint32_t access_flags; /* class constant access flags */ uint32_t property_guard; /* single property guard */ uint32_t extra; /* not further specified */ &#125; u2;&#125;; zval 结构内嵌一个union类型的zend_value 下面会有所介绍 u1 结构 变量的类型就通过u1.v.type区分 u2 结构 假如zval只有:value、u1两个值，整个zval的大小也会对齐到16byte，既然不管有没有u2大小都是16byte，把多余的4byte拿出来用于一些特殊用途还是很划算的，比如next在哈希表解决哈希冲突时会用到，还有fe_pos在foreach会用到…… u1.v.type值，文件Zend/zend_types.h123456789101112131415161718192021222324252627/* regular data types */#define IS_UNDEF 0#define IS_NULL 1#define IS_FALSE 2#define IS_TRUE 3#define IS_LONG 4#define IS_DOUBLE 5#define IS_STRING 6#define IS_ARRAY 7#define IS_OBJECT 8#define IS_RESOURCE 9#define IS_REFERENCE 10/* constant expressions */#define IS_CONSTANT 11#define IS_CONSTANT_AST 12/* fake types */#define _IS_BOOL 13#define IS_CALLABLE 14#define IS_ITERABLE 19#define IS_VOID 18/* internal types */#define IS_INDIRECT 15#define IS_PTR 17#define _IS_ERROR 20 zend_value 结构12345678910111213141516171819typedef union _zend_value &#123; zend_long lval; /* long value int整型*/ double dval; /* double value float型*/ zend_refcounted *counted; zend_string *str; // string 字符串 zend_array *arr; // array 数组 zend_object *obj; // object 对象 zend_resource *res; // resource 资源类型 zend_reference *ref; // 引用类型 通过 &amp;$var_name定义 zend_ast_ref *ast; // 下面几个都是内核使用的value zval *zv; void *ptr; zend_class_entry *ce; zend_function *func; struct &#123; uint32_t w1; uint32_t w2; &#125; ww;&#125; zend_value; IS_NULL _zval_struct结构中u1.v.type标记为NULL类型，_zvalue_value不存储。 IS_TRUE _zval_struct结构中u1.v.type标记为布尔true类型，_zvalue_value不存储。 IS_FALSE _zval_struct结构中u1.v.type标记为布尔false类型，_zvalue_value不存储。 IS_LONG _zval_struct结构中u1.v.type标记为INT类型，_zvalue_value中lval存储， IS_DOUBLE _zval_struct结构中u1.v.type标记为DOUBLE类型，_zvalue_value中dval存储， IS_STRING _zval_struct结构中u1.v.type标记为STRING类型，_zvalue_value中zend_string存储， IS_ARRAY _zval_struct结构中u1.v.type标记为ARRAY类型，_zvalue_value中zend_array存储， IS_OBJECT _zval_struct结构中u1.v.type标记为OBJECT类型，_zvalue_value中zend_object存储， IS_RESOURCE _zval_struct结构中u1.v.type标记为RESOURCE类型，_zvalue_value中zend_resource存储， zend_string 字符串123456struct _zend_string &#123; zend_refcounted_h gc; // 变量引用信息，比如当前value的引用数，所有用到引用计数的变量类型都会有这个结构 zend_ulong h; /* hash value 哈希值，数组中计算索引时会用到 */ size_t len; // 字符串长度，通过这个值保持二进制安全 char val[1]; // 字符串内容，变长struct，分配时按len长度申请内存&#125;; zend_array 数组12345678910111213141516171819202122// array是PHP中非常强大的一个数据结构，它的底层实现就是普通有序HashTablestruct _zend_array &#123; zend_refcounted_h gc; // 引用计数，与字符串相同 union &#123; struct &#123; ZEND_ENDIAN_LOHI_4( zend_uchar flags, zend_uchar nApplyCount, zend_uchar nIteratorsCount, zend_uchar consistency) &#125; v; uint32_t flags; &#125; u; uint32_t nTableMask; // 计算bucket索引时的掩码 Bucket *arData; // bucket 数组 uint32_t nNumUsed; // 已用bucket数 uint32_t nNumOfElements; // 已有元素数，nNumOfElements &lt;= nNumUsed，因为删除的并不是直接从arData中移除 uint32_t nTableSize; // 数组的大小 为2^n uint32_t nInternalPointer; // 数值索引 zend_long nNextFreeElement; dtor_func_t pDestructor;&#125;; zend_object 对象12345678struct _zend_object &#123; zend_refcounted_h gc; uint32_t handle; // TODO: may be removed ??? zend_class_entry *ce; // 对象对应的class类 const zend_object_handlers *handlers; HashTable *properties; // 对象属性hash表 zval properties_table[1];&#125;; zend_resource 资源12345678// 资源// tcp链接、文件句柄struct _zend_resource &#123; zend_refcounted_h gc; int handle; // TODO: may be removed ??? int type; void *ptr;&#125;; 参考资料https://github.com/pangudashu/php7-internal/blob/master/2/zval.mdhttp://www.phpinternalsbook.com/php7/internal_types/zvals/basic_structure.html]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP5.6的变量 zval 结构]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F17%2Fphp-zval%2F</url>
    <content type="text"><![CDATA[深入探究PHP5.6 zval结构 环境 PHP5.6众所周知，PHP是弱类型语言，而C是强类型语言。那强类型语言C是怎么实现弱类型PHP语言的呢，变量在C中是如何定义的呢？ _zval_struct 结构12345678910typedef struct _zval_struct zval;// PHP使用这个结构来存储变量的所有数据struct _zval_struct &#123; /* Variable information */ zvalue_value value; /* value 存储变量的值 */ zend_uint refcount__gc; /* 表示引用计数 */ zend_uchar type; /* active type 存储变量的类型 type字段就是实现弱类型最关键的字段*/ zend_uchar is_ref__gc; /* 表示是否引用 */&#125;; value 存储变量的值 type 存储变量的类型 (8种数据类型) IS_NULL IS_BOOL IS_LONG IS_DOUBLE IS_STRING IS_ARRAY IS_OBJECT IS_RESOURCE refcount__gc 引用计数 默认为1 is_ref__gc 是否引用 默认为0 zvalue_value_zval_struct 结构12345678910111213变量的值存储在zvalue_value联合体中，结构体定义如下typedef union _zvalue_value &#123; long lval; /* long value */ double dval; /* double value */ struct &#123; char *val; int len; &#125; str; HashTable *ht; /* hash table value */ zend_object_value obj; zend_ast *ast;&#125; zvalue_value; IS_NULL _zval_struct结构中type标记为NULL类型，_zvalue_value不存储。 IS_BOOL _zval_struct结构中type标记为BOOL类型，_zvalue_value中lval存储，0(false) 和1(true) IS_LONG _zval_struct结构中type标记为INT类型，_zvalue_value中lval存储， 这是一个有符号整数类型，即它可以存储正整数和负整数。但是不适合位(&amp;,|,^)操作 64位UNIX操作系统占8个字节，64位windows操作系统占4个字节。所以在不同的操作系统中，存储的整型范围不同。 IS_DOUBLE _zval_struct结构中type标记为DOUBLE类型，_zvalue_value中dval存储 根据IEEE-754指定的，采用8字节存储。 IS_STRING _zval_struct结构中type标记为STRING类型，_zvalue_value中struct {char *val; int len; } str;存储 C中字符串是以\0结尾的字符数组，这里多存储了字符串的长度。空间换时间，strlen时间负责度O(1) 字符串foo长度为3，实际上存储是4。strlen(&quot;foo&quot;) == sizeof(&quot;foo&quot;) - 1 IS_ARRAY _zval_struct结构中type标记为ARRAY类型，_zvalue_value中HashTable *ht存储 PHP5.6 HashTable http://blog.xpisme.com/posts/PHP/2018/04/09/php-hashtable/ IS_OBJECT _zval_struct结构中type标记为OBJECT类型，_zvalue_value中zend_object_value obj存储 12345// 对象Object结构体，php对象只有在运行时才会被创建。typedef struct _zend_object_value &#123; zend_object_handle handle; // unsigned int类型，EG(objects_store).object_buckets的索引 object对象值内容的zend_object_handle域就是当前对象在对象池中所在的索引 const zend_object_handlers *handlers; // handlers字段则是将对象进行操作时的处理函数保存起来&#125; zend_object_value; IS_RESOURCE _zval_struct结构中type标记为RESOURCE类型，_zvalue_value中lval存储 资源(IS_RESOURCE)与对象相似，它们也存储一个惟一的ID，可以用来查找实际值。这个ID存储在long lval成员中 类型存储对应关系 有意思的宏12345zval *zv_ptr = /* 假设有zval结构的值 */;if (zv_ptr-&gt;type == IS_LONG) &#123; php_printf("Zval 是一个长整型，其值为 %ld\n", zv_ptr-&gt;value.lval);&#125; else /* ... 处理其他类型 */ 在定义了宏后，操作变得更简单了12345zval *zv_ptr = /* ... */;if (Z_TYPE_P(zv_ptr) == IS_LONG) &#123; php_printf("Zval 是一个长整型，其值为 %ld\n", Z_LVAL_P(zv_ptr));&#125; else /* ... */ Z_TYPE_P宏取的是zval的type值，Z_LVAL_P宏取的是zval的lval字段值。 12345#define Z_TYPE(zval) (zval).type#define Z_TYPE_P(zval_p) Z_TYPE(*zval_p)#define Z_LVAL_P(zval_p) Z_LVAL(*zval_p)#define Z_LVAL(zval) (zval).value.lval 有意思的打印函数1234567891011121314151617181920212223242526272829303132switch (Z_TYPE_P(zv_ptr)) &#123; case IS_NULL: php_printf("NULL: null\n"); break; case IS_BOOL: if (Z_BVAL_P(zv_ptr)) &#123; php_printf("BOOL: true\n"); &#125; else &#123; php_printf("BOOL: false\n"); &#125; break; case IS_LONG: php_printf("LONG: %ld\n", Z_LVAL_P(zv_ptr)); break; case IS_DOUBLE: php_printf("DOUBLE: %g\n", Z_DVAL_P(zv_ptr)); break; case IS_STRING: php_printf("STRING: value=\""); PHPWRITE(Z_STRVAL_P(zv_ptr), Z_STRLEN_P(zv_ptr)); php_printf("\", length=%d\n", Z_STRLEN_P(zv_ptr)); break; case IS_RESOURCE: php_printf("RESOURCE: id=%ld\n", Z_RESVAL_P(zv_ptr)); break; case IS_ARRAY: php_printf("ARRAY: hashtable=%p\n", Z_ARRVAL_P(zv_ptr)); break; case IS_OBJECT: php_printf("OBJECT: ???\n"); break;&#125; 变量的引用计数和写时复制 假如我们定义了一个变量然后赋值给另外一个变量，可能后面都只是只读操作，硬拷贝就会有多余的一份数据。解决方案是： 引用计数+写时复制xdebug扩展安装：http://blog.xpisme.com/posts/PHP/2018/04/08/build-enviorment-for-php/ 引用计数1234567891011121314$a = 'hello';xdebug_debug_zval('a'); //refcount只有变量a在引用 所以为1$b = $a;xdebug_debug_zval('a'); //refcount有变量a和变量b在引用 所以为2$c = $b;xdebug_debug_zval('a'); //refcount有变量a、b、c在引用 所以为3unset($b);xdebug_debug_zval('a'); //refcount有变量a、c在引用，所以为2输出a: (refcount=1, is_ref=0)=1a: (refcount=2, is_ref=0)=1a: (refcount=3, is_ref=0)=1a: (refcount=2, is_ref=0)=1 图解 写时复制12345678910111213141516$a = 'hello';xdebug_debug_zval('a'); //refcount只有变量a在引用 所以为1$b = $a;xdebug_debug_zval('a'); //refcount有变量a和变量b在引用 所以为2$c = $b;xdebug_debug_zval('a'); //refcount有变量a、b、c在引用 所以为3$a = 'world'; // $a 与 $b,$c 存储分离xdebug_debug_zval('a'); //refcount只有变量a在引用 所以为1xdebug_debug_zval('b'); //refcount有变量b和变量c在引用 所以为2输出a: (refcount=1, is_ref=0)=1a: (refcount=2, is_ref=0)=1a: (refcount=3, is_ref=0)=1a: (refcount=1, is_ref=0)=2b: (refcount=2, is_ref=0)=1 图解 参考资料http://www.phpinternalsbook.com/zvals/basic_structure.htmlhttp://www.php-internals.com/book/?p=chapt03/03-01-00-variables-structure]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP current、end函数遇到的坑]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F16%2Fphp-current-end%2F</url>
    <content type="text"><![CDATA[current函数用于取数组第一个值，end函数用于取最后一个值 环境 PHP7.2 背景一个主任务中有许多子任务，每个子任务都有开始时间、结束时间。我想计算主任务耗费的总时长。代码如下123456789101112$arrData = [ [ 'start' =&gt; 1, 'end' =&gt; 10, ], [ 'start' =&gt; 12, 'end' =&gt; 20, ],];echo end($arrData)['end'] - current($arrData)['start']; 结果竟然是8，不能理解。 然后逐个打印这两个值。12345678910111213$arrData = [ [ 'start' =&gt; 1, 'end' =&gt; 10, ], [ 'start' =&gt; 12, 'end' =&gt; 20, ],];echo current($arrData)['start'], PHP_EOL; // 输出为1echo end($arrData)['end'] , PHP_EOL; // 输出为20 第一个输出为1，第二个输出为20。没问题啊，等等，如果先打印end，再打印current呢。12345678910111213$arrData = [ [ 'start' =&gt; 1, 'end' =&gt; 10, ], [ 'start' =&gt; 12, 'end' =&gt; 20, ],];echo end($arrData)['end'] , PHP_EOL; // 输出为20echo current($arrData)['start'], PHP_EOL; // 输出为12 第一个输出20，没问题，第二个输出12，输出12，输出12 ….. 翻开源码current函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546ext/standard/array.cPHP_FUNCTION(current)&#123; HashTable *array; zval *entry; ZEND_PARSE_PARAMETERS_START(1, 1) Z_PARAM_ARRAY_OR_OBJECT_HT(array) ZEND_PARSE_PARAMETERS_END(); // 重点zend_hash_get_current_data()函数， 获取当前指针指向的值 if ((entry = zend_hash_get_current_data(array)) == NULL) &#123; RETURN_FALSE; &#125; if (Z_TYPE_P(entry) == IS_INDIRECT) &#123; entry = Z_INDIRECT_P(entry); &#125; ZVAL_DEREF(entry); ZVAL_COPY(return_value, entry);&#125;Zend/zend_hash.h// 传址，当前的指针#define zend_hash_get_current_data(ht) \ zend_hash_get_current_data_ex(ht, &amp;(ht)-&gt;nInternalPointer)Zend/zend_hash.c// current函数传过来的为ht, &amp;(ht)-&gt;nInternalPointer// 获取ht的偏移量为pos的值ZEND_API zval* ZEND_FASTCALL zend_hash_get_current_data_ex(HashTable *ht, HashPosition *pos)&#123; uint32_t idx = *pos; Bucket *p; IS_CONSISTENT(ht); if (idx != HT_INVALID_IDX) &#123; p = ht-&gt;arData + idx; return &amp;p-&gt;val; &#125; else &#123; return NULL; &#125;&#125; 翻开源码end函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PHP_FUNCTION(end)&#123; HashTable *array; zval *entry; ZEND_PARSE_PARAMETERS_START(1, 1) Z_PARAM_ARRAY_OR_OBJECT_HT_EX(array, 0, 1) ZEND_PARSE_PARAMETERS_END(); // 重点将指针移到最后一个位置 zend_hash_internal_pointer_end(array); if (USED_RET()) &#123; // 重点zend_hash_get_current_data()函数， 获取当前指针指向的值 if ((entry = zend_hash_get_current_data(array)) == NULL) &#123; RETURN_FALSE; &#125; if (Z_TYPE_P(entry) == IS_INDIRECT) &#123; entry = Z_INDIRECT_P(entry); &#125; ZVAL_DEREF(entry); ZVAL_COPY(return_value, entry); &#125;&#125;// 重点看下这个zend_hash_internal_pointer_end函数Zend/zend_hash.h// 指针传址#define zend_hash_internal_pointer_end(ht) \ zend_hash_internal_pointer_end_ex(ht, &amp;(ht)-&gt;nInternalPointer)Zend/zend_hash.cZEND_API void ZEND_FASTCALL zend_hash_internal_pointer_end_ex(HashTable *ht, HashPosition *pos)&#123; uint32_t idx; IS_CONSISTENT(ht); HT_ASSERT(ht, &amp;ht-&gt;nInternalPointer != pos || GC_REFCOUNT(ht) == 1); idx = ht-&gt;nNumUsed; // 在这里循环 将当前的指针，指向最后一个 while (idx &gt; 0) &#123; idx--; if (Z_TYPE(ht-&gt;arData[idx].val) != IS_UNDEF) &#123; *pos = idx; return; &#125; &#125; *pos = HT_INVALID_IDX;&#125; 总结 先执行current，再执行end，没有问题。 先执行end，此时当前指针到了最后。再执行current，得到的值是最后的一个值。 源码注解：https://github.com/gxpisme/read_php/commit/f53beab43abf3549d00252b68e20bfb6ac9cf091 推荐看下PHP5.6的hash table结构。http://blog.xpisme.com/posts/PHP/2018/04/09/php-hashtable/推荐看下PHP7.2的hash table结构。http://blog.xpisme.com/posts/PHP/2018/04/19/php7-hashtable/]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的编译]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F15%2Fphp-token%2F</url>
    <content type="text"><![CDATA[PHP代码 编译过程 PHP的SAPI，SAPI处于PHP整个架构较上层，而真正脚本的执行主要由Zend引擎来完成。 编程语言 编程语言分类 编译型语言 运行前必须对源代码进行编译，然后运行编译后的目标文件。例如：C++、java 解释型语言 无需经过编译即可”运行”，可以理解为直接运行。例如：PHP、Python、Javascript 这些语言并不是真的直接就被能被机器理解，这些语言都需要一个解释器， 由解释器来执行这些源码， 实际上这些语言还是会经过编译环节， 只不过它们一般会在运行的时候实时进行编译。 为了效率，并不是所有语言在每次执行的时候都会重新编译一遍， 比如PHP的各种opcode缓存扩展、Python会将编译的中间文件保存成pyc/pyo文件。 PHP代码的编译过程 PHP代码先进行词法、语法分析生成抽象语法树(AST)然后再将抽象语法树编译为opcode 图解如下 将PHP转为tokenPHP中提供了一个函数token_get_all， 该函数接收一个字符串参数， 返回一个按照词法规则切分好的数组。函数token_name，该函数将数字转化为解析器代号。123456789101112&lt;?php$code = &lt;&lt;&lt;PHP_CODE&lt;?php$str = 'hi';echo $str;?&gt;PHP_CODE;$tokens = token_get_all($code);foreach ($tokens as $k =&gt; $v) &#123; $tokens[$k][0] = empty(token_name($v[0])) ? $v[0] : token_name($v[0]);&#125;print_r($tokens); 就是将这一小段代码转化为词法规则。1234&lt;?php$str = 'hi';echo $str;?&gt; 解析器代码列表 输出结果如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172Array( [0] =&gt; Array ( [0] =&gt; T_OPEN_TAG [1] =&gt; &lt;?php [2] =&gt; 1 ) [1] =&gt; Array ( [0] =&gt; T_WHITESPACE [1] =&gt; [2] =&gt; 2 ) [2] =&gt; = [3] =&gt; Array ( [0] =&gt; T_WHITESPACE [1] =&gt; [2] =&gt; 2 ) [4] =&gt; Array ( [0] =&gt; T_CONSTANT_ENCAPSED_STRING [1] =&gt; 'hi' [2] =&gt; 2 ) [5] =&gt; ; [6] =&gt; Array ( [0] =&gt; T_WHITESPACE [1] =&gt; [2] =&gt; 2 ) [7] =&gt; Array ( [0] =&gt; T_ECHO [1] =&gt; echo [2] =&gt; 3 ) [8] =&gt; Array ( [0] =&gt; T_WHITESPACE [1] =&gt; [2] =&gt; 3 ) [9] =&gt; ; [10] =&gt; Array ( [0] =&gt; T_WHITESPACE [1] =&gt; [2] =&gt; 3 ) [11] =&gt; Array ( [0] =&gt; T_CLOSE_TAG [1] =&gt; ?&gt; [2] =&gt; 4 )) PHP使用re2c完成这个阶段的工作，re2c是词法分析器，将输入分割为一个个有意义的词块，称为token。 词法、语法解析 词法分析读入PHP源代码，将PHP代码切割为可识别的token。语法分析根据token，生成抽象语法树（AST） $a = 12 + 5 - 1，经过词法、语法解析后生成AST树 参考资料http://www.php-internals.com/book/?p=chapt02/02-03-00-how-php-script-get-executedhttps://github.com/pangudashu/php7-internal/blob/master/3/zend_compile_parse.mdhttp://www.laruence.com/2008/06/18/221.html]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的SAPI]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F15%2Fphp-sapi%2F</url>
    <content type="text"><![CDATA[揭开PHP的SAPI神秘面纱 SAPI的示意图 SAPI的作用SAPI提供了一个和外部通信的接口。与外部通信一般表现为命令行下、web服务器下调用等。SAPI可以理解为用于与外部通信的一套接口（协议）。实现这套接口应用于命令行，则在命令行下与PHP内核交互时使用命令行下的这套接口。实现这套接口应用于web服务器，则在web服务器下与PHP内核交互时使用web服务器下的这套接口。 每个SAPI源码的目录 利用php_sapi_name函数确定使用的那种sapi在命令行下运行，则使用cli实现的sapi在web服务器（Nginx）下运行，则使用fpm实现的sapi SAPI的结构体sapi_module_struct1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556main/SAPI.hstruct _sapi_module_struct &#123; char *name; // 名字 标识用 char *pretty_name; // 更好理解的名字 int (*startup)(struct _sapi_module_struct *sapi_module); // 启动函数 当SAPI初始化时，首先会调用该函数。如果服务器处理多个请求时，该函数只会调用一次。 int (*shutdown)(struct _sapi_module_struct *sapi_module); // 关闭方法 它用来释放所有SAPI的数据结构，内存等。 int (*activate)(void); // 激活 此函数会在每个请求开始时调用，它会再次初始化每个请求前的数据结构。 int (*deactivate)(void); // 停用 此函数会在每个请求结束时调用，它用来确保释放activate中初始化的数据结构 size_t (*ub_write)(const char *str, size_t str_length); // 不缓存的写操作 unbuffered write 用来将PHP的数据输出给客户端 void (*flush)(void *server_context); // flush 刷新输出，在CLI模式下通过使用C语言的库函数fflush实现，在php_mode5模式下，使用Apache的提供的函数rflush实现。 zend_stat_t *(*get_stat)(void); // get uid char *(*getenv)(char *name, size_t name_len); // getenv void (*sapi_error)(int type, const char *error_msg, ...) ZEND_ATTRIBUTE_FORMAT(printf, 2, 3); //error handler 报告错误用，大多数的SAPI都是使用的PHP的默认实现php_error int (*header_handler)(sapi_header_struct *sapi_header, sapi_header_op_enum op, sapi_headers_struct *sapi_headers); //header handler int (*send_headers)(sapi_headers_struct *sapi_headers); // send headers handler void (*send_header)(sapi_header_struct *sapi_header, void *server_context); // send header handler 发送头部信息，此方法一般的SAPI都会定制，其所不同的是，有些的会调服务器自带的（如apache），有些需要自己实现（FastCGI） size_t (*read_post)(char *buffer, size_t count_bytes); // read POST data 此函数和read_cookie一样也是在SAPI激活是调用，他与请求的方法相关，当请求的方式是POST时，程序会操作$_POST/$HTTP_RAS_POST_DATA等变量 char *(*read_cookies)(void); // read Cookies 在SAPI激活时，程序会调用次函数，并且将此函数获取的值赋给SG request_info.cookie_data 在CLI模式下，函数会返回NULL void (*register_server_variables)(zval *track_vars_array); // register server variables void (*log_message)(char *message, int syslog_type_int); // Log message double (*get_request_time)(void); // Request Time void (*terminate_process)(void); // Child Terminate char *php_ini_path_override; // 覆盖的ini路径 void (*default_post_reader)(void); void (*treat_data)(int arg, char *str, zval *destArray); char *executable_location; int php_ini_ignore; int php_ini_ignore_cwd; /* don't look for php.ini in the current directory */ int (*get_fd)(int *fd); int (*force_http_10)(void); int (*get_target_uid)(uid_t *); int (*get_target_gid)(gid_t *); unsigned int (*input_filter)(int arg, char *var, char **val, size_t val_len, size_t *new_val_len); void (*ini_defaults)(HashTable *configuration_hash); int phpinfo_as_text; char *ini_entries; const zend_function_entry *additional_functions; unsigned int (*input_filter_init)(void);&#125;; cli模式的_sapi_module_struct123456789101112131415161718192021222324252627282930313233sapi/cli/php_cli.cstatic sapi_module_struct cli_sapi_module = &#123; "cli", /* name */ "Command Line Interface", /* pretty name */ php_cli_startup, /* startup */ php_module_shutdown_wrapper, /* shutdown */ NULL, /* activate */ sapi_cli_deactivate, /* deactivate */ sapi_cli_ub_write, /* unbuffered write */ sapi_cli_flush, /* flush */ NULL, /* get uid */ NULL, /* getenv */ php_error, /* error handler */ sapi_cli_header_handler, /* header handler */ sapi_cli_send_headers, /* send headers handler */ sapi_cli_send_header, /* send header handler */ NULL, /* read POST data 命令行模式下 没有post数据 */ sapi_cli_read_cookies, /* read Cookies */ sapi_cli_register_variables, /* register server variables */ sapi_cli_log_message, /* Log message */ NULL, /* Get request time */ NULL, /* Child terminate */ STANDARD_SAPI_MODULE_PROPERTIES&#125;; fpm模式下的_sapi_module_struct123456789101112131415161718192021222324252627282930313233sapi/fpm/fpm/fpm_main.cstatic sapi_module_struct cgi_sapi_module = &#123; "fpm-fcgi", /* name */ "FPM/FastCGI", /* pretty name */ php_cgi_startup, /* startup */ php_module_shutdown_wrapper, /* shutdown */ sapi_cgi_activate, /* activate */ sapi_cgi_deactivate, /* deactivate */ sapi_cgibin_ub_write, /* unbuffered write */ sapi_cgibin_flush, /* flush */ NULL, /* get uid */ sapi_cgibin_getenv, /* getenv */ php_error, /* error handler */ NULL, /* header handler */ sapi_cgi_send_headers, /* send headers handler */ NULL, /* send header handler */ sapi_cgi_read_post, /* read POST data */ sapi_cgi_read_cookies, /* read Cookies */ sapi_cgi_register_variables, /* register server variables */ sapi_cgi_log_message, /* Log message */ NULL, /* Get request time */ NULL, /* Child terminate */ STANDARD_SAPI_MODULE_PROPERTIES&#125;; php_sapi_name取的值就是sapi_module的name123456789101112PHP_FUNCTION(php_sapi_name)&#123; if (zend_parse_parameters_none() == FAILURE) &#123; return; &#125; if (sapi_module.name) &#123; RETURN_STRING(sapi_module.name); &#125; else &#123; RETURN_FALSE; &#125; &#125; TIPS大家可以观察下sapi/fpm/fpm/fpm_main.c下cgi_sapi_module的sapi_cgi_read_post函数。然后再观察下sapi/cli/php_cli.c下cli_sapi_module的获取post数据。发现cli（命令行模式）下获取post数据是NULL，因为命令行下没有POST数据。 你也可以看下获取cookie函数。 参考资料http://www.laruence.com/2008/08/12/180.htmlhttp://www.php-internals.com/book/?p=chapt02/02-02-00-overviewhttp://php.net/manual/zh/function.php-sapi-name.php]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从CGI到PHP-FPM]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F13%2Fphp-cgi%2F</url>
    <content type="text"><![CDATA[从CGI到PHP-FPM到底经历了什么？ CGI Web Server 与 Web Application 之间数据交换的一种协议就是CGI。Web Server 一般指Apache、Nginx、IIS、Lighttpd、Tomcat等服务器，Web Application 一般指PHP、Java、Asp.net等应用程序。 CGI程序，指的就是PHP程序、Java程序、Asp.net程序。 CGI缺点及例子 每次的CGI请求都需要新生成一个程序的副本来运行。fork一个子进程，然后在执行。 以PHP为例，fork一个子进程，需要解析php.ini，初始化执行环境(对应上一篇的MINIT函数)。 CGI程序运行在独立的进程中，并对每个Web请求创建一个进程，这种方法非常容易实现，但效率很差，难以扩展。面对大量请求，进程的大量创建和消亡使操作系统性能大大下降。 为了解决CGI这种低效的方式，因此就出现了FASTCGI。 FASTCGI FASTCGI生成一些解释器进程，这些解释器进程只是在创建时初始化环境，读取配置文件等等。如果再来CGI请求的，直接交给解释器进程执行即可。FASTCGI只是一个协议。 那么PHP-FPM又是什么呢？ PHP-FPM是实现了FASTCGI协议。 PHP-FPM PHP-FPM的管理对象是php-cgi(PHP解释器)因为PHP-CGI只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理。所以就出现了一些能够调度 php-cgi 进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。同样，PHP-FPM也是用于调度管理PHP解析器php-cgi的管理程序。 Fastcgi会先启一个master，解析配置文件，初始化执行环境，然后再启动多个worker。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着；当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是fastcgi的对进程的管理。PHP-FPM实现了FASTCGI协议。 可以平滑重启，因为master进程可以生成新的work进程，新的work进程就会读取php.ini文件，实现热加载。master进程通知老的work进程该消失了。 参考资料https://segmentfault.com/q/1010000000256516https://www.awaimai.com/371.htmlhttps://zh.wikipedia.org/wiki/FastCGI]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的生命周期]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F11%2Fphp-life-cycle%2F</url>
    <content type="text"><![CDATA[一段PHP程序从执行开始到结束，经历了什么？ PHP启动 会执行MINIT请求开始 会执行RINIT请求结束 会执行RSHUTDOWNPHP结束 会执行MSHUTDOWN PHP启动 模块初始化阶段（MINIT）启动CLI或者FPM时；apache中php模块，apache启动时，php的模块也会启动。新开启一个php进程时，此时就会执行MINIT。 例如PHP注册了一些扩展模块，则在MINIT阶段会回调所有模块的MINIT函数。例如调用MySQLI扩展模块的MINIT函数、PDO扩展模块的MINIT函数等等。看看php.ini文件里打开了哪些扩展。模块在这个阶段可以进行一些初始化工作，例如注册常量，定义模块使用的类等等。12345PHP_MINIT_FUNCTION(myphpextension)&#123; // 注册常量或者类等初始化操作 return SUCCESS; &#125; PDO的MINIT函数 MySQLI的MINIT部分函数 请求开始（RINIT）一旦PHP启动完成，PHP就会等着处理一个或多个请求。PHP在CLI模式下，一个脚本只能处理一个请求。在web server下， PHP-FPM或apache下，可以处理多个请求。在处理请求时，就会运行RINIT。 PHP会调用所有模块的RINIT函数， 在这个阶段各个模块也可以执行一些相关的操作123456PHP_RINIT_FUNCTION(myphpextension)&#123; // 例如记录请求开始时间 // 随后在请求结束的时候记录结束时间。这样我们就能够记录下处理请求所花费的时间了 return SUCCESS; &#125; 一个经典的例子是Session模块的RINIT，如果在php.ini中启用了Session模块，那在调用该模块的RINIT时就会初始化$_SESSION变量，并将相关内容读入 Session 的 RINIT函数 请求结束 (RSHUTDOWN，对应RINIT)执行到了文件结尾或exit、die函数终止，PHP就会启动清理程序，它会按顺序调用各个模块的RSHUTDOWN方法。清除程序运行时产生的符号表，也就是对每个变量调用unset函数。停止对这个请求的处理，准备处理下个请求。 PHP结束 释放各个模块内存 (MSHUTDOWN，对应MINIT)PHP最终会关闭自身，关闭php的进程就是MSHUTDOWN。PHP调用每个扩展的MSHUTDOWN方法，这是各个模块释放内存。 并行模型在CLI模式下，所有的东西都很简单，一个PHP进程处理一个请求，运行模式是单独的脚本执行，然后结束。但是在web server模式下比CLI模式下复杂的多。 在同一时间处理多个请求，在PHP中有两种存在模式。 多进程模式 在多进程模式下，每个PHP解释器都被操作系统隔离到自己的进程中。这种模式通常会运行在UNIX系统下。这种模式通常应用在PHP-CLI, PHP-FPM 和 PHP-CGI中。 多线程模式 在多线程模式下，每个PHP解释器都被隔离到一个线程中。这种模式通常会运行在Windows操作系统，但也能运行在UNIX系统下。PHP及它的扩展必须在线程安全的模式下。 从PHP扩展解析PHP扩展在一些阶段可以被PHP触发，这些阶段其实就是几个函数，这种又叫做钩子。我们来看下PHP扩展的结构zend_module_entry123456789101112131415161718192021222324252627282930struct _zend_module_entry &#123; unsigned short size; unsigned int zend_api; unsigned char zend_debug; unsigned char zts; const struct _zend_ini_entry *ini_entry; const struct _zend_module_dep *deps; const char *name; const struct _zend_function_entry *functions; int (*module_startup_func)(INIT_FUNC_ARGS); // MINIT int (*module_shutdown_func)(SHUTDOWN_FUNC_ARGS); // MSHUTDOWN int (*request_startup_func)(INIT_FUNC_ARGS); // RINIT int (*request_shutdown_func)(SHUTDOWN_FUNC_ARGS); // RSHUTDOWN void (*info_func)(ZEND_MODULE_INFO_FUNC_ARGS); // PHPINFO const char *version; size_t globals_size;#ifdef ZTS ts_rsrc_id* globals_id_ptr;#else void* globals_ptr;#endif void (*globals_ctor)(void *global); // GINIT void (*globals_dtor)(void *global); // GSHUTDOWN int (*post_deactivate_func)(void); // RPSHUTDOWN int module_started; unsigned char type; void *handle; int module_number; const char *build_id;&#125;; 总结 参考文献http://www.php-internals.com/book/?p=chapt02/02-01-php-life-cycle-and-zend-enginehttp://www.laruence.com/2008/08/12/180.htmlhttp://www.phpinternalsbook.com/php7/extensions_design/php_lifecycle.html]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP HashTable]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F09%2Fphp-hashtable%2F</url>
    <content type="text"><![CDATA[HashTable 环境 PHP5.6PHP的数组使用哈希表（HashTable）来存储关联数据，PHP内核中的哈希表是十分重要的数据结构，PHP的大部分的语言特性都是基于哈希表实现的。 哈希表基本原理 哈希函数12345伪代码HASH_INDEX(ht, int key) &#123; return key % ht-&gt;size;&#125; 操作接口初始化123456789伪代码int hash_init(HashTable *ht)&#123; ht-&gt;size = HASH_TABLE_INIT_SIZE; ht-&gt;elem_num = 0; ht-&gt;buckets = calloc(ht-&gt;size, sizeof(Bucket *)); return SUCCESS;&#125; 内容插入到哈希表中1234567891011121314151617181920212223242526272829303132伪代码（细节待完善）int hash_insert(HashTable *ht, char *key, void *value)&#123; // 判断是否需要重哈希 resize_hash_table_if_needed(ht); // 通过哈希函数获取bucket int index = HASH_INDEX(ht, key); Bucket *tmp_bucket = ht-&gt;buckets[index]; // key已经存在，循环冲突的链表，如果找到key则更新其value while(tmp_bucket) &#123; if(strcmp(key, tmp_bucket-&gt;key) == 0) &#123; tmp_bucket-&gt;value = value; return SUCCESS; &#125; tmp_bucket = tmp_bucket-&gt;next; &#125; // 生成新的元素 Bucket *bucket = (Bucket *)malloc(sizeof(Bucket)); bucket-&gt;key = key; bucket-&gt;value = value; bucket-&gt;next = NULL; ht-&gt;buckets[index]= bucket; // 总的元素+1 ht-&gt;elem_num += 1; return SUCCESS;&#125; 重哈希12345678910111213141516171819202122232425262728293031323334353637伪代码resize_hash_table_if_needed(HashTable *ht)&#123; // buckets的长度小于等于总的元素 if(ht-&gt;size - ht-&gt;elem_num &lt; 1) &#123; hash_resize(ht); &#125;&#125;static int hash_resize(HashTable *ht)&#123; // 原来长度的两倍 int org_size = ht-&gt;size; ht-&gt;size = ht-&gt;size * 2; ht-&gt;elem_num = 0; // 新的buckets Bucket **buckets = (Bucket **)calloc(ht-&gt;size, sizeof(Bucket *)); Bucket **org_buckets = ht-&gt;buckets; ht-&gt;buckets = buckets; int i = 0; for(i=0; i &lt; org_size; ++i) &#123; Bucket *cur = org_buckets[i]; while(cur) &#123; // 重哈希，重新插入 hash_insert(ht, cur-&gt;key, cur-&gt;value); // 链表循环（冲突的hash值） cur = cur-&gt;next; &#125; &#125; free(org_buckets); return SUCCESS;&#125; PHP中哈希表的实现存储结构1234567891011121314151617181920212223242526272829typedef struct bucket &#123; ulong h; // 如果键是数字，那么h指的就是数字；如果键是字符串，那么h指的是字符串经过hash后获得int型值 uint nKeyLength; // hash关键字的长度，如果数组索引为数字，此值为0 void *pData; // 指向value，一般是用户数据的副本，如果是指针数据，则指向pDataPtr void *pDataPtr; // 如果是指针数据，此值会指向真正的vaule，同时上面pData会指向此值 struct bucket *pListNext; // 整个hash表的下一个元素 struct bucket *pListLast; // 整个hash表的上一个元素 struct bucket *pNext; // 同一个 Bucket内的下一个元素 struct bucket *pLast; // 同一个 Bucket内的上一个元素 const char *arKey; // 保存当前值所对于的key字符串，这个字段只能定义在最后，实现变长的结构体&#125; Bucket;typedef struct _hashtable &#123; uint nTableSize; // hash Bucket的大小，最小为8， 以2n增长 nTableSize字段用于标示哈希表的容量 uint nTableMask; // nTableMask-1 索引取值的优化 uint nNumOfElements; // 整个hash table 中当前存在的元素个数，count() 函数会直接返回比值 ulong nNextFreeElement; // 下一个数字索引的位置 Bucket *pInternalPointer; /* Used for element traversal 当前遍历的指针 （foreach比for快的原因之一 ）*/ Bucket *pListHead; // 存储数组头元素指针 Bucket *pListTail; // 存储数组尾元素指针 Bucket **arBuckets; // 存储hash数组 dtor_func_t pDestructor; // 在删除元素时执行的回调函数，用于资源的释放 zend_bool persistent; // 指出了Bucket内存的分配方式，如果persistent为true，则使用操作系统本身的内存分配函数为Bucket分配内存，否则使用PHP的内存分配函数 unsigned char nApplyCount; // 标记当前 hash Bucket被递归访问的次数（防止多次递归） zend_bool bApplyProtection; // 标记当前hash桶运行不允许多次访问，不允许访问时，最多只能递归3次#if ZEND_DEBUG int inconsistent;#endif&#125; HashTable; hashtable的pListHead存储数组头元素指针，bucket的pListNext 整个hash表的下一个元素 hashtable的pListTail存储数组尾元素指针，bucket的pListLast 整个hash表的上一个元素 bucket的pNext同一个hash Bucket内的下一个元素(红色) bucket的pLast同一个hash bucket的下一个元素 哈希表的初始化 hash_init12345678910111213141516171819202122232425262728293031Zend/zend_hash.cZEND_API int _zend_hash_init(HashTable *ht, uint nSize, dtor_func_t pDestructor, zend_bool persistent ZEND_FILE_LINE_DC)&#123; uint i = 3; SET_INCONSISTENT(HT_OK); if (nSize &gt;= 0x80000000) &#123; /* prevent overflow 防止溢出 */ ht-&gt;nTableSize = 0x80000000; &#125; else &#123; while ((1U &lt;&lt; i) &lt; nSize) &#123; i++; &#125; ht-&gt;nTableSize = 1 &lt;&lt; i; &#125; ht-&gt;nTableMask = 0; /* 0意味着ht-&gt;arBuckets未初始化 */ ht-&gt;pDestructor = pDestructor; ht-&gt;arBuckets = (Bucket**)&amp;uninitialized_bucket; ht-&gt;pListHead = NULL; ht-&gt;pListTail = NULL; ht-&gt;nNumOfElements = 0; ht-&gt;nNextFreeElement = 0; ht-&gt;pInternalPointer = NULL; ht-&gt;persistent = persistent; ht-&gt;nApplyCount = 0; ht-&gt;bApplyProtection = 1; return SUCCESS;&#125; 计算哈希值1234567h = zend_inline_hash_func(arKey, nKeyLength);nIndex = h &amp; ht-&gt;nTableMask;ht-&gt;nTableMask的大小为ht-&gt;nTableSize -1。 这里使用&amp;操作mask的作用就是将哈希值映射到槽位所能存储的索引范围内。例如：某个key的索引值是21， 哈希表的大小为8，则mask为7， 则求与时的二进制表示为： 10101 &amp; 111 = 101 也就是十进制的5。 插入内容到哈希表建议看源码 Zend/zend_hash.c 文件中 _zend_hash_add_or_update函数 如果Bucket中已经存在该元素，则遍历整个Bucket，查找是否存在相同的key值元素，如果有并且是update调用，则执行update数据操作。 创建新的Bucket元素，初始化数据，并将新元素添加到当前hash值对应的Bucket链表的最前面（CONNECT_TO_BUCKET_DLLIST）。 这也是为什么上面图中 插入顺序为bucket1，bucket2，bucket3。bucket1与bucket2冲突，bucket2在前面的原因 总结 HashTable 是采用拉链法解决hash冲突的，了解到计算哈希值的计算规则，一些黑客利用这个特性，插入许多hash冲突的元素，则会将时间复杂度O(1)退化到O(N)。 HashTable 是使用两个结构进行存储的 hashtable和bucket，hashtable中存在一些必要的元素，例如：元素的总数，头指针、尾指针等，bucket中存在哈希冲突的指针和整个HashTable的指针。因此HashTable是双向链表，其中的bucket也是双向链表。 HashTable是双向链表，因此实现 (array_pop 删除尾部元素 array_push 向尾部加入元素 array_shift 删除头部元素 array_unshift 向头增加元素) 轻而易举。 参考文献哈希冲突： https://blog.csdn.net/qq_27093465/article/details/52269862PHP中的hash算法： http://www.laruence.com/2009/07/23/994.htmlPHP数组的Hash冲突实例：http://www.laruence.com/2011/12/30/2435.html哈希表(HashTable)：http://www.php-internals.com/book/?p=chapt03/03-01-01-hashtablePHP的哈希表实现： http://www.php-internals.com/book/?p=chapt03/03-01-02-hashtable-in-php]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建PHP环境（PHP5.6）]]></title>
    <url>%2Fposts%2FPHP%2F2018%2F04%2F08%2Fbuild-enviorment-for-php%2F</url>
    <content type="text"><![CDATA[搭建PHP5.6环境 背景搭建简单的PHP5.6环境供调试使用。 搭建PHP5.6环境安装PHP5.6123456下载 wget http://cn2.php.net/get/php-5.6.35.tar.gz/from/this/mirror -O php-5.6.35.tar.gz解压 tar xzvf php-5.6.35.tar.gz cd php-5.6.35安装三步曲 ./configure --disable-all --prefix=/yourpath/php5 make make install 安装vld扩展1234567下载 wget http://pecl.php.net/get/vld-0.14.0.tgz解压 tar xzvf vld-0.14.0.tgz cd vld-0.14.0安装扩展小四步 /yourpath/php5/bin/phpize ./configure --with-php-config=/yourpath/php5/bin/php-config --enable-vld make make install 创建/yourpath/php5/lib/php.iniphp.ini文件中的内容为12extension_dir="/yourpath/php5/lib/php/extensions/no-debug-non-zts-20131226"extension="vld.so" 安装xdebug扩展12345678下载 wget https://xdebug.org/files/xdebug-2.5.5.tgz解压 tar xzvf xdebug-2.5.5.tgz cd xdebug-2.5.5安装扩展小四步 /yourpath/php5/bin/phpize ./configure --with-php-config=/yourpath/php5/bin/php-config --enable-xdebug make make install 添加到php.ini中，由于xdebug必须在zend的扩展中，所以php.ini配置如下123extension_dir="/yourpath/php5/lib/php/extensions/no-debug-non-zts-20131226"extension="vld.so"zend_extension="/yourpath/php5/lib/php/extensions/no-debug-non-zts-20131226/xdebug.so" 查看安装的模块123456789101112131415[xpisme@aliyun ~]$ /yourpath/php5/bin/php -m[PHP Modules]CoredateeregpcreReflectionSPLstandardvldxdebug[Zend Modules]Xdebug vld使用：http://www.php-internals.com/book/?p=C-php-vld]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘阵列（RAID）]]></title>
    <url>%2Fposts%2Fprogramming%2F2018%2F03%2F21%2Fraid%2F</url>
    <content type="text"><![CDATA[独立硬盘冗余阵列（RAID, Redundant Array of Independent Disks），旧称廉价磁盘冗余阵列（Redundant Array of Inexpensive Disks），简称磁盘阵列。 把多个相对便宜的硬盘组合起来，称为一个硬盘阵列组，使性能达到甚至超过一个价格昂贵、容量巨大的硬盘。 标准RAIDRAID 0 将两个以上的磁盘并联起来，称为一个大容量的磁盘。 在所有的级别中，RAID 0的速度最快。 RAID 0没有冗余功能、不具备容错能力。RAID 1 两组以上的N个磁盘互相作镜像。 再多线程操作系统中有很好的读取速度，理论上读取速度等于硬盘数量的倍数。 写入速度有下降 数据安全性最好RAID 2 以汉明码（Hamming Code）的方式将数据进行编码后分区为独立的比特，并将数据分别写入硬盘中。因为在数据中加入了错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些，RAID2最少要三台磁盘驱动器方能运作。 在写入时，RAID 2在写入数据位同时还要计算出它们的汉明码并写入校验阵列，读取时也要对数据即时地进行校验，最后再发向系统。 主要为了即时校验以保证数据安全，但由于花费太大RAID 3 RAID 3是把数据分成多个“块”，按照一定的容错算法，存放在N+1个硬盘上，实际数据占用的有效空间为N个硬盘的空间总和，而第N+1个硬盘上存储的数据是校验容错信息 校验盘很容易成为整个系统的瓶颈 RAID3更加适合应用于那些写入操作较少，读取操作较多的应用环境 安全性得到保证RAID 4 与RAID 3不同的是它在分区时是以区块为单位分别存在硬盘中，但每次的数据访问都必须从同比特检查的那个硬盘中取出对应的同比特数据进行核对，由于过于频繁的使用，所以对硬盘的损耗可能会提高。（块交织技术，Block interleaving）RAID 5 RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。RAID 6 与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。 查看服务器raid信息http://www.51niux.com/?id=77 参考资料https://zh.wikipedia.org/wiki/RAIDhttps://baike.baidu.com/item/RAID%201https://baike.baidu.com/item/RAID%202https://baike.baidu.com/item/RAID%203https://baike.baidu.com/item/RAID%204https://baike.baidu.com/item/RAID%205https://baike.baidu.com/item/RAID%206]]></content>
      <tags>
        <tag>硬盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[慢查询&分析SQL]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2018%2F03%2F13%2Fmysql-slow-log%2F</url>
    <content type="text"><![CDATA[slow log &amp; profiling sql 找出MySQL服务器的慢查询，分析特定SQL语句使用的是MySQL5.6 慢查询1234567891011121314151617181920212223242526是否开启慢查询日志 (ON开启 OFF关闭)mysql&gt; show variables like 'slow_query_log';+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | ON |+----------------+-------+1 row in set (0.00 sec)慢查询日志存放的位置mysql&gt; show variables like 'slow_query_log_file';+---------------------+--------------------------------+| Variable_name | Value |+---------------------+--------------------------------+| slow_query_log_file | /var/lib/mysql/aliyun-slow.log |+---------------------+--------------------------------+1 row in set (0.00 sec)耗时大于long_query_time的都会记录到日志中mysql&gt; show variables like 'long_query_time';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 10.000000|+-----------------+----------+1 row in set (0.00 sec) long_query_time=0 则会记录所有的查询 分析慢查询工具pt-query-digestpt-query-digest官网 安装使用12345wget percona.com/get/percona-toolkit.tar.gztar xzvf percona-toolkit.tar.gz./percona-toolkit-3.0.7/bin/pt-query-digest /var/lib/mysql/aliyun-slow.log 若出现错误12Can't locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at ./percona-toolkit-3.0.7/bin/pt-query-digest line 2470.BEGIN failed--compilation aborted at ./percona-toolkit-3.0.7/bin/pt-query-digest line 2470. 则 yum install perl-Digest-MD5 效果截图 分析特定SQL使用 SHOW PROFILE准备数据sakilasakila数据下载sakila数据安装 使用PROFILE123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354开始PROFILEmysql&gt; set profiling = 1;mysql&gt; select * from sakila.nicer_but_slower_film_list;997 rows in set (0.25 sec)mysql&gt; show profiles;+----------+------------+-------------------------------------------------+| Query_ID | Duration | Query |+----------+------------+-------------------------------------------------+| 1 | 0.24953300 | select * from sakila.nicer_but_slower_film_list |+----------+------------+-------------------------------------------------+1 rows in set (0.00 sec)mysql&gt; show profile for query 1;+----------------------+----------+| Status | Duration |+----------------------+----------+| starting | 0.000096 || checking permissions | 0.000012 || Opening tables | 0.000248 || checking permissions | 0.000004 || checking permissions | 0.000003 || checking permissions | 0.000002 || checking permissions | 0.000002 || checking permissions | 0.000112 || init | 0.002236 || System lock | 0.000018 || optimizing | 0.000005 || optimizing | 0.001518 || statistics | 0.097620 || preparing | 0.001815 || Creating tmp table | 0.000087 || Sorting result | 0.000008 || statistics | 0.000013 || preparing | 0.000006 || executing | 0.000286 || Sending data | 0.000016 || executing | 0.000002 || Sending data | 0.127138 || Creating sort index | 0.015985 || removing tmp table | 0.000236 || Creating sort index | 0.001276 || end | 0.000007 || query end | 0.000006 || closing tables | 0.000002 || removing tmp table | 0.000180 || closing tables | 0.000031 || freeing items | 0.000015 || removing tmp table | 0.000006 || freeing items | 0.000526 || cleaning up | 0.000022 |+----------------------+----------+34 rows in set, 1 warning (0.00 sec) 查询information_schema中的PROFILING12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849mysql&gt; use information_schema;Database changedmysql&gt; set @query_id=1;Query OK, 0 rows affected (0.00 sec)mysql&gt; select -&gt; state, -&gt; sum(duration) as total_r, -&gt; round( -&gt; 100 * sum(duration) / -&gt; (select sum(duration) -&gt; from profiling -&gt; where query_id=@query_id -&gt; ), 2) as pct_r, -&gt; count(1) as calls, -&gt; sum(duration)/count(*) as "R/call" -&gt; from -&gt; profiling -&gt; where query_id=@query_id -&gt; group by state -&gt; order by total_r desc;+----------------------+----------+-------+-------+--------------+| state | total_r | pct_r | calls | R/call |+----------------------+----------+-------+-------+--------------+| Sending data | 0.127154 | 50.96 | 2 | 0.0635770000 || statistics | 0.097633 | 39.13 | 2 | 0.0488165000 || Creating sort index | 0.017261 | 6.92 | 2 | 0.0086305000 || init | 0.002236 | 0.90 | 1 | 0.0022360000 || preparing | 0.001821 | 0.73 | 2 | 0.0009105000 || optimizing | 0.001523 | 0.61 | 2 | 0.0007615000 || freeing items | 0.000541 | 0.22 | 2 | 0.0002705000 || removing tmp table | 0.000422 | 0.17 | 3 | 0.0001406667 || executing | 0.000288 | 0.12 | 2 | 0.0001440000 || Opening tables | 0.000248 | 0.10 | 1 | 0.0002480000 || checking permissions | 0.000135 | 0.05 | 6 | 0.0000225000 || starting | 0.000096 | 0.04 | 1 | 0.0000960000 || Creating tmp table | 0.000087 | 0.03 | 1 | 0.0000870000 || closing tables | 0.000033 | 0.01 | 2 | 0.0000165000 || cleaning up | 0.000022 | 0.01 | 1 | 0.0000220000 || System lock | 0.000018 | 0.01 | 1 | 0.0000180000 || Sorting result | 0.000008 | 0.00 | 1 | 0.0000080000 || end | 0.000007 | 0.00 | 1 | 0.0000070000 || query end | 0.000006 | 0.00 | 1 | 0.0000060000 |+----------------------+----------+-------+-------+--------------+19 rows in set (0.00 sec)--- 可以很清楚看到该sql在哪个阶段耗时较长。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工具]]></title>
    <url>%2Fposts%2F%E6%8A%98%E8%85%BE%2F2018%2F03%2F05%2Ftool%2F</url>
    <content type="text"><![CDATA[日常小工具 截全屏chrome 第一步：F12 第二步：ctrl + shift + p 第三步：输入 full；回车即可]]></content>
      <categories>
        <category>折腾</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入缓冲]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2018%2F02%2F28%2Finnodb-insert-buffer%2F</url>
    <content type="text"><![CDATA[学习 InnoDB-插入缓冲 InnoDB存储引擎可以大幅度提高数据中非唯一索引的插入性能。 为什么必须是非唯一索引InnoDB中有分为主键索引、非唯一索引、唯一索引。12345678CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `phone` char(11) DEFAULT NULL, `name` varchar(30) DEFAULT NULL, PRIMARY KEY (`id`), //主键索引 KEY `name` (`name`), //非唯一索引 UNIQUE KEY `phone` (`phone`) //唯一索引) ENGINE=InnoDB DEFAULT CHARSET=utf8 对于自增主键值的插入是顺序的，非随机IO，因此插入有较高的性能。 对于非唯一索引，插入也不是有序，通过insert buffer技术，提升插入新能。 对于唯一索引，插入不是有序的；并且还需要查找插入值与已存在的值是否冲突，并不能使用Insert Buffer，因此性能并不好。 Insert Buffer原理对于非唯一索引的插入或更新操作，不是每次都直接插入到索引页，而是先判断插入的非唯一索引页是否在缓冲池中，若在，则插入；若不在，则放入Insert Buffer中。表象是非唯一索引页插入到叶子结点，本质上存在了另一个位置。然后再以一定的频率，将多个插入合并到一个操作中。这就很大幅度上提高了非唯一索引插入的性能。InnoDB关键特性之Insert Buffer Change BufferInnoDB从1.0.x版本开始引入Change Buffer，也可认为是Insert Buffer的升级。InnoDB可以对DML操作进行缓冲，分别是Insert Buffer、Delete Buffer、Purge Buffer。对一条记录进行UPDATE操作可分为两个过程。 将记录标记为删除 真正将记录删除因此Delete Buffer对应UPDATE的第一个过程。Purge Buffer对应UPDATE操作第二个过程。同时，InnoDB存储引擎提供了参数innodb_change_buffering，用来开启各种buffer选项。该参数可选的值为：inserts、deletes、purges、changes、all、none。其中inserts、deletes、purges就是前面讨论的三种情况。changes包含inserts和deletes，all表示启用所有，none表示都不启用。该参数值默认为all。 该参数innodb_change_buffer_max_size，来控制Change Buffer最大使用内存的数量。innodb_change_buffer_max_size默认为25，表示最多使用1/4的缓冲池内存空间。 merged operations中insert表示Insert Buffer，20462次；delete mark表示Delete Buffer，20158次；delete表示Purge buffer 4215次。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[敏感词设计]]></title>
    <url>%2Fposts%2F%E7%AE%97%E6%B3%95%2F2018%2F02%2F05%2Fconfilter-word%2F</url>
    <content type="text"><![CDATA[通用的敏感词服务 背景 敏感词在各个论坛、网站中都会应用到，通常在发帖、评论等等地方出现。为了防止用户输入敏感词汇，例如：迷信邪教、黄赌毒、枪支弹药类、不文明用户词汇。 设计简单 每个人都能想到的方法，for循环所有的敏感词，一一对输入的词汇进行查找匹配。123456789101112131415/** * PHP语言 * * 敏感词过滤 * @param string $strContent 需要校验的词汇 * @return boolean */function check($strContent) &#123; foreach ($invalidGoodsName as $value) &#123; if (false !== stripos($strContent, $value)) &#123; return false; &#125; &#125; return true;&#125; 这种匹配的方式，效率低，性能低下。 树形结构 根据敏感词构建树形结构（例如：王八蛋、王八羔子） 如果敏感词是（王八、王八蛋、王八羔子），构建出来的树，与上面一致。 为了解决这种情况，需要增加敏感词是否结束的标识。最终构建树形结构如下 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class DFA&#123; private $arrHashMap = []; public function __construct() &#123; $this-&gt;arrHashMap = json_decode(file_get_contents('tire.tree'), true); &#125; /** * 将构造好的树形结构存储在文件中。 * @return */ public function putHashMap() &#123; file_put_contents('tire.tree', json_encode($this-&gt;arrHashMap)); &#125; /** * 构建树形结构 * @param string $strWord 敏感词汇 */ public function addKeyWord($strWord) &#123; $len = mb_strlen($strWord, 'UTF-8'); // 传址 $arrHashMap = &amp;$this-&gt;arrHashMap; for ($i=0; $i &lt; $len; $i++) &#123; $word = mb_substr($strWord, $i, 1, 'UTF-8'); // 已存在 if (isset($arrHashMap[$word])) &#123; if ($i == ($len - 1)) &#123; $arrHashMap[$word]['end'] = 1; &#125; &#125; else &#123; // 不存在 if ($i == ($len - 1)) &#123; $arrHashMap[$word] = []; $arrHashMap[$word]['end'] = 1; &#125; else &#123; $arrHashMap[$word] = []; $arrHashMap[$word]['end'] = 0; &#125; &#125; // 传址 $arrHashMap = &amp;$arrHashMap[$word]; &#125; &#125; /** * 判断输入词汇中是否存在敏感词 * @param string $strWord 输入词汇 * @return boolean */ public function searchKey($strWord) &#123; $len = mb_strlen($strWord, 'UTF-8'); $arrHashMap = $this-&gt;arrHashMap; for ($i=0; $i &lt; $len; $i++) &#123; $word = mb_substr($strWord, $i, 1, 'UTF-8'); if (!isset($arrHashMap[$word])) &#123; // reset hashmap $arrHashMap = $this-&gt;arrHashMap; continue; &#125; if ($arrHashMap[$word]['end']) &#123; return true; &#125; $arrHashMap = $arrHashMap[$word]; &#125; return false; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 搭建Hadoop环境]]></title>
    <url>%2Fposts%2FHadoop%2F2018%2F01%2F17%2Fbuild-hadoop-enviorment%2F</url>
    <content type="text"><![CDATA[CentOS 搭建Hadoop环境 笔者是使用的阿里云的机器 安装软件ssh1sudo yum install ssh rsync1sudo yum install rsync java下载JDK从http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 选择下载JDK的最新版本 JDK 8。 我选择的是：jdk-8u161-linux-x64.tar.gz 解压&amp;安装123456sudo mkdir -p /usr/local/javasudo cp /your_path/jdk-8u161-linux-x64.tar.gz /usr/local/javacd /usr/local/javatar xzvf jdk-8u161-linux-x64.tar.gz rm jdk-8u161-linux-x64.tar.gz ln -s jdk1.8.0_161 /usr/local/java/latest 配置环境变量1234在 ~/.bashrc 下添加JAVA_HOME="/usr/local/java/latest"JRE_HOME="/usr/local/java/latest/jre"PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/usr/local/java/latest/bin" 环境变量配置生效source ~/.bashrc 然后要告诉系统，我们使用的是sun的JDK，而非OpenJDK123sudo update-alternatives --install /usr/bin/java java /usr/local/java/jdk1.8.0_161/bin/java 300sudo update-alternatives --install /usr/bin/javac javac /usr/local/java/jdk1.8.0_161/bin/javac 300sudo update-alternatives --config java 12345执行 java -version命令java version "1.8.0_161"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode) 安装Hadoop下载hadoop从http://hadoop.apache.org/releases.html 找到一个你想要的版本，下载binary包1234sudo cp /your_path/hadoop-3.0.0-src.tar.gz /usr/local/hadoopcd /usr/local/hadooptar xzvf hadoop-3.0.0-src.tar.gzrm hadoop-3.0.0-src.tar.gz 配置JAVA_HOME123vim ./etc/hadoop/hadoop-env.shJAVA_HOME=/usr/local/java/latest 尝试命令bin/hadoop将会显示hadoop 脚本的使用文档 demoinput的数据1234567891011121314mkdir /tmp/input/vim /tmp/input/citycity中的数据如下| 1 | 上海 | shanghai | 上海市 | 10009 | 310000 | 2 | 31.2304 | 121.474 | 1 | 1514276827 | 1514276827 || 2 | 杭州 | hangzhou | 杭州市 | 10011 | 330100 | 2 | 30.2742 | 120.155 | 1 | 1514276820 | 1514276820 || 3 | 北京 | beijing | 北京市 | 10001 | 110000 | 2 | 39.9047 | 116.407 | 1 | 1514276821 | 1514276821 || 4 | 广州 | guangzhou | 广州市 | 10019 | 440100 | 2 | 23.1291 | 113.264 | 1 | 1514276823 | 1514276823 || 5 | 天津 | tianjin | 天津市 | 10002 | 120000 | 2 | 39.0851 | 117.199 | 0 | 1514276822 | 1514276822 || 6 | 南京 | nanjing | 南京市 | 10010 | 320100 | 2 | 31.8418 | 118.505 | 0 | 1514276820 | 1514276820 || 7 | 武汉 | wuhan | 武汉市 | 10017 | 420100 | 2 | 30.5928 | 114.305 | 0 | 1514276821 | 1514276821 || 8 | 苏州 | suzhou | 苏州市 | 10010 | 320500 | 2 | 31.2983 | 120.583 | 1 | 1514276820 | 1514276820 || 9 | 福州 | fuzhou | 福州市 | 10013 | 350100 | 2 | 26.0742 | 119.296 | 1 | 1514276821 | 1514276821 || 10 | 哈尔滨 | haerbin | 哈尔滨市 | 10008 | 230100 | 2 | 45.8022 | 126.536 | 1 | 1514276826 | 1514276826 | 执行命令./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar grep /tmp/input /tmp/output &apos;100&apos; 查看输出结果，就可以了cd /tmp/output 参考资料https://hadoop.apache.org/docs/r1.0.4/cn/quickstart.htmlhttps://www.cnblogs.com/yangyquin/p/5021074.htmlhttp://www.powerxing.com/install-hadoop-in-centos/]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB的行锁]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2018%2F01%2F15%2Finnodb-row-lock%2F</url>
    <content type="text"><![CDATA[InnoDB特有的行锁 行锁的三种算法- Record Lock 单个记录上的锁 - Gap Lock 间隙锁，锁定一个范围，但不含记录本身 - Next-Key Lock Record+Gap，锁定一个范围，并锁定记录本身 在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。假设一个索引有10,11,13,20这四个值，那么该索引可能被Next-Key Locking的区间为12345(-∞, 10](10, 11](11, 13](13, 20](20, +∞) 除了Next-Key 还有一种是Previous-Key 其区间为12345(-∞, 10)[10, 11)[11, 13)[13, 20)[20, +∞) 非唯一索引 （Next-Key） Next-Key Lock是一个范围，包含本身的前后范围。 12345drop table if exists t;create table t ( a int, key(a));insert into t select 1;insert into t select 2;insert into t select 5; 时间 会话A 会话B 1 Begin 2 select * from t where a = 5 for update 3 begin 4 insert into t select 4 4 insert into t select 6 4 select * from t where a = 5 lock in share mode 4 insert into t select 2 4 这几条命令都会阻塞。 图解 唯一索引 （Next-Key 降级为 Record-Key） 查询的索引含有唯一属性时，InnoDB存储引擎会对Next-Key 降级为Record-Key。 主键 primary key12345drop table if exists t;create table t ( a int primary key);insert into t select 1;insert into t select 2;insert into t select 5; 时间 会话A 会话B 1 Begin 2 select * from t where a = 5 for update 3 begin 4 insert into t select 4 5 commit 立即成功 6 commit - 表t中共有1、2、5 三个值。会话A中首先对a=5进行锁定，由于a是主键，主键都是唯一的。因此就从Next-Key Lock 降级为Record Lock，仅锁定5这个值。而不是范围(2, 5] (5, +∞)，因此插入4这个值非阻塞。 唯一索引 unique key12345drop table if exists t;create table t ( a int, unique key (a));insert into t select 1;insert into t select 2;insert into t select 5; 时间 会话A 会话B 1 Begin 2 select * from t where a = 5 for update 3 begin 4 insert into t select 4 5 commit 立即成功 6 commit - 证明是唯一索引，就会从Next-Key Lock 降级为Record Lock]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB 共享锁/排他锁/意向共享锁/意向排他锁]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2018%2F01%2F15%2Fshare-exclusive-lock%2F</url>
    <content type="text"><![CDATA[共享锁、排他锁、意向共享锁、意向排他锁 共享锁和排他锁 InnoDB在行锁上实现了两种标准的锁，共享锁（shared locks）和排他锁（exclusive locks）共享锁简称S锁，排他锁简称X锁。 共享锁（S锁）允许事务读一行数据 排他锁（X锁）允许事务删除或更新一行数据 事务T1获得了行r的共享锁。如果事务T2也要获取行r的共享锁，此时是可以的，即锁兼容，因为都是读数据。如果事务T2要获取行r的排他锁，则必须等到T1释放r的共享锁，才能获得行r的排他锁，即锁不兼容，因为如果T2可以获得排他锁，则会修改行r的数据，则T1再去读取数据时，就会发生不一致。 意向共享锁和意向排他锁 事务T1在某一行加上了S锁，事务T1锁住了表中的一行，让这一行只能读，不能写。事务T2申请整个表的X锁，申请整个表的写锁。如何判断是否可以申请成功？判断每一行是否有锁，需要遍历整个表。为了应对这种低效的情况，意向锁应运而生。(只是自己的理解，如有疑问，欢迎讨论) 意向共享锁（Intention shared lock）（IS锁） 意向排他锁（Intention exclusive lock）（IX锁） 12345SELECT ... LOCK IN SHARE MODE会先给表加上IS锁，在给对应的行加上S锁。SELECT ... FOR UPDATE会先给表加上IX锁，在给对应的行加上X锁。 按照刚才的例子 事务T1在行r加上了S锁，则会先在表t加上IS锁，然后在表t中行r加上S锁。 事务T2申请整个表的X锁，由于X锁与IS锁不兼容。则需要事务T1释放IS锁，S锁，事务T2才能申请成功。 IX锁与X锁（行级别X锁） Session A 请求 IX–成功，Session B请求 IX–成功 Session A 请求 X，只要Session A 和 Session B操作的行无交集，就不会发生冲突。 IX锁与S锁（行级别S锁） Session A 请求 IX–成功，Session B请求 IS–成功（在申请S锁之前，必须先申请IS锁） Session B 请求 S锁，只要Session A 和 Session B操作的行，无交集，则不会发生冲突。 Session A 操作 第1,2,3行数据，Session B 操作第4行数据，则不会冲突。 Session A 操作 第1,2,3行数据，Session B 操作第1行数据，则会冲突。 参考文献 https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html InnoDB存储引擎 第二版 https://www.zhihu.com/question/51513268 http://blog.csdn.net/huyangyamin/article/details/46853321 http://mysql.taobao.org/monthly/2016/01/01/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOV网(Activity on Vertex Network)与拓扑排序]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2018%2F01%2F11%2Faov-topology%2F</url>
    <content type="text"><![CDATA[夯实基础 AOV网(Activity on Vertex Network) 用顶点表示活动，用弧表示活动间的优先关系的有向图称为顶点表示活动的网（Activity On Vertex Network)，简称AOV网。在现代化管理中，人们常用有向图来描述和分析一项工程的计划和实施过程，一个工程常被分为多个小的子工程，这些子工程被称为活动（Activity)，在有向图中若以顶点表示活动，有向边表示活动之间的先后关系，这样的图简称为AOV网。 AOV网是一种有向无回路的图。 在网中，若从顶点i到顶点j有一条有向路径，则i是j的前驱。 AOV网中的弧表示了活动之间先后次序存在的制约关系。必须先完成前一个，才能完成下一个。必须先小学毕业，才能初中毕业。 拓扑排序 由AOV网构造拓扑序列的过程叫做拓扑排序(Topological sort)由AOV网构造拓扑序列的实际的意义：如果按照拓扑序列中的顶点次序，在开始每一项活动时，能够保证它的所有前驱活动都已完成。 对AOV网进行拓扑排序的步骤如下 从AOV网中选一个没有前驱的顶点（该顶点的入度为0），并输出它。 从AOV网中山区该顶点以及以它为弧尾的所有有向边。 重复上述两个步骤，知道剩余的网中不再存在没有前驱的节点。 快速通道 图的邻接表存储123456789101112邻接表结构的类型typedef struct edge &#123; //边 int adjvex; // 该边的终止顶点在顶点结点中的位置，数组的key int weight; struct edge *next;&#125; Elink;typedef struct ver &#123; int indegree; //顶点的入度 vertype vertex; Elink * link;&#125;TOPOVlink; 拓扑排序的算法思想 将所有没有前驱的顶点(indegree=0)，压入链接栈。 当堆栈不空时，从栈中退出栈顶元素并输出，并把该顶点引出的所有有向边删除，同时分别把他的各个邻接顶点的入度减一(indegree-1) 将新的入度为0的顶点亚茹堆栈。 重复2和3步骤，知道输出全部顶点或图中剩余顶点里不在有入度为0的顶点。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最短路径算法]]></title>
    <url>%2Fposts%2F%E7%AE%97%E6%B3%95%2F2017%2F12%2F26%2Fdijkstra-algorithm%2F</url>
    <content type="text"><![CDATA[在图中两个顶点之间的路径 最短路径问题来自于实际生活中在一个地区中，各个城市之间公路网连接。知道n个城市和想通的公路和距离，找从A城市到B城市最近的一条道路。 在图中两个顶点之间的路径，下图求出a点到b点的最短路径的过程。 从a出发，到终点b，对上图gif解析如下。 ①到②的距离为7，①到③的距离为9，①到⑥的距离为14。out①，最短距离是到②，下一个判断② ②到③的距离为10，则从①到②再到③的距离为10+7 17&gt;①到③的距离为9。②到④的距离15，①到④的距离为22。out②，最短距离是到③，下一判断③ ③到④的距离为11，则从①到③再到④的距离20 &lt; 从①到②再到④的距离22，更新到④的距离为20。 ③到⑥的距离为2，则从①到③再到⑥的距离11 &lt; 从①到⑥的距离14，更新到⑥的距离为11。 out③，最短距离是到⑥，下一个判断⑥ ⑥到⑤(为终点b)的距离为9，即最终为从①到⑥再到⑤，out⑥。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图-最小生成树]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F12%2F20%2Fminimum-spanning-tree%2F</url>
    <content type="text"><![CDATA[最小生成树 Minimum Spanning Tree MST 最小生成树 假设要在n个城市之间建立通讯网，则连通n个城市只需要修剪n-1条线路，如何在最节省经费的前提下建立这个通讯网？答案是：最小生成树。 Prim算法 基本思想从一个点出发找出到邻接点权值最小的顶点，然后从这两个顶点中找出邻接点权值最小的顶点，然后从这三个顶点找出邻接点权值最小的顶点，依次类推。 图解 算法实现 lowcost[i]：表示以i为终点的最小权值 mst[i]: 表示lowcost[i]的起点 12345678910111213141516171819202122232425262728293031int prim(int graph[][MAX], int n)&#123; int lowcost[MAX]; int mst[MAX]; int i, j, min, minid, sum = 0; for (i = 2; i &lt;= n; i++) &#123; lowcost[i] = graph[1][i]; mst[i] = 1; &#125; mst[1] = 0; for (i = 2; i &lt;= n; i++) &#123; min = MAXCOST; minid = 0; for (j = 2; j &lt;= n; j++) &#123; if (lowcost[j] &lt; min &amp;&amp; lowcost[j] != 0) &#123; min = lowcost[j]; minid = j; &#125; &#125; cout &lt;&lt; "V" &lt;&lt; mst[minid] &lt;&lt; "-V" &lt;&lt; minid &lt;&lt; "=" &lt;&lt; min &lt;&lt; endl; sum += min; lowcost[minid] = 0; for (j = 2; j &lt;= n; j++) &#123; if (graph[minid][j] &lt; lowcost[j]) &#123; lowcost[j] = graph[minid][j]; mst[j] = minid; &#125; &#125; &#125; return sum;&#125; kruskal算法 基本思想找出权值最小的、再找出权值次小的、依次类推。如果其中已经有连线，则换下一个。 图解]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于redis的一些思考]]></title>
    <url>%2Fposts%2FRedis%2F2017%2F12%2F08%2Fredis-think%2F</url>
    <content type="text"><![CDATA[大key？ redis实现分布式锁？ mget？ 大key 大key，并不是指redis的key很大，而是指所对应的value值很大 背景： 由于value很大，导致一次get的时间很长，又由于redis是单进程，所以后面的命令会阻塞，请求会超时。图解：解决方案： 拆大key，以hash存储为例123456789//将大key映射为多个key来存储该hash。$redis-&gt;hset($hash, $key, $value);function myHset($hash, $key, $value) &#123; $number = crc32($hash); $hashKey = $hash . ":shard:". $number % 1024; return $redis-&gt;hset($hashKey, $key, $value);&#125; redis分布式锁（简单的实现，满足大部分需要） 分布式锁的应用场景举例：两个请求访问decr库存 1234567891011121314151617181920212223/** * @brief lock * @param $strKey * @param $intTimeout second * @return bool */public function lock($strKey, $intTimeout = 10) &#123; $this-&gt;strLockVal = mt_rand(); // nx 只有键key不存在的时候才会设置key的值 return $this-&gt;redis-&gt;set($strKey, $this-&gt;strLockVal, array('nx', 'ex' =&gt; $intTimeout));&#125;/** * @brief unlock * @param $strKey * @return void */public function unlock($strKey) &#123; $strRes = $this-&gt;redis-&gt;get($strKey); if ($strRes == $this-&gt;strLockVal) &#123; $this-&gt;redis-&gt;del($strKey); &#125;&#125; mget？mset？ 一次set、get数据不要太多，否则一次获取会导致redis阻塞。 12345//解决方法 500一份 mset$arrSetRedisData = array_chunk($arrData, 500, true);foreach ($arrSetRedisData as $arrChunk) &#123; $this-&gt;redis-&gt;set($arrChunk);&#125;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-图]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F12%2F04%2Fstruct-graph%2F</url>
    <content type="text"><![CDATA[线性结构 1:1，树形结构 1:N，图形结构 N:N 图定义 图存储邻接矩阵 邻接矩阵，益存储稠密图。但是现实总稀疏图较多，用邻接矩阵存储浪费空间。 邻接表 邻接表存储，不会浪费空间。计算入度简单，但是计算出度复杂。通常计算顶点出度时，通常会用逆邻接表 有向图十字链表 无向图多重邻接表 图遍历深度优先算法 遍历原则：从图中某一指定顶点v出发，先访问v，然后从该顶点的未被访问过的邻接顶点w出发，进行深度优先搜索。直到图中与v相通的所有顶点都被访问。若图中还存在未被访问过的顶点，则以这个未被访问的顶点重复上述过程。白话：找一个顶点，遍历其邻接顶点，在遍历邻接顶点的邻接节点。 12345678910111213void DFS(VLink G[], int v) &#123; int w; VISIT(v); //访问顶点v visited[v] = 1; // 将顶点v对应的访问标记为1 w = FIRSTADJ(G, v); // 求v的第一个邻接点，若无邻接点，则返回-1 while (w != -1) &#123; if (visited[i] == 0) &#123; DFS(G, w); // 递归遍历 &#125; w = NEXTADJ(G, w); // 求v的下一个邻接点，若无邻接点，则返回-1 &#125;&#125; 广度优先算法 遍历原则：从图中指定顶点v触发，访问v以后再依次访问v的各个未被访问的邻接点。然后从这些邻接点出发，按照同样原则依次访问它们的未被访问过的邻接点…。若此时图中还存在未被访问的顶点，则从另一个未被访问的顶点出发，继续上述过程。白话：先访问指定出发点，然后依次访问该顶点的所有未被访问过的邻接点，再接下来访问邻接点的未被访问过的邻接点。(需要队列实现) 12345678910111213141516171819void BFS(VLink G[], int v) &#123; int w; VISIT(v); // 访问顶点v visited[v] = 1; // 将顶点v对应的访问标位1 ADDQ(Q, v); // 将v添加到队列中 while (!EMPTY(Q)) &#123; v = DEL(Q); // 退出队头元素v w = FIRSTADJ(G, v); // 求v的第1个邻接点，无邻接点返回-1 while (w != -1) &#123; if (visited[w]) &#123; continue; &#125; VISIT(w); //访问顶点w ADDQ(Q, w); // 当前被访问过的顶点w入队 visited[w] = 1; // 顶点w对应的访问标记为1 w = NEXTADJ(G, v); //求v的下一个邻接点，无邻接点，返回-1 &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树算法]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F11%2F29%2Fbinary-tree-algorithm%2F</url>
    <content type="text"><![CDATA[面试中的二叉树 二叉树的节点总数123456int nodeNumber(struct node *root) &#123; if (root == NULL) &#123; return 0; &#125; return nodeNumber(root-&gt;left) + nodeNumber(root-&gt;right) + 1;&#125; 二叉树的深度123456789// 二叉树的深度int nodeDepth(struct node *root) &#123; if (root == NULL) &#123; return 0; &#125; return nodeDepth(root-&gt;left) &gt; nodeDepth(root-&gt;right) ? nodeDepth(root-&gt;left) + 1 : nodeDepth(root-&gt;right) + 1 ;&#125; 叶结点总数12345678910//叶子结点的个数int leafNode(struct node *root) &#123; if (root == NULL) &#123; return 0; &#125; if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) &#123; return 1; &#125; return leafNode(root-&gt;left) + leafNode(root-&gt;right);&#125; 第k层的结点数12345678910//第k层的结点数int kNode(struct node *root, int k, int level = 1) &#123; if (root == NULL) &#123; return 0; &#125; if (k == level) &#123; return 1; &#125; return kNode(root-&gt;left, k, level + 1) + kNode(root-&gt;right, k, level + 1);&#125; 判断二叉树是不是平衡二叉树12345678910//判断二叉树是不是平衡二叉树【左子树与右子树高度差不大于1】int isAVL(struct node * root) &#123; if (root == NULL) &#123; return 0; &#125; // 利用树的深度 int leftDepth = nodeDepth(root-&gt;left); int rightDepth = nodeDepth(root-&gt;right); return abs(leftDepth - rightDepth) &gt; 1 ? 1 : 0;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的遍历]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F11%2F27%2Ftree-traversal%2F</url>
    <content type="text"><![CDATA[还记得那些面试题吗？ 二叉树的遍历 前序遍历前序遍历：根结点-&gt;左子树-&gt;右子树123456789101112131415161718192021222324252627282930313233343536伪代码//递归function preorder(root) &#123; if (root) &#123; printf("%d\n", root-&gt;data); preorder(root-&gt;left); preorder(root-&gt;right); &#125;&#125;//非递归，栈//思路：//1. 根结点开始，开始遍历，并输出，将结点压入到栈//2. 当到达最左结点的时候，访问右结点//第一步已经输出了根结点，和最左结点function preorderInteration(root) &#123; if (root == NULL) &#123; return ; &#125; node = root; while (node != NULL &amp;&amp; !stack.isempty()) &#123; while (node != NULL) &#123; //输出根结点，最后输出了最左结点 printf("%d\n", node-&gt;data); stack.push(node); node = node-&gt;left &#125; if (! stack.isempty()) &#123; node = stack.top(); stack.pop(); node = node-&gt;right; &#125; &#125;&#125; 中序遍历中序遍历：左子树-&gt;根结点-&gt;右子树12345678910111213141516171819202122232425262728293031323334伪代码//递归function midorder(root) &#123; if (root) &#123; midorder(root-&gt;left); printf("%d\n", root-&gt;data); midorder(root-&gt;right); &#125;&#125;//非递归 栈来实现//思路：//1. 从根结点开始，开始遍历//2. 递归输出直至最左，然后输出（中序先输出左孩子，而中序遍历第一个输出的是其最左叶子结点）//3. 当到达最左结点的时候，访问右结点function midorderinteration(root) &#123; if (root == NULL) &#123; return ; &#125; node = root; while (node != NULL &amp;&amp; !stack.isempty()) &#123; while (node != NULL) &#123; stack.push(node); node = node-&gt;left &#125; if (! stack.isempty()) &#123; node = stack.top(); printf("%d\n", node-&gt;data); stack.pop(); node = node-&gt;right; &#125; &#125;&#125; 后序遍历后序遍历：左子树-&gt;右子树-&gt;根结点12345678910111213141516171819202122232425262728293031323334353637383940414243444546伪代码//递归function postorder(root) &#123; if (root) &#123; postorder(root-&gt;left); postorder(root-&gt;right); printf("%d\n", root-&gt;data); &#125;&#125;//非递归 栈来实现//思路：保证根结结点在左右访问之后才能访问//1. 对于任意结点N先入栈//2. 如果N不存在左右孩子，则访问// 如果N的左孩子刚被输出，而N的右孩子为NULL，则访问// 如果N的右孩子刚被输出，则访问function postorderiteration(root) &#123; if (root == NULL) &#123; return ; &#125; pre; // 上一次访问的结点 cur; // 当前结点 stack.push(root); while (!stack.empty()) &#123; cur = stack.top(); if ( (cur-&gt;left == NULL &amp;&amp; cur-&gt;right == NULL) || (cur-&gt;left == pre &amp;&amp; cur-&gt;right == NULL) || (pre == cur-&gt;right) ) &#123; printf("%d\n", cur-&gt;data); // 出栈 stack.pop(); pre = cur; &#125; else &#123; if (cur-&gt;right != NULl) &#123; push(cur-&gt;right); &#125; if (cur-&gt;left != NULl) &#123; push(cur-&gt;left); &#125; &#125; &#125;&#125; 层次遍历/广度优先从最顶层，一层层向下遍历，又可称为广度优先遍历1234567891011121314151617181920伪代码// 迭代，不能用递归实现function levelOrder(root) &#123; tempNode = root; while (tempNode) &#123; printf("%d\n", tempNode-&gt;data); if (tempNode-&gt;left) &#123; // 左子树存在，入队列 enQueue(queue, tempNode-&gt;left); &#125; if (tempNode-&gt;right) &#123; // 右子树存在，入队列 enQueue(queue, tempNode-&gt;right); &#125; // 获取出队列的值 tempNode = deQueue(queue); &#125;&#125; 深度优先遍历(包含前序遍历、中序遍历、后序遍历)12345678910伪代码//递归function getList(head)&#123; if (!head.left &amp;&amp; !head.right) &#123; return head.val; &#125; return head.val + getList(head.left) + getList(head.right);&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[游戏]]></title>
    <url>%2Fposts%2F%E6%8A%98%E8%85%BE%2F2017%2F11%2F18%2Fgame%2F</url>
    <content type="text"><![CDATA[贪吃蛇]]></content>
      <categories>
        <category>折腾</category>
      </categories>
      <tags>
        <tag>折腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的那些事儿]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F11%2F15%2Fbinary-tree%2F</url>
    <content type="text"><![CDATA[每一个结点最多只有两棵子树，通常称这种树为二叉树。在二叉树中严格区分结点的左、右孩子。因此二叉树是有序树。 有序树严格区分左右子树 二叉树的5种基本形态 二叉树演化出来的树 二叉查找树、满二叉树、完全二叉树、自平衡二叉树、AVL、红黑树…头晕，为啥整出这么多树？ 分类图 满二叉树 对于任意一个结点，要么是叶子结点，要么它有两个孩子结点 完全二叉树 最下面两层的结点度可以小于2，并且最下面一层结点依次排列在最左边的位置上 自平衡二叉查找树 为啥有这个呢？因为在一般的二叉查找树中查找某个结点，跟树的深度有关，当深度大的时候，查询复杂度越高。 解决这样的问题：有两种常用的树，就是AVL树和红黑树了。 AVL树红黑树 红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树 哈夫曼树 给定一组权值，构造出的具有最小带权路径长度的二叉树称为哈夫曼树，又称为最优二叉树。 斜树]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树的性质]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F11%2F13%2Fstruct-tree-nature%2F</url>
    <content type="text"><![CDATA[四个性质性质一：非空树的结点数等于树中所有结点的度之和加1 性质二：度为k的非空树的第i层最多有$k^{i-1}$个结点（i&gt;=1）数学归纳法 大法好当i = 1时，第一层只有一个结点，即树的根结点。$k^0 = 1$。当i &gt; 1时，假设命题成立，则第i-1层最多有$k^{i-2}$个结点。因为度为k的树，每个结点最多有k个孩子结点。则i层的最多的结点数是第i-1层的k倍，则第i层最多有$k*k^{i-2}$=$k^{i-1}$个结点。 性质三：深度为h的k叉树最多有$\frac{k^h -1}{k-1}$只有当深度为h的k叉树的每一层都达到该层最大结点总数时，该树的结点总数才达到最大，因此$$\sum_{i=1}^k k^{i-1}=k^0 + k^1 + k^2 + … + k^{h-1}=\frac{k^h-1}{k-1}$$ 其实是一个等比数列，从1开始，等比为k的数列，则总和为$S_n = a_1 + a_2 + a_3 + … + a_n$$$S_n=\frac{1 - k^{h-1}*k}{1-k} = \frac{k^h-1}{k-1}$$ 一颗k叉树的结点总数为$\frac{k^h-1}{k-1}$时，称为该树为满k叉树。 性质四：具有n个结点的k叉树的最小深度为$log_k(n(k-1)+1)$详细证明如下设具有n个结点的k叉树的深度为h，若该树的前h-1层都是满的，即每一层的结点数都为$k^{i-1}$个$(1≤i≤h-1)$第h层（最后一层）的结点数可能满，也可能不满，n总结点数小于等于深度为h的满k叉树，则可得如下式子：$$n ≤ \frac{k^h-1}{k-1}$$ 又因为n肯定大于h-1层的满k叉树，即$$\frac{k^{h-1}-1}{k-1} &lt; n$$ 合并得$$\frac{k^{h-1}-1}{k-1} &lt; n ≤ \frac{k^h-1}{k-1}$$$${k^{h-1}-1} &lt; n(k-1) ≤ {k^h-1}$$$$k^{h-1} &lt; n(k-1) + 1 ≤ k^h$$取以k为底的对数$$① h-1 &lt; log_k(n(k-1) + 1) ≤ h$$$$② h &lt; log_k(n(k-1) + 1) + 1 ≤ h + 1$$根据①，②得$$log_k(n(k-1)+1) ≤ h &lt; log_k(n(k-1) + 1) + 1$$又因h是树的深度，只能是整数，所以$$h = log_k(n(k-1)+1) $$ 例题例题1：一个深度为5的满2叉树的结点总数为多少？例题2：一个深度为3的满6叉树的结点总数为多少？例题3：对于二叉树，最小深度为$log_2(n(2-1) + 1)，n=20$，最小深度为？例题4：对于三叉树，最小深度为$log_3(n(3-1) + 1)，n=20$，最小深度为？]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树的名词图解]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F2017%2F11%2F09%2Fstruct-tree%2F</url>
    <content type="text"><![CDATA[结点的度：一个结点含有的子树的个数称为该结点的度。 结点的度：一个结点含有的子树的个数称为该结点的度。 树的度：一棵树中，最大的结点的度称为树的度。 叶结点：度为0的结点。 分支结点：度不为0的结点。 父结点：若一个结点含有子结点，则这个结点称为其子结点的父结点。 子结点：一个结点含有的子树的根结点称为该结点的子结点。 兄弟结点：具有相同父结点的结点互称为兄弟结点。 结点的层次：从根开始定义起，根为第1层，根的子结点为第2层，以此类推。 深度：对于任意结点n,n的深度为从根到n的唯一路径长，根的深度为0。 高度：对于任意结点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next主题 支持数学表达式MathJax]]></title>
    <url>%2Fposts%2F%E6%8A%98%E8%85%BE%2F2017%2F11%2F01%2Fsupport-math%2F</url>
    <content type="text"><![CDATA[安装步骤（三步）第一步：安装hexo-math1npm install hexo-math --save 第二步：配置站点根目录_config.yml123456math: engine: 'mathjax' # or 'katex' mathjax: src: custom_mathjax_source config: # MathJax config 第三步：配置主题themes/next/_config.yml 如果设置了pre_page: true，则按照下面设置即可 完成，测试代码。执行hexo g即可1$\sum_&#123;i=0&#125;^n i^2 = \frac&#123;(n^2+n)(2n+1)&#125;&#123;6&#125;$ 效果如下$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$]]></content>
      <categories>
        <category>折腾</category>
      </categories>
      <tags>
        <tag>折腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我和弟弟的谈话]]></title>
    <url>%2Fposts%2F%E6%88%90%E9%95%BF%E8%BD%A8%E8%BF%B9%2F2017%2F05%2F14%2Ffeeling%2F</url>
    <content type="text"><![CDATA[我和一个正在上初中弟弟的谈话 我弟弟跟当年的我一样，在一个乡镇中学上学。我问他上学怎么样？每天累吗？我觉得上初中没有那么累，就是玩着学着就过去了。我弟弟跟我讲，早晨5.30起床，然后晨读，吃早饭，上课，吃中午饭，休息到2点，上课，吃晚饭，上三节晚自习，睡觉的时候快10点了。其中具体的时间记得不太清楚了，只记得一个5.30和10点。我惊讶了，我每天都是8点半起床，早饭有时吃，有时不吃。然后上班，12点吃中午饭，工作到6点左右吃个晚饭！回去再加会班，9点多回家，在家玩会手机。快12点了就睡觉。一个初中生感觉比正青春年少的我还要努力。我心里对我弟弟萌生了一份敬仰之心。我毕业快一年了，刚进入社会，应该怀抱着理想与激情，在社会中尽快的让自己成长，而不是整天混日子，上班，下班。我还年轻，不能让自己这样无所谓的进行下去了！我在北京，一个北漂的人，北漂这个形容词并不是每个在北京的人都能配上这个词，每天不甘心现在，而努力奋斗的人才能配的上。以我现在的状况，我实属不配北漂这个形容词。]]></content>
      <categories>
        <category>成长轨迹</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库水平拆分-分享记录]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2017%2F04%2F13%2Fhorizon-split-db%2F</url>
    <content type="text"><![CDATA[有幸参加沈剑的有关数据库水平拆分的技术分享，把分享的一些点记录了下来。 业务决定架构磁盘很容易成为架构的瓶颈，往磁盘上写数据有两类 一类：日志，只是新增数据，没有大的性能影响 另一类：数据库写磁盘 一：基本概念 分片 sharding 业务场景：数据量大 单库分为两个或多个库，例如user表有1亿条记录，分成两个5千万的表 复制 replication 业务场景：数据备份，读多写少 主从复制，一主两从等等 分组 group 一主两从或一主多从 为一组 路由规则 route rule 常见的路由方法 范围：range 0~1千万 1库 1~2千万 2库 2~3千万 3库 … 规则简单，拿id取模就可以找到对应的库中查询 易扩容，新增数据，按照范围，直接可扩容 数据访问不平均，1库访问较多，2库访问明显较少 哈希：hash 规则简单，对id哈希得到数，然后去对应的库中查询 数据访问理论上平均 不易扩容 路由服务：router-config-server 调用者无需关心如何拆分数据库，不需要将选库的逻辑放在代码中 多了一次调用 二：如何进行水平拆分？拆分依据是什么？ 四类典型场景 几乎涵盖互联网90%业务场景 （单key）用户库如何拆分：user(uid, XXOO) （1对多）帖子库如何拆分：tiezi(tid, uid, XXOO) （多对多）好友库如何拆分：friend(uid, friend_uid, XXOO) （多key）订单库如何拆分：order(oid, buyer_id, seller_id, XXOO) 三：用户库拆分？ 用户库，10亿数据量 user(uid, uname, passwd, age, sex, create_time); 业务需求如下 （1）1%登录请求=&gt; where uname=XXX and passwd=XXX （2）99%查询请求=&gt; where uid=XXX 问题？那uname的查询怎么办？ 解决方案 建立uname与uid的对应关系 uname与uid uname的长度一般是固定的，采用树形结构进行存储 四：帖子库拆分？ 帖子库，15亿数据量 tiezi(tid, uid, title, content, time); 业务需求如下 （1）查询帖子详情（90%请求） SELECT FROM tiezi WHERE tid=$tid （2）查询用户所有发帖（10%请求） SELECT FROM tiezi WHERE uid=$uid 如何拆分？ 根据tid来分，90%的问题能解决。 10%的问题，最粗暴的方法，循环每个库来一遍 五：好友库拆分？ 好友库，1亿数据量 friend(uid, friend_uid, nick, memo, XXOO); 业务需求如下 （1）查询我的好友（50%请求）=&gt; 用亍界面展示 SELECT friend_uidFROM friend WHERE uid=$my_uid （2）查询加我为好友的用户（50%请求）=&gt; 用户反向通知 SELECT uidFROM friend WHERE friend_uid=$my_uid 方案 维护uid与friend_id的关系 friend_id与uid的关系 六：订单库如何拆分？ 订单库，10亿数据量 order(oid, buyer_id, seller_id, order_info, XXOO); 业务需求如下 （1）查询订单信息（80%请求） SELECT FROM order WHERE oid=$oid （2）查询我买的东东（19%请求） SELECT FROM order WHERE buyer_id=$my_uid （3）查询我卖出的东东（1%请求） SELECT *FROM order WHERE seller_id=$my_uid 方案 方案1 需求一和需求二 用帖子库的处理方法处理 需求三和需求二 用好友库的处理反复处理 方案2 需求一和需求二 用帖子库的处理方法处理 需求三仅仅是1% 但是增加了架构的复杂度 没有必要 TIPS 1主3从，其中1从用于后台的查询。 原因是后台与前台请求没有分开，如果后台的请求对数据库进行order by操作， 整个CPU都满了，那么会影响前台的请求。 主库写的多，可以不给主库设置索引，只给从库设置索引]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅读]]></title>
    <url>%2Fposts%2F%E6%88%90%E9%95%BF%E8%BD%A8%E8%BF%B9%2F2017%2F03%2F29%2Fbook%2F</url>
    <content type="text"><![CDATA[书籍 20151. 黑客与画家 20161. 重构 改善既有代码的设计 2. php核心技术与最佳实践 3. 大型网站技术架构：核心原理与案例分析 4. 大型分布式网站架构设计与实践 5. 一千零一夜 6. 大话设计模式 20171. 建筑的永恒之道 2. 人类简史 3. 狼图腾 4. 把时间当做朋友 5. 乔布斯传 6. mysql技术innodb存储引擎 7. redis设计与实现 8. 奇特的一生 9. 活出生命的意义 10. 看见 11. 北大凌晨四点半 12. 人人都是产品经理 13. 好好学习 14. 半小时漫画中国史 20181. 人性的弱点 2. 刻意练习 3. 钢铁是怎样炼成的 4. 万历十五年 5. 假如给我三天光明 6. 朝花夕拾 7. 呐喊 8. MacTalk 跨越边界 9. 庄子说-蔡志忠 10. 图解HTTP 11. 图解密码技术 12. 图解TCP/IP 13. 深入剖析PHP内核 14. 高性能MySQL 20191. 飘 2. 三体 3. 穷爸爸富爸爸 4. 小狗钱钱 5. 你的第一本保险指南 6. 半小时漫画经济学1-2册 7. 终身成长 8. 毛泽东传 2020]]></content>
      <categories>
        <category>成长轨迹</category>
      </categories>
      <tags>
        <tag>成长轨迹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库第一范式]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2017%2F03%2F13%2Ffirst-paradigm%2F</url>
    <content type="text"><![CDATA[数据库第一范式 数据库最常见的设计都会遵循三大范式，今天就来唠唠数据库设计的第一范式！ 定义：规定关系的每一个分量必须是一个不可分的数据项。简单来说就是每一个列（属性）只有一个，没有重复。 例一：重复的组 此份数据不符合第一范式，只要将每笔记录转化为单一记录就可以了。 例二：缺乏唯一识别码 交易一模一样，无法区分。缺乏唯一识别码，都简称为ID，为唯一的标识。 例三：很多字段来表达同一个意思 假设我们想要知道喜欢吃一种食物有哪几个人，查询条件复杂。 也是一个糟糕的设计，第一范式也不允许列重复。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 账号管理]]></title>
    <url>%2Fposts%2FLinux%2F2017%2F02%2F14%2Faccount-manage%2F</url>
    <content type="text"><![CDATA[Linux 下的账号管理习题 1 创建用户 one_user 并设置密码为 1234567812345678910[root@aliyun ~]# useradd one_user[root@aliyun ~]# passwd one_userChanging password for user one_user.New password:BAD PASSWORD: it is too simplistic/systematicRetype new password:passwd: all authentication tokens updated successfully.######################################useradd 是新增用户的命令passwd 是设置用户密码的命令 2 重置用户 one_user 的密码为 123abcdefg12345678[root@aliyun ~]# passwd one_userChanging password for user one_user.New password:BAD PASSWORD: it is too simplistic/systematicRetype new password:passwd: all authentication tokens updated successfully.######################################passwd 是设置用户密码的命令 3 删除用户 one_user，如果也要删除该用户在机器上的所有文件及目录12345[root@aliyun ~]# userdel one_user######################################userdel 删除用户，仅仅删除的是用户名和密码[root@aliyun ~]# userdel -r one_useruserdel -r 删除所有关于用户的文件及目录 4 新增用户组 group_name123[root@aliyun ~]# groupadd group_name######################################groupadd 新增用户组 5 删除用户组 group_name123[root@aliyun ~]# groupdel group_name######################################groupdel 删除用户组 6 假设用户组developer存在，新增用户phper到developer用户组下1234[root@aliyun ~]# useradd -G developer phper######################################useradd -G 用户组名 用户新增用户phper 指定用户组为developer 7 假设用户组developer存在，修改存在的用户pythoner到developer用户组下1234[root@aliyun ~]# usermod -g developer pythoner######################################usermod -g 用户组名 用户修改存在的用户pythoner到developer用户组下 8 查看某个用户的所属的用户组1234[root@aliyun ~]# id pythoneruid=1018(pythoner) gid=1009(developer) groups=1009(developer)######################################id 用户]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分析80万知乎用户数据]]></title>
    <url>%2Fposts%2F%E6%8A%98%E8%85%BE%2F2017%2F01%2F23%2Fzhihu-user%2F</url>
    <content type="text"><![CDATA[满足下好奇心 总体数据如图专业排名前20分布如图性别统计分布教育排名前20分布名校性别比例居住地排名前20统计职业排名前20统计行业排名前20统计]]></content>
      <categories>
        <category>折腾</category>
      </categories>
      <tags>
        <tag>折腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯面试]]></title>
    <url>%2Fposts%2F%E6%88%90%E9%95%BF%E8%BD%A8%E8%BF%B9%2F2017%2F01%2F16%2Ftencent-interview%2F</url>
    <content type="text"><![CDATA[第一次大公司面试 2016年11月15号，下午4点多，在公司和往常一样写着代码。瞟了一眼手机，指示灯亮了。 好奇心驱使着我打开手机。心里诅咒着：谁呀？都过了双十一了，还打广告。一看有个未读短信，扫了一眼短信内容：“郭新鹏，您好。很高兴通知您，请于2016.11.16下午15:00到知春路49号希格玛大厦3F进行面试（腾讯北京公司）……”。 看完之后没感觉，只是觉得空荡荡的。只是觉得我离BAT这样的公司还很遥远。以至于面了腾讯回来后，大脑皮层还没有觉察到发生了什么。我认真地反复地读着短信，才觉得这是真的，明天我要去面腾讯。心情好激动，思绪都跑到腾讯面试去了，没有空余的思绪去写代码了。想着先好好忙工作，明天请一天假，上午好好准备，下午去面试，穿什么衣服我都想好了。 2016年11月16日，早晨8:00起床，没有去上班，因为今天下午3：00面试腾讯。简单收拾了一下，开始做面试的准备。看了些在leetcode上刷过的题，背了一道单链表翻转的题。做了一些网上有关腾讯的面试题。找了一些容易考的笔试题，比如：端口号，tcp3次握手，4次握手，http状态码等等。 时间紧迫，只有一个上午。想起昨天晚上读了一篇有关面试腾讯的文章，文章中讲到需要自我介绍，也描绘了自我介绍的重要性。我开始急匆匆的整理自我介绍的思路，准备一下思路，对着镜子练习了15分钟。 宝贵的上午就这么匆匆的溜走了。我住在六里桥，去知春路面试，现在1点整，坐地铁10号线大概50分钟左右就到了，3点才开始面试。时间充裕，抱着忐忑的心情从家里出发了，先去附近的复印店打印了两份简历，两份简历4页，4块钱，心情有点小波澜。 到知春路才1:55，还有一个小时才能面试呢，这去哪？就绕着腾讯大夏走了一圈，看了下时间，2：05。时间怎么过的这么慢呢，我又走了一圈。手心里都是汗，这么长时间也不能老紧张着，于是一咬牙，就给面试官打个电话，询问能不能现在面试。和面试官打通电话说：我在你们公司楼下，现在可以去面试吗？ 面试官说：可以！ 我到了三层，做了登记，领了个牌，前台解释说要让面试官来接。没有办法只能再给面试官打个电话，不一会儿，面试官来了。“咱们约的3点吧！”，我说：“是的，我在楼下转了好长时间了”。跟着面试官，到了一个专门面试的大厅，让我稍等一下，说要去准备一下。等了大概5分钟左右吧，面试官拿着我的简历来了。简历应该是面试官刚打印出来的。我看到面试官拿着的简历不太清晰，我递给面试官了一份清晰的简历。 面试官看着我的简历。接下来的时间就开始面我了。 面试官：你对腾讯的了解有多少?我：qq和微信覆盖面比较广，游戏也是腾讯的一大产业，但是我不玩游戏。BAT是中国的三大互联网企业，我觉得每个程序员都想进google，facebook。在国内的话，当然都想进BAT。面试官：我简单的介绍一下我的部门。我们是……面试官：你做一下自我介绍吧。我：12年入学，16年毕业。大二暑假开始实习，边上学边实习，当时的工资是1500。面试官：你做的这个项目是你自己完成的吗？我：是，还有一个后端就是简单的指点我一下。面试官：那你在实习的公司学到了什么？我：成长。当一件事情压着你的时候，就是最难的时候，也是你成长最快的时候。还有就是解决问题的能力。面试官：接着说吧！我：到了大三，觉得学的东西还是不够，于是又回到学校学习memcached、redis、mongo等面试官：你觉得什么地方学的东西不扎实。我：数据库学的不太够。在学校继续学习了段时间，时间很快，就要升大四了。因为学校大四的课程不多，所以就来北京了。当时比较着急落脚，就在北京xx公司工作了。当时做了许多相关微信的开发。后来偶然间一个社区让我给他们做一套课程，于是就是他们的认证讲师。面试官：为什么你在北京xx公司只干了三个月？我：是一家外包公司，只是简单的复制粘贴，没有成长。然后就去了北京yy公司，在这里，因为去的时候正好赶上项目启动。面试官：你在这里是项目组长，那你怎么当上的项目组长的？我：因为有的员工离职等等，我接触的这个项目对代码都很熟悉，所以新入职的员工都是我来带着他们。面试官：你接触过的数据量是什么级别？我：我犹豫了好长时间，心里没有底气的说道百万级。面试官：我是前端的，需要招聘后端，希望带着前端去做，希望后端有一个带头的作用，类似于组长。我: 我学过前端，我在现在这个公司也写页面，写交互等等。面试官：拿着笔对我的简历，画了一块，用html简单的写一下。我: 大概写了一下，不过在纸上写代码确实不太好看，并且潦草。面试官：看不懂。我：我直接给您讲吧，于是就简单的说了说。面试官：之后讲让技术面你一下吧，在那稍等一会儿。 等了一会儿，面试官带我去四楼去面试。面试官和技术面试官简单的说了几句。 技术面试官就来了，就开始面试了。技术面试官：你是郭新鹏是吧？我：是的，您好！技术面试官：接下来就开始面试了！你说说innodb和myisam引擎的区别？我：myisam的锁的力度比较大，而innodb锁的力度比较小，innodb引擎是主流的数据库引擎。myisam insert快 select慢技术面试官：myisam select为什么慢我：两者用的索引不一样，具体我也不知道。技术面试官：你读过ThinkPHP源码，那你讲讲ORM是怎么实现的。我：其实现的核心是利用php的魔术方法。还有就是为什么能够 M(‘user’)-&gt;select()-&gt;field()-&gt;where()-&gt;limit();因为他们返回的是这个对象。技术面试官：讲一下一致性哈希我：不知道直接讲，还是从取模算法讲起。想了想还是从取模算法讲起。取模算法边列举，边画图，讲完了取模算法，还给面试官解释了一下为什么宕机之后命中率会是1/n。刚开始讲一致性哈希……技术面试官：你知道这个，我就不问你了。一致性哈希其实是为了更好地扩容。那你讲讲工作中遇到的瓶颈。我：搜索like匹配关键字，使用的sphinx做全文索引，自己搭建的sphinx，用的coreseek做的中文分词。技术面试官：在纸上画了一个二叉树，说你用广度优先遍历一下所有的数，用程序写出来。123 1 2 34 5 6 7 我：1234567function getList(head)&#123; if (!head.left &amp;&amp; !head.right) &#123; return head.val; &#125; return getList(head.left) + getList(head.right);&#125; 技术面试官：你这个是深度优先吧，你在想想。我：这个就是广度优先技术面试官：你在写出一个深度优先我：不会了技术面试官：你在工作中还用到那些？我：缓存，缓存DB的数据，缓存打包好的数据。通过分库来区别，有对应的过期时间。缓存有了但是为了保持数据一致性，这又是个问题。技术面试官：你是怎么解决的？我：当数据更新了，就把缓存中对应的key给删除。这样数据取不到，就会去数据库中去取。技术面试官：数据库是怎么个情况？我：一主一丛。技术面试官：那缓存是怎么读的？读主库还是从库？我：读的是从库。技术面试官：那主从有延迟，怎么解决？我：不知道。技术面试官：配置nginx使静态文件到另一个目录。我：123location ~ (.css|.js) &#123; root /data/www/static;&#125; 技术面试馆：php是怎么配置的我：通常这个是放在一个文件里，其他配置去引用。123location ~ *.php &#123; fastcgi_pass: 9000;&#125; 等等就是这个意思。技术面试官：我就面到你这，在我这里，你是通过了，当然决定要不要你，还是刚才的领导说的算。我：好的。 tips：面试一定要带简历（简历你都不带，那你是干嘛来了？） 不会的：0：回答问题不要犹豫（回答数量是什么级别）1：二叉树广度优先遍历，深度优先遍历2： 主从延迟怎么解决3：ORM的原理4：innodb和myisam的区别]]></content>
      <categories>
        <category>成长轨迹</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Session 存储流程]]></title>
    <url>%2Fposts%2FHTTP%2F2016%2F12%2F07%2Fsession%2F</url>
    <content type="text"><![CDATA[Session 服务器端存储流程 文件存储和redis存储 基础介绍配置文件1/etc/php-fpm.d/www.conf 123; Set session path to a directory owned by process userphp_value[session.save_handler] = files ;这里指明session的存储方式php_value[session.save_path] = /data/session ;这里指明了session的存储目录 session_set_save_handler12345678910#实现session存储的函数bool session_set_save_handler ( callable $open , callable $close , callable $read , callable $write , callable $destroy , callable $gc [, callable $create_sid ])#实现这几个接口，就能管理session Session存储，数据流向 通过一个Hanler类来实现使用__call魔术方法，可以得到对应函数名和参数以及执行顺序 12345678910111213141516171819202122&lt;?phpclass Handler &#123; public function __call($method, $param) &#123; echo '方法名 ' , $method . PHP_EOL; var_dump($param); echo "&lt;hr /&gt;" &#125;&#125;$handler = new Handler();session_set_save_handler( [$handler, 'open'], [$handler, 'close'], [$handler, 'read'], [$handler, 'write'], [$handler, 'destory'], [$handler, 'gc']);session_start();$_SESSION['name'] = 'value';var_dump($_SESSION); 执行顺序由上图可知open -&gt; read -&gt; write -&gt; close 实现文件存储代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?phpclass Handler &#123; // 存储目录 private $savePath = '/var/log/phpsession'; // 打开操作句柄 public function open($savePath, $sessionName) &#123; return true; &#125; // 读取句柄 public function read($sessionId) &#123; return file_get_contents($this-&gt;savePath.'/sess_'.$sessionId); &#125; // 通过句柄写入 public function write($sessionId, $value) &#123; return file_put_contents($this-&gt;savePath.'/sess_'.$sessionId, $value); &#125; // 关闭 public function close() &#123; return true; &#125; // 调用不存在的方法，就会调用到该函数 public function __call($method, $param) &#123; echo '方法名 ' , $method , "&lt;br /&gt;"; var_dump($param); echo "&lt;hr /&gt;"; &#125;&#125;$handler = new Handler();session_set_save_handler( [$handler, 'open'], [$handler, 'close'], [$handler, 'read'], [$handler, 'write'], [$handler, 'destory'], [$handler, 'gc']);session_start();$_SESSION['name'] = 'value';var_dump($_SESSION); 实现redis存储session代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?phpclass Handler &#123; private $redis; // 获取打开redis链接 public function open($savePath, $sessionName) &#123; $redis = new Redis(); $redis-&gt;connect('127.0.0.1', 6379); $this-&gt;redis = $redis; &#125; // 通过redis链接读取数据 public function read($sessionId) &#123; return $this-&gt;redis-&gt;get('sess_'.$sessionId); &#125; // 通过redis链接写入数据 public function write($sessionId, $value) &#123; return $this-&gt;redis-&gt;set('sess_'.$sessionId, $value); &#125; // 关闭redis链接 public function close() &#123; return $this-&gt;redis-&gt;close(); &#125; public function __call($method, $param) &#123; echo '方法名 ' , $method , "&lt;br /&gt;"; var_dump($param); echo "&lt;hr /&gt;"; &#125;&#125;$handler = new Handler();session_set_save_handler( [$handler, 'open'], [$handler, 'close'], [$handler, 'read'], [$handler, 'write'], [$handler, 'destory'], [$handler, 'gc']);session_start();$_SESSION['name'] = 'value';var_dump($_SESSION); 在浏览器中访问后 浏览器设置 PHPSESSID=rt17ej10h6nv9ej9p1vpdm78e1 服务端查看 key = sess_rt17ej10h6nv9ej9p1vpdm78e1]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Session 工作原理]]></title>
    <url>%2Fposts%2FHTTP%2F2016%2F12%2F07%2Fsession-theory%2F</url>
    <content type="text"><![CDATA[Session 工作原理 为什么要有session？ 针对http协议的局限性，即http是一种无状态的协议提出的一种保持客户端和服务器间保持会话连接状态的机制从本质上讲session和cookie没有太大的区别。 session工作原理 session通过一个PHPSESSID的cookie和服务器联系。session是通过sessionID判断客户端用户的。PHPSESSID名字即是session的文件名。session存在服务端器的文件中，其存在形式不仅仅是文本文件，还可以是cache或者数据库。服务器要想识别客户端，所以客户端必须向服务端发送sessionID这个信息，其表现形式通常为HTTPrequest传输，当然也可以url传输等。 设置session12345#setsession.php 文件&lt;?phpsession_start();$_SESSION['name'] = 'value';var_dump($_SESSION); 浏览器访问该文件 服务器端截图 sessionid 在浏览器端存储的值为 17hroo36ao9q1e2ah0i6c1h350 sessionid 在服务器端的文件名为 sess_17hroo36ao9q1e2ah0i6c1h350 看得出来 浏览器Cookies中的PHPSESSION的值与服务器端存储名一致。 获取Session1234#getsession.php 文件&lt;?phpsession_start();var_dump($_SESSION);]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cookie 工作原理]]></title>
    <url>%2Fposts%2FHTTP%2F2016%2F12%2F06%2Fcookie-theory%2F</url>
    <content type="text"><![CDATA[Cookie 工作原理 为什么要有cookie？ 从早期开始，随着internet的发展，网站常常需要记录访问者的一些信息。服务器要知道两个请求是否来自于同一个浏览器，就是维持状态。是否已经登录，登录才能回复评论，获取用户信息等等这些都是有状态的。有上下文就是有状态的。 Cookie工作原理 Cookie是利用了HTTP头信息进行传递的，在浏览器地址栏中输入example.com，浏览器要发送http请求。这个时候浏览器就会在电脑(客户端)上寻找example.com网站设置的cookie文件如果找到，浏览器就把cookie文件中的信息发送到example服务器，服务器根据客户端传递过来的Cookie就知知道上下文信息了。 设置Cookie123&lt;?phpsetcookie('date', date('Y-m-d H:i:s'), time() + 3600);var_dump($_COOKIE); 用户首次访问www.xpisme.com/setcookie.php 获取Cookie12&lt;?phpvar_dump($_COOKIE); 用户访问www.xpisme.com/getcookie.php]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信开发获取openid中遇到的坑]]></title>
    <url>%2Fposts%2F%E5%BE%AE%E4%BF%A1%2F2016%2F04%2F13%2Fweixin-pit%2F</url>
    <content type="text"><![CDATA[从坑里走出来 微信后台设置授权回调页面域名 注意不要加http:// 微信授权回调的url1https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPID&amp;redirect_uri=http://test.ceshi.com&amp;response_type=code&amp;scope=snsapi_base&amp;state=STATE#wechat_redirect 要加http://，redirect_uri=http://test.ceshi.com正确：redirect_uri=http://test.ceshi.com错误：redirect_uri=test.ceshi.com (这个在电脑端的微信客户端可以， 在手机端就不行，害我周六来改) 注意redirect_uri中的参数如果你在微信端分享出去的链接像这样 http://test.ceshi.com?id=551https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPID&amp;redirect_uri=http://test.ceshi.com?id=55&amp;response_type=code&amp;scope=snsapi_base&amp;state=STATE#wechat_redirect id=55会丢失的 我是这么解决的：0、session中有openid的话就不用走下面了1、把分享出去的http://test.ceshi.com?id=55放入session中2、redirect_uri=http://test.ceshi.com3、微信回调回来之后再进行获取openid的操作4、把openid存入session中5、从session中取出http://test.ceshi.com?id=55，这个url，再跳转回去]]></content>
      <categories>
        <category>微信</category>
      </categories>
      <tags>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主从服务搭建]]></title>
    <url>%2Fposts%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2015%2F05%2F26%2Fmysql-master-slave%2F</url>
    <content type="text"><![CDATA[基础学习：MySQL主从服务搭建 配置一主一从 主：192.168.56.102从：192.168.56.101 主：配置/etc/my.cnf(这个路径根据自己的环境)12345678910[mysqld]#声明二进制日志文件为mysql-bin.XXXXXXlog-bin=mysql-bin#二进制格式有三个row/statement/mixed#row 记录磁盘改变 适合 执行语句长，改变小#statement 记录执行语句 适合 执行语句短 磁盘改变多#mixed是系统自己判断来用哪个格式才存储binlog_format=mixed#给mysql服务一个独特的id，通常为局域网的ip最后一段值server-id = 102 从：配置/etc/my.cnf(这个路径根据自己的环境)123456[mysqld]log-bin=mysql-binbinlog_format=mixedserver-id = 101#得到主的bin-log分析后成relay-log才能被自己所用relay-log=mysql-relay 账号设置 主服务器设置账号从服务器凭借账号去读主服务器的bin-log日志从服务器上注意：master_log_file和master_log_pos这两个选项这两个选项应该和show master status;出来的结果一样(因为从哪个文件，哪个位置开始读) 主：1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000015 | 547 | | |+------------------+----------+--------------+------------------+1 row in set (0.00 sec) 主设置账号12mysql&gt;grant replication client,replication slave on *.* to xp@'192.168.56.%' identified by 'xpisme';mysql&gt;flush privileges; 从关联到主服务器123456mysql&gt;change master tomaster_host='192.168.56.102',master_user='xp',master_password='xpisme',master_log_file='mysql-bin.000015',master_log_pos=547; 从：1mysql&gt;start slave;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
